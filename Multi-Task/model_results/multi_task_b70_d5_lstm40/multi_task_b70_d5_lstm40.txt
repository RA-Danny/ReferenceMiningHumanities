______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_30 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_30[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_43 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_29 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_29 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_43[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_29 (Embedding)                         (None, 73, 300)                  17130300          input_29[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_30 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_29[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_15 (Concatenate)                     (None, 73, 3000)                 0                 embedding_29[0][0]                                
                                                                                                    time_distributed_30[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_44 (Dropout)                             (None, 73, 3000)                 0                 concatenate_15[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_30 (Bidirectional)                 (None, 73, 80)                   973120            dropout_44[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_45 (Dropout)                             (None, 73, 80)                   0                 bidirectional_30[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_43 (Dense)                                 (None, 73, 28)                   2268              dropout_45[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_44 (Dense)                                 (None, 73, 11)                   891               dropout_45[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_45 (Dense)                                 (None, 73, 5)                    405               dropout_45[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_43 (CRF)                                     (None, 73, 28)                   1652              dense_43[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_44 (CRF)                                     (None, 73, 11)                   275               dense_44[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_45 (CRF)                                     (None, 73, 5)                    65                dense_45[0][0]                                    
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1736s - loss: 0.6143 - crf_43_loss: 0.2831 - crf_44_loss: 0.2188 - crf_45_loss: 0.1123 - crf_43_acc_1: 0.9099 - crf_43_acc_2: 0.7718 - crf_43_acc_3: 0.7736 - crf_44_acc_1: 0.7698 - crf_44_acc_2: 0.9061 - crf_44_acc_3: 0.7727 - crf_45_acc_1: 0.7711 - crf_45_acc_2: 0.7717 - crf_45_acc_3: 0.9576 - val_loss: 0.1834 - val_crf_43_loss: 0.0981 - val_crf_44_loss: 0.0713 - val_crf_45_loss: 0.0140 - val_crf_43_acc_1: 0.9548 - val_crf_43_acc_2: 0.8128 - val_crf_43_acc_3: 0.8134 - val_crf_44_acc_1: 0.8133 - val_crf_44_acc_2: 0.9504 - val_crf_44_acc_3: 0.8153 - val_crf_45_acc_1: 0.8131 - val_crf_45_acc_2: 0.8146 - val_crf_45_acc_3: 0.9890 - val_f1: 0.8022 - val_crf_43_f1: 0.7316 - val_crf_44_f1: 0.7326 - val_crf_45_f1: 0.9425
Epoch 2/25
 - 1707s - loss: 0.1993 - crf_43_loss: 0.1102 - crf_44_loss: 0.0677 - crf_45_loss: 0.0214 - crf_43_acc_1: 0.9454 - crf_43_acc_2: 0.7724 - crf_43_acc_3: 0.7758 - crf_44_acc_1: 0.7723 - crf_44_acc_2: 0.9399 - crf_44_acc_3: 0.7740 - crf_45_acc_1: 0.7745 - crf_45_acc_2: 0.7729 - crf_45_acc_3: 0.9787 - val_loss: 0.0702 - val_crf_43_loss: 0.0494 - val_crf_44_loss: 0.0264 - val_crf_45_loss: -5.5938e-03 - val_crf_43_acc_1: 0.9654 - val_crf_43_acc_2: 0.8129 - val_crf_43_acc_3: 0.8135 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9549 - val_crf_44_acc_3: 0.8153 - val_crf_45_acc_1: 0.8133 - val_crf_45_acc_2: 0.8152 - val_crf_45_acc_3: 0.9898 - val_f1: 0.8368 - val_crf_43_f1: 0.8035 - val_crf_44_f1: 0.7611 - val_crf_45_f1: 0.9457
Epoch 3/25
 - 1703s - loss: 0.0880 - crf_43_loss: 0.0643 - crf_44_loss: 0.0261 - crf_45_loss: -2.4137e-03 - crf_43_acc_1: 0.9521 - crf_43_acc_2: 0.7724 - crf_43_acc_3: 0.7756 - crf_44_acc_1: 0.7722 - crf_44_acc_2: 0.9457 - crf_44_acc_3: 0.7739 - crf_45_acc_1: 0.7749 - crf_45_acc_2: 0.7730 - crf_45_acc_3: 0.9807 - val_loss: 0.0094 - val_crf_43_loss: 0.0252 - val_crf_44_loss: 0.0030 - val_crf_45_loss: -1.8813e-02 - val_crf_43_acc_1: 0.9689 - val_crf_43_acc_2: 0.8130 - val_crf_43_acc_3: 0.8134 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9580 - val_crf_44_acc_3: 0.8152 - val_crf_45_acc_1: 0.8134 - val_crf_45_acc_2: 0.8151 - val_crf_45_acc_3: 0.9894 - val_f1: 0.8511 - val_crf_43_f1: 0.8310 - val_crf_44_f1: 0.7782 - val_crf_45_f1: 0.9441
Epoch 4/25
 - 1709s - loss: 0.0267 - crf_43_loss: 0.0394 - crf_44_loss: 0.0044 - crf_45_loss: -1.7122e-02 - crf_43_acc_1: 0.9553 - crf_43_acc_2: 0.7724 - crf_43_acc_3: 0.7755 - crf_44_acc_1: 0.7722 - crf_44_acc_2: 0.9488 - crf_44_acc_3: 0.7738 - crf_45_acc_1: 0.7751 - crf_45_acc_2: 0.7730 - crf_45_acc_3: 0.9814 - val_loss: -3.5759e-02 - val_crf_43_loss: 0.0072 - val_crf_44_loss: -1.2436e-02 - val_crf_45_loss: -3.0490e-02 - val_crf_43_acc_1: 0.9732 - val_crf_43_acc_2: 0.8129 - val_crf_43_acc_3: 0.8135 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9599 - val_crf_44_acc_3: 0.8153 - val_crf_45_acc_1: 0.8134 - val_crf_45_acc_2: 0.8154 - val_crf_45_acc_3: 0.9904 - val_f1: 0.8613 - val_crf_43_f1: 0.8525 - val_crf_44_f1: 0.7864 - val_crf_45_f1: 0.9451
Epoch 5/25
 - 1706s - loss: -1.7571e-02 - crf_43_loss: 0.0222 - crf_44_loss: -1.0735e-02 - crf_45_loss: -2.9051e-02 - crf_43_acc_1: 0.9571 - crf_43_acc_2: 0.7723 - crf_43_acc_3: 0.7755 - crf_44_acc_1: 0.7722 - crf_44_acc_2: 0.9499 - crf_44_acc_3: 0.7737 - crf_45_acc_1: 0.7751 - crf_45_acc_2: 0.7730 - crf_45_acc_3: 0.9813 - val_loss: -6.9252e-02 - val_crf_43_loss: -5.0467e-03 - val_crf_44_loss: -2.4195e-02 - val_crf_45_loss: -4.0010e-02 - val_crf_43_acc_1: 0.9723 - val_crf_43_acc_2: 0.8129 - val_crf_43_acc_3: 0.8134 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9610 - val_crf_44_acc_3: 0.8153 - val_crf_45_acc_1: 0.8135 - val_crf_45_acc_2: 0.8150 - val_crf_45_acc_3: 0.9883 - val_f1: 0.8612 - val_crf_43_f1: 0.8539 - val_crf_44_f1: 0.7938 - val_crf_45_f1: 0.9357
Epoch 6/25
 - 1706s - loss: -5.4484e-02 - crf_43_loss: 0.0084 - crf_44_loss: -2.3038e-02 - crf_45_loss: -3.9848e-02 - crf_43_acc_1: 0.9582 - crf_43_acc_2: 0.7723 - crf_43_acc_3: 0.7755 - crf_44_acc_1: 0.7722 - crf_44_acc_2: 0.9511 - crf_44_acc_3: 0.7737 - crf_45_acc_1: 0.7752 - crf_45_acc_2: 0.7730 - crf_45_acc_3: 0.9809 - val_loss: -1.0012e-01 - val_crf_43_loss: -1.6583e-02 - val_crf_44_loss: -3.4285e-02 - val_crf_45_loss: -4.9251e-02 - val_crf_43_acc_1: 0.9735 - val_crf_43_acc_2: 0.8129 - val_crf_43_acc_3: 0.8134 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9628 - val_crf_44_acc_3: 0.8154 - val_crf_45_acc_1: 0.8134 - val_crf_45_acc_2: 0.8148 - val_crf_45_acc_3: 0.9860 - val_f1: 0.8594 - val_crf_43_f1: 0.8600 - val_crf_44_f1: 0.8022 - val_crf_45_f1: 0.9160
Epoch 7/25
 - 1708s - loss: -8.8229e-02 - crf_43_loss: -3.7427e-03 - crf_44_loss: -3.4234e-02 - crf_45_loss: -5.0252e-02 - crf_43_acc_1: 0.9590 - crf_43_acc_2: 0.7723 - crf_43_acc_3: 0.7755 - crf_44_acc_1: 0.7722 - crf_44_acc_2: 0.9521 - crf_44_acc_3: 0.7737 - crf_45_acc_1: 0.7753 - crf_45_acc_2: 0.7730 - crf_45_acc_3: 0.9806 - val_loss: -1.3343e-01 - val_crf_43_loss: -2.7313e-02 - val_crf_44_loss: -4.5609e-02 - val_crf_45_loss: -6.0509e-02 - val_crf_43_acc_1: 0.9741 - val_crf_43_acc_2: 0.8130 - val_crf_43_acc_3: 0.8134 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9617 - val_crf_44_acc_3: 0.8152 - val_crf_45_acc_1: 0.8136 - val_crf_45_acc_2: 0.8149 - val_crf_45_acc_3: 0.9854 - val_f1: 0.8559 - val_crf_43_f1: 0.8631 - val_crf_44_f1: 0.7954 - val_crf_45_f1: 0.9092
Epoch 8/25
 - 1708s - loss: -1.1998e-01 - crf_43_loss: -1.4739e-02 - crf_44_loss: -4.4817e-02 - crf_45_loss: -6.0425e-02 - crf_43_acc_1: 0.9597 - crf_43_acc_2: 0.7723 - crf_43_acc_3: 0.7755 - crf_44_acc_1: 0.7722 - crf_44_acc_2: 0.9531 - crf_44_acc_3: 0.7736 - crf_45_acc_1: 0.7753 - crf_45_acc_2: 0.7730 - crf_45_acc_3: 0.9804 - val_loss: -1.6279e-01 - val_crf_43_loss: -3.7166e-02 - val_crf_44_loss: -5.5493e-02 - val_crf_45_loss: -7.0134e-02 - val_crf_43_acc_1: 0.9744 - val_crf_43_acc_2: 0.8130 - val_crf_43_acc_3: 0.8135 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9612 - val_crf_44_acc_3: 0.8153 - val_crf_45_acc_1: 0.8135 - val_crf_45_acc_2: 0.8153 - val_crf_45_acc_3: 0.9853 - val_f1: 0.8556 - val_crf_43_f1: 0.8661 - val_crf_44_f1: 0.7957 - val_crf_45_f1: 0.9050
Epoch 9/25
 - 1704s - loss: -1.5086e-01 - crf_43_loss: -2.5603e-02 - crf_44_loss: -5.4891e-02 - crf_45_loss: -7.0363e-02 - crf_43_acc_1: 0.9605 - crf_43_acc_2: 0.7723 - crf_43_acc_3: 0.7754 - crf_44_acc_1: 0.7722 - crf_44_acc_2: 0.9535 - crf_44_acc_3: 0.7736 - crf_45_acc_1: 0.7753 - crf_45_acc_2: 0.7730 - crf_45_acc_3: 0.9805 - val_loss: -1.9117e-01 - val_crf_43_loss: -4.6091e-02 - val_crf_44_loss: -6.5278e-02 - val_crf_45_loss: -7.9805e-02 - val_crf_43_acc_1: 0.9739 - val_crf_43_acc_2: 0.8130 - val_crf_43_acc_3: 0.8135 - val_crf_44_acc_1: 0.8134 - val_crf_44_acc_2: 0.9615 - val_crf_44_acc_3: 0.8154 - val_crf_45_acc_1: 0.8136 - val_crf_45_acc_2: 0.8148 - val_crf_45_acc_3: 0.9855 - val_f1: 0.8527 - val_crf_43_f1: 0.8621 - val_crf_44_f1: 0.7923 - val_crf_45_f1: 0.9036

-------------------------------------------
Best F1 score: 0.861325967626   (epoch number 4)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5000    0.6667       148
        archivalreference     0.7494    0.7538    0.7516       853
              archive_lib     0.8936    0.8155    0.8528       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9385    0.8949    0.9162      4948
                      box     0.8485    0.5091    0.6364       110
              cartulation     0.1311    1.0000    0.2319         8
              conjunction     0.5287    0.6866    0.5974       134
                     date     0.2532    0.3448    0.2920        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3889    0.5000    0.4375        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1156    0.1667    0.1365       120
                        o     0.2590    0.2301    0.2437       752
               pagination     0.9231    0.9377    0.9303      1139
   publicationnumber-year     0.5433    0.8158    0.6522       646
         publicationplace     0.9202    0.8335    0.8748      1592
publicationspecifications     0.2437    0.1048    0.1466       372
                publisher     0.8739    0.7928    0.8314      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.6596    0.4052    0.5020       153
                    title     0.8999    0.9567    0.9274     15560
                     tomo     1.0000    0.1161    0.2080       224
                   volume     0.4764    0.5090    0.4921       277
                     year     0.9201    0.7809    0.8448      2036

              avg / total     0.9743    0.9732    0.9724    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5000    0.6667       148
        archivalreference     0.7494    0.7538    0.7516       853
              archive_lib     0.8936    0.8155    0.8528       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9385    0.8949    0.9162      4948
                      box     0.8485    0.5091    0.6364       110
              cartulation     0.1311    1.0000    0.2319         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5287    0.6866    0.5974       134
                     date     0.2532    0.3448    0.2920        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3889    0.5000    0.4375        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1156    0.1667    0.1365       120
                        o     0.2590    0.2301    0.2437       752
               pagination     0.9231    0.9377    0.9303      1139
   publicationnumber-year     0.5433    0.8158    0.6522       646
         publicationplace     0.9202    0.8335    0.8748      1592
publicationspecifications     0.2437    0.1048    0.1466       372
                publisher     0.8739    0.7928    0.8314      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.6596    0.4052    0.5020       153
                    title     0.8999    0.9567    0.9274     15560
                     tomo     1.0000    0.1161    0.2080       224
                   volume     0.4764    0.5090    0.4921       277
                     year     0.9201    0.7809    0.8448      2036

              avg / total     0.8628    0.8567    0.8525     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.5937    0.5920    0.5928       348
        b-primary     0.5769    0.1429    0.2290       105
      b-secondary     0.7286    0.5892    0.6515       852
e-meta-annotation     0.8601    0.7418    0.7966      1061
        e-primary     0.7250    0.5800    0.6444       300
      e-secondary     0.8015    0.8136    0.8075      1717
i-meta-annotation     0.7228    0.8586    0.7849      9981
        i-primary     0.8126    0.8258    0.8192      1728
      i-secondary     0.8645    0.7697    0.8143     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2759    0.3372    0.3035       427

      avg / total     0.9616    0.9599    0.9600    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.5937    0.5920    0.5928       348
        b-primary     0.5769    0.1429    0.2290       105
      b-secondary     0.7286    0.5892    0.6515       852
e-meta-annotation     0.8601    0.7418    0.7966      1061
        e-primary     0.7250    0.5800    0.6444       300
      e-secondary     0.8015    0.8136    0.8075      1717
i-meta-annotation     0.7228    0.8586    0.7849      9981
        i-primary     0.8126    0.8258    0.8192      1728
      i-secondary     0.8645    0.7697    0.8143     14357
                o     0.2759    0.3372    0.3035       427

      avg / total     0.7949    0.7861    0.7864     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8213    0.6552    0.7289      1305
        e-r     0.9627    0.5908    0.7323      1310
        i-r     0.9610    0.9889    0.9747     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3402    0.3115    0.3252       427

avg / total     0.9900    0.9904    0.9897    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8213    0.6552    0.7289      1305
        e-r     0.9627    0.5908    0.7323      1310
        i-r     0.9610    0.9889    0.9747     27834
          o     0.3402    0.3115    0.3252       427

avg / total     0.9466    0.9485    0.9451     30876




Confusion matrix, without normalization
[[    36      0    112      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     7      4    833      9      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    13      0     90      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   865      2   4074      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2    108      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2      6      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    132      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      6     52      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      2      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1     26      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      5    113      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     9     14    591    138      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    192    947      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1     17    628      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1590      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2    347     22      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1442      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      1    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   100     12  15410     38      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      3    221      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    539   1323    174      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.43243243e-01   0.00000000e+00   7.56756757e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.20633060e-03   4.68933177e-03   9.76553341e-01   1.05509965e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.26213592e-01   0.00000000e+00   8.73786408e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.74818108e-01   4.04203719e-04   8.23362975e-01   1.41471302e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.81818182e-02   9.81818182e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.50000000e-01   7.50000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.85074627e-01   1.49253731e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.03448276e-01   8.96551724e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.33333333e-01   6.66666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   3.57142857e-02   9.28571429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   4.16666667e-02   9.41666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.19680851e-02   1.86170213e-02   7.85904255e-01   1.83510638e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.68568920e-01   8.31431080e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   2.63157895e-02   9.72136223e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.28140704e-04   9.98743719e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   5.37634409e-03   9.32795699e-01   5.91397849e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   0.00000000e+00   9.99306999e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   6.49350649e-03   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.42673522e-03   7.71208226e-04   9.90359897e-01   2.44215938e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.33928571e-02   9.86607143e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.64734774e-01   6.49803536e-01   8.54616896e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   257      0     52     39      0      0      0      0      0      0
       0]
 [    20      0     85      0      0      0      0      0      0      0
       0]
 [   578      0    171    103      0      0      0      0      0      0
       0]
 [     0    241    820      0      0      0      0      0      0      0
       0]
 [     0     20    274      6      0      0      0      0      0      0
       0]
 [     0    513   1194     10      0      0      0      0      0      0
       0]
 [    52      3   9903     23      0      0      0      0      0      0
       0]
 [     7      9   1701     11      0      0      0      0      0      0
       0]
 [   121     10  14160     66      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     6      8    280    133      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.38505747e-01   0.00000000e+00   1.49425287e-01   1.12068966e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.90476190e-01   0.00000000e+00   8.09523810e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.78403756e-01   0.00000000e+00   2.00704225e-01   1.20892019e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.27144204e-01   7.72855796e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.66666667e-02   9.13333333e-01   2.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.98776937e-01   6.95398952e-01   5.82411182e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.20989881e-03   3.00571085e-04   9.92185152e-01   2.30437832e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.05092593e-03   5.20833333e-03   9.84375000e-01   6.36574074e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.42794456e-03   6.96524344e-04   9.86278470e-01   4.59706067e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.40515222e-02   1.87353630e-02   6.55737705e-01   3.11475410e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   855      0    308      0    142]
 [     0    774    528      0      8]
 [   180     22  27524      0    108]
 [     0      0      0 133958      0]
 [     6      8    280      0    133]]
Normalized confusion matrix
[[  6.55172414e-01   0.00000000e+00   2.36015326e-01   0.00000000e+00
    1.08812261e-01]
 [  0.00000000e+00   5.90839695e-01   4.03053435e-01   0.00000000e+00
    6.10687023e-03]
 [  6.46691097e-03   7.90400230e-04   9.88862542e-01   0.00000000e+00
    3.88014658e-03]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  1.40515222e-02   1.87353630e-02   6.55737705e-01   0.00000000e+00
    3.11475410e-01]]
