______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_34 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_34[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_49 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_33 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_33 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_49[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_33 (Embedding)                         (None, 73, 300)                  17130300          input_33[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_34 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_33[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_17 (Concatenate)                     (None, 73, 3000)                 0                 embedding_33[0][0]                                
                                                                                                    time_distributed_34[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_50 (Dropout)                             (None, 73, 3000)                 0                 concatenate_17[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_34 (Bidirectional)                 (None, 73, 200)                  2480800           dropout_50[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_51 (Dropout)                             (None, 73, 200)                  0                 bidirectional_34[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_49 (Dense)                                 (None, 73, 28)                   5628              dropout_51[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_50 (Dense)                                 (None, 73, 11)                   2211              dropout_51[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_51 (Dense)                                 (None, 73, 5)                    1005              dropout_51[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_49 (CRF)                                     (None, 73, 28)                   1652              dense_49[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_50 (CRF)                                     (None, 73, 11)                   275               dense_50[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_51 (CRF)                                     (None, 73, 5)                    65                dense_51[0][0]                                    
======================================================================================================================================================
Total params: 19,663,636
Trainable params: 19,663,636
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1669s - loss: 0.4409 - crf_49_loss: 0.2152 - crf_50_loss: 0.1599 - crf_51_loss: 0.0658 - crf_49_acc_1: 0.9336 - crf_49_acc_2: 0.7718 - crf_49_acc_3: 0.7759 - crf_50_acc_1: 0.7710 - crf_50_acc_2: 0.9246 - crf_50_acc_3: 0.7744 - crf_51_acc_1: 0.7731 - crf_51_acc_2: 0.7717 - crf_51_acc_3: 0.9708 - val_loss: 0.1315 - val_crf_49_loss: 0.0711 - val_crf_50_loss: 0.0530 - val_crf_51_loss: 0.0074 - val_crf_49_acc_1: 0.9722 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8134 - val_crf_50_acc_2: 0.9587 - val_crf_50_acc_3: 0.8157 - val_crf_51_acc_1: 0.8134 - val_crf_51_acc_2: 0.8151 - val_crf_51_acc_3: 0.9899 - val_f1: 0.8586 - val_crf_49_f1: 0.8495 - val_crf_50_f1: 0.7810 - val_crf_51_f1: 0.9452
Epoch 2/25
 - 1613s - loss: 0.1247 - crf_49_loss: 0.0720 - crf_50_loss: 0.0454 - crf_51_loss: 0.0073 - crf_49_acc_1: 0.9631 - crf_49_acc_2: 0.7723 - crf_49_acc_3: 0.7756 - crf_50_acc_1: 0.7722 - crf_50_acc_2: 0.9534 - crf_50_acc_3: 0.7737 - crf_51_acc_1: 0.7752 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9844 - val_loss: 0.0495 - val_crf_49_loss: 0.0379 - val_crf_50_loss: 0.0196 - val_crf_51_loss: -8.0181e-03 - val_crf_49_acc_1: 0.9744 - val_crf_49_acc_2: 0.8129 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8134 - val_crf_50_acc_2: 0.9617 - val_crf_50_acc_3: 0.8154 - val_crf_51_acc_1: 0.8134 - val_crf_51_acc_2: 0.8153 - val_crf_51_acc_3: 0.9908 - val_f1: 0.8706 - val_crf_49_f1: 0.8635 - val_crf_50_f1: 0.7970 - val_crf_51_f1: 0.9515
Epoch 3/25
 - 1615s - loss: 0.0393 - crf_49_loss: 0.0370 - crf_50_loss: 0.0130 - crf_51_loss: -1.0667e-02 - crf_49_acc_1: 0.9679 - crf_49_acc_2: 0.7723 - crf_49_acc_3: 0.7755 - crf_50_acc_1: 0.7722 - crf_50_acc_2: 0.9595 - crf_50_acc_3: 0.7735 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9862 - val_loss: -7.5008e-03 - val_crf_49_loss: 0.0170 - val_crf_50_loss: -2.1596e-03 - val_crf_51_loss: -2.2389e-02 - val_crf_49_acc_1: 0.9757 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8134 - val_crf_50_acc_1: 0.8134 - val_crf_50_acc_2: 0.9618 - val_crf_50_acc_3: 0.8151 - val_crf_51_acc_1: 0.8136 - val_crf_51_acc_2: 0.8152 - val_crf_51_acc_3: 0.9905 - val_f1: 0.8730 - val_crf_49_f1: 0.8739 - val_crf_50_f1: 0.7957 - val_crf_51_f1: 0.9494
Epoch 4/25
 - 1608s - loss: -1.3377e-02 - crf_49_loss: 0.0162 - crf_50_loss: -5.9145e-03 - crf_51_loss: -2.3647e-02 - crf_49_acc_1: 0.9702 - crf_49_acc_2: 0.7722 - crf_49_acc_3: 0.7754 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9631 - crf_50_acc_3: 0.7735 - crf_51_acc_1: 0.7752 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9871 - val_loss: -4.1572e-02 - val_crf_49_loss: 0.0037 - val_crf_50_loss: -1.4104e-02 - val_crf_51_loss: -3.1121e-02 - val_crf_49_acc_1: 0.9757 - val_crf_49_acc_2: 0.8129 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8134 - val_crf_50_acc_2: 0.9630 - val_crf_50_acc_3: 0.8153 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8149 - val_crf_51_acc_3: 0.9892 - val_f1: 0.8733 - val_crf_49_f1: 0.8748 - val_crf_50_f1: 0.8018 - val_crf_51_f1: 0.9433
Epoch 5/25
 - 1597s - loss: -5.4339e-02 - crf_49_loss: 5.1856e-04 - crf_50_loss: -1.9945e-02 - crf_51_loss: -3.4913e-02 - crf_49_acc_1: 0.9722 - crf_49_acc_2: 0.7722 - crf_49_acc_3: 0.7754 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9659 - crf_50_acc_3: 0.7734 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9874 - val_loss: -7.5763e-02 - val_crf_49_loss: -8.2548e-03 - val_crf_50_loss: -2.5837e-02 - val_crf_51_loss: -4.1671e-02 - val_crf_49_acc_1: 0.9760 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8133 - val_crf_50_acc_2: 0.9636 - val_crf_50_acc_3: 0.8151 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8153 - val_crf_51_acc_3: 0.9900 - val_f1: 0.8747 - val_crf_49_f1: 0.8759 - val_crf_50_f1: 0.8047 - val_crf_51_f1: 0.9435
Epoch 6/25
 - 1604s - loss: -9.0506e-02 - crf_49_loss: -1.2652e-02 - crf_50_loss: -3.2154e-02 - crf_51_loss: -4.5700e-02 - crf_49_acc_1: 0.9738 - crf_49_acc_2: 0.7722 - crf_49_acc_3: 0.7753 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9682 - crf_50_acc_3: 0.7734 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9880 - val_loss: -9.8707e-02 - val_crf_49_loss: -1.5872e-02 - val_crf_50_loss: -3.3831e-02 - val_crf_51_loss: -4.9003e-02 - val_crf_49_acc_1: 0.9755 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8136 - val_crf_50_acc_1: 0.8133 - val_crf_50_acc_2: 0.9621 - val_crf_50_acc_3: 0.8152 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8155 - val_crf_51_acc_3: 0.9867 - val_f1: 0.8704 - val_crf_49_f1: 0.8745 - val_crf_50_f1: 0.8038 - val_crf_51_f1: 0.9330
Epoch 7/25
 - 1608s - loss: -1.2414e-01 - crf_49_loss: -2.4724e-02 - crf_50_loss: -4.3333e-02 - crf_51_loss: -5.6079e-02 - crf_49_acc_1: 0.9751 - crf_49_acc_2: 0.7722 - crf_49_acc_3: 0.7753 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9707 - crf_50_acc_3: 0.7733 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9881 - val_loss: -1.3450e-01 - val_crf_49_loss: -2.7851e-02 - val_crf_50_loss: -4.5962e-02 - val_crf_51_loss: -6.0688e-02 - val_crf_49_acc_1: 0.9761 - val_crf_49_acc_2: 0.8131 - val_crf_49_acc_3: 0.8134 - val_crf_50_acc_1: 0.8134 - val_crf_50_acc_2: 0.9654 - val_crf_50_acc_3: 0.8152 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8155 - val_crf_51_acc_3: 0.9887 - val_f1: 0.8750 - val_crf_49_f1: 0.8752 - val_crf_50_f1: 0.8165 - val_crf_51_f1: 0.9334
Epoch 8/25
 - 1600s - loss: -1.5651e-01 - crf_49_loss: -3.6037e-02 - crf_50_loss: -5.4115e-02 - crf_51_loss: -6.6361e-02 - crf_49_acc_1: 0.9765 - crf_49_acc_2: 0.7721 - crf_49_acc_3: 0.7753 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9727 - crf_50_acc_3: 0.7733 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9881 - val_loss: -1.6112e-01 - val_crf_49_loss: -3.6431e-02 - val_crf_50_loss: -5.4575e-02 - val_crf_51_loss: -7.0113e-02 - val_crf_49_acc_1: 0.9743 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8133 - val_crf_50_acc_2: 0.9630 - val_crf_50_acc_3: 0.8153 - val_crf_51_acc_1: 0.8137 - val_crf_51_acc_2: 0.8151 - val_crf_51_acc_3: 0.9871 - val_f1: 0.8670 - val_crf_49_f1: 0.8700 - val_crf_50_f1: 0.8035 - val_crf_51_f1: 0.9275
Epoch 9/25
 - 1604s - loss: -1.8793e-01 - crf_49_loss: -4.6900e-02 - crf_50_loss: -6.4537e-02 - crf_51_loss: -7.6488e-02 - crf_49_acc_1: 0.9777 - crf_49_acc_2: 0.7721 - crf_49_acc_3: 0.7753 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9743 - crf_50_acc_3: 0.7733 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9882 - val_loss: -1.8441e-01 - val_crf_49_loss: -4.4085e-02 - val_crf_50_loss: -6.2249e-02 - val_crf_51_loss: -7.8078e-02 - val_crf_49_acc_1: 0.9750 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8134 - val_crf_50_acc_2: 0.9633 - val_crf_50_acc_3: 0.8152 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8154 - val_crf_51_acc_3: 0.9853 - val_f1: 0.8659 - val_crf_49_f1: 0.8696 - val_crf_50_f1: 0.8095 - val_crf_51_f1: 0.9187
Epoch 10/25
 - 1602s - loss: -2.1866e-01 - crf_49_loss: -5.7349e-02 - crf_50_loss: -7.4750e-02 - crf_51_loss: -8.6564e-02 - crf_49_acc_1: 0.9786 - crf_49_acc_2: 0.7721 - crf_49_acc_3: 0.7753 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9760 - crf_50_acc_3: 0.7733 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9883 - val_loss: -2.1394e-01 - val_crf_49_loss: -5.4826e-02 - val_crf_50_loss: -7.1321e-02 - val_crf_51_loss: -8.7793e-02 - val_crf_49_acc_1: 0.9757 - val_crf_49_acc_2: 0.8129 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8134 - val_crf_50_acc_2: 0.9611 - val_crf_50_acc_3: 0.8153 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8153 - val_crf_51_acc_3: 0.9858 - val_f1: 0.8619 - val_crf_49_f1: 0.8737 - val_crf_50_f1: 0.7973 - val_crf_51_f1: 0.9147
Epoch 11/25
 - 1619s - loss: -2.4932e-01 - crf_49_loss: -6.7761e-02 - crf_50_loss: -8.4923e-02 - crf_51_loss: -9.6637e-02 - crf_49_acc_1: 0.9795 - crf_49_acc_2: 0.7721 - crf_49_acc_3: 0.7753 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9774 - crf_50_acc_3: 0.7732 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9884 - val_loss: -2.3923e-01 - val_crf_49_loss: -6.2296e-02 - val_crf_50_loss: -7.9832e-02 - val_crf_51_loss: -9.7106e-02 - val_crf_49_acc_1: 0.9734 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8136 - val_crf_50_acc_1: 0.8133 - val_crf_50_acc_2: 0.9575 - val_crf_50_acc_3: 0.8153 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8150 - val_crf_51_acc_3: 0.9831 - val_f1: 0.8469 - val_crf_49_f1: 0.8676 - val_crf_50_f1: 0.7744 - val_crf_51_f1: 0.8988
Epoch 12/25
 - 1606s - loss: -2.7929e-01 - crf_49_loss: -7.7664e-02 - crf_50_loss: -9.5007e-02 - crf_51_loss: -1.0662e-01 - crf_49_acc_1: 0.9804 - crf_49_acc_2: 0.7721 - crf_49_acc_3: 0.7753 - crf_50_acc_1: 0.7721 - crf_50_acc_2: 0.9787 - crf_50_acc_3: 0.7732 - crf_51_acc_1: 0.7753 - crf_51_acc_2: 0.7731 - crf_51_acc_3: 0.9887 - val_loss: -2.6683e-01 - val_crf_49_loss: -7.0712e-02 - val_crf_50_loss: -8.9754e-02 - val_crf_51_loss: -1.0636e-01 - val_crf_49_acc_1: 0.9746 - val_crf_49_acc_2: 0.8130 - val_crf_49_acc_3: 0.8135 - val_crf_50_acc_1: 0.8133 - val_crf_50_acc_2: 0.9630 - val_crf_50_acc_3: 0.8154 - val_crf_51_acc_1: 0.8135 - val_crf_51_acc_2: 0.8151 - val_crf_51_acc_3: 0.9839 - val_f1: 0.8596 - val_crf_49_f1: 0.8718 - val_crf_50_f1: 0.8055 - val_crf_51_f1: 0.9015

-------------------------------------------
Best F1 score: 0.875021278809   (epoch number 7)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.8913    0.5541    0.6833       148
        archivalreference     0.8053    0.7902    0.7976       853
              archive_lib     0.8235    0.8155    0.8195       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9465    0.9153    0.9306      4948
                      box     0.7805    0.2909    0.4238       110
              cartulation     0.3636    1.0000    0.5333         8
              conjunction     0.5093    0.8134    0.6264       134
                     date     0.4545    0.7759    0.5732        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2250    0.6429    0.3333        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1920    0.2000    0.1959       120
                        o     0.2822    0.3178    0.2989       752
               pagination     0.9499    0.9148    0.9320      1139
   publicationnumber-year     0.6581    0.8344    0.7358       646
         publicationplace     0.9322    0.8807    0.9057      1592
publicationspecifications     0.3295    0.4624    0.3848       372
                publisher     0.9203    0.8247    0.8699      1443
                      ref     0.1000    0.6667    0.1739         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.9225    0.7778    0.8440       153
                    title     0.9274    0.9469    0.9370     15560
                     tomo     0.9351    0.3214    0.4784       224
                   volume     0.5143    0.5199    0.5171       277
                     year     0.9146    0.8099    0.8591      2036

              avg / total     0.9789    0.9761    0.9766    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.8913    0.5541    0.6833       148
        archivalreference     0.8053    0.7902    0.7976       853
              archive_lib     0.8235    0.8155    0.8195       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9465    0.9153    0.9306      4948
                      box     0.7805    0.2909    0.4238       110
              cartulation     0.3636    1.0000    0.5333         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5093    0.8134    0.6264       134
                     date     0.4545    0.7759    0.5732        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2250    0.6429    0.3333        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1920    0.2000    0.1959       120
                        o     0.2822    0.3178    0.2989       752
               pagination     0.9499    0.9148    0.9320      1139
   publicationnumber-year     0.6581    0.8344    0.7358       646
         publicationplace     0.9322    0.8807    0.9057      1592
publicationspecifications     0.3295    0.4624    0.3848       372
                publisher     0.9203    0.8247    0.8699      1443
                      ref     0.1000    0.6667    0.1739         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.9225    0.7778    0.8440       153
                    title     0.9274    0.9469    0.9370     15560
                     tomo     0.9351    0.3214    0.4784       224
                   volume     0.5143    0.5199    0.5171       277
                     year     0.9146    0.8099    0.8591      2036

              avg / total     0.8875    0.8725    0.8752     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6593    0.6839    0.6714       348
        b-primary     0.7885    0.3905    0.5223       105
      b-secondary     0.7605    0.6373    0.6935       852
e-meta-annotation     0.8493    0.7597    0.8020      1061
        e-primary     0.6857    0.5600    0.6165       300
      e-secondary     0.8401    0.8538    0.8469      1717
i-meta-annotation     0.7780    0.8428    0.8091      9981
        i-primary     0.8344    0.7784    0.8054      1728
      i-secondary     0.8691    0.8345    0.8514     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2988    0.4192    0.3489       427

      avg / total     0.9663    0.9654    0.9656    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6593    0.6839    0.6714       348
        b-primary     0.7885    0.3905    0.5223       105
      b-secondary     0.7605    0.6373    0.6935       852
e-meta-annotation     0.8493    0.7597    0.8020      1061
        e-primary     0.6857    0.5600    0.6165       300
      e-secondary     0.8401    0.8538    0.8469      1717
i-meta-annotation     0.7780    0.8428    0.8091      9981
        i-primary     0.8344    0.7784    0.8054      1728
      i-secondary     0.8691    0.8345    0.8514     14357
                o     0.2988    0.4192    0.3489       427

      avg / total     0.8201    0.8155    0.8165     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8307    0.7218    0.7724      1305
        e-r     0.9293    0.3412    0.4992      1310
        i-r     0.9543    0.9864    0.9701     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3381    0.3888    0.3617       427

avg / total     0.9887    0.9887    0.9875    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8307    0.7218    0.7724      1305
        e-r     0.9293    0.3412    0.4992      1310
        i-r     0.9543    0.9864    0.9701     27834
          o     0.3381    0.3888    0.3617       427

avg / total     0.9395    0.9396    0.9334     30876




Confusion matrix, without normalization
[[    36      0    112      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    35     14    790     14      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    16      0     76     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   895      2   4017     34      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      7      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    132      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     28      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     11      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3    112      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    12      3    547    190      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    145    990      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      6    635      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1   1586      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    355     17      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1442      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     3      0    151      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   126      4  15385     45      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2    274      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     7    298   1570    161      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.43243243e-01   0.00000000e+00   7.56756757e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.10316530e-02   1.64126612e-02   9.26143025e-01   1.64126612e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.55339806e-01   0.00000000e+00   7.37864078e-01   1.06796117e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.80881164e-01   4.04203719e-04   8.11843169e-01   6.87146322e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.25000000e-01   8.75000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.85074627e-01   1.49253731e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.33333333e-02   9.16666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.33333333e-03   2.50000000e-02   9.33333333e-01   3.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.59574468e-02   3.98936170e-03   7.27393617e-01   2.52659574e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.27304653e-01   8.69183494e-01   3.51185250e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   9.28792570e-03   9.82972136e-01   6.19195046e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   6.28140704e-04   9.96231156e-01   2.51256281e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.54301075e-01   4.56989247e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   0.00000000e+00   9.99306999e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.94805195e-02   0.00000000e+00   9.80519481e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.09768638e-03   2.57069409e-04   9.88753213e-01   2.89203085e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   7.22021661e-03   9.89169675e-01   3.61010830e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.43811395e-03   1.46365422e-01   7.71119843e-01   7.90766208e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   276      0     35     37      0      0      0      0      0      0
       0]
 [    49      0     54      2      0      0      0      0      0      0
       0]
 [   617      0    123    112      0      0      0      0      0      0
       0]
 [     0    164    889      8      0      0      0      0      0      0
       0]
 [     1      4    285     10      0      0      0      0      0      0
       0]
 [     0    279   1430      8      0      0      0      0      0      0
       0]
 [    46      3   9901     31      0      0      0      0      0      0
       0]
 [    15     19   1645     49      0      0      0      0      0      0
       0]
 [   122      9  14158     68      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     8      3    250    166      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.93103448e-01   0.00000000e+00   1.00574713e-01   1.06321839e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.66666667e-01   0.00000000e+00   5.14285714e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.24178404e-01   0.00000000e+00   1.44366197e-01   1.31455399e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.54571159e-01   8.37888784e-01   7.54005655e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.33333333e-03   1.33333333e-02   9.50000000e-01   3.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.62492720e-01   8.32847991e-01   4.65928946e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.60875664e-03   3.00571085e-04   9.91984771e-01   3.10590121e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.68055556e-03   1.09953704e-02   9.51967593e-01   2.83564815e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.49759699e-03   6.26871909e-04   9.86139166e-01   4.73636554e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.87353630e-02   7.02576112e-03   5.85480094e-01   3.88758782e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   942      0    212      0    151]
 [     0    447    852      0     11]
 [   184     31  27456      0    163]
 [     0      0      0 133958      0]
 [     8      3    250      0    166]]
Normalized confusion matrix
[[ 0.72183908  0.          0.16245211  0.          0.11570881]
 [ 0.          0.34122137  0.65038168  0.          0.00839695]
 [ 0.00661062  0.00111375  0.98641949  0.          0.00585615]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.01873536  0.00702576  0.58548009  0.          0.38875878]]
