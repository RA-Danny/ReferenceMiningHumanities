______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_2 (InputLayer)                             (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_2[0][0]                                     
______________________________________________________________________________________________________________________________________________________
dropout_1 (Dropout)                              (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_1 (InputLayer)                             (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_1 (TimeDistributed)             (None, 73, 54, 50)               25200             dropout_1[0][0]                                   
______________________________________________________________________________________________________________________________________________________
embedding_1 (Embedding)                          (None, 73, 300)                  17130300          input_1[0][0]                                     
______________________________________________________________________________________________________________________________________________________
time_distributed_2 (TimeDistributed)             (None, 73, 2700)                 0                 time_distributed_1[0][0]                          
______________________________________________________________________________________________________________________________________________________
concatenate_1 (Concatenate)                      (None, 73, 3000)                 0                 embedding_1[0][0]                                 
                                                                                                    time_distributed_2[0][0]                          
______________________________________________________________________________________________________________________________________________________
dropout_2 (Dropout)                              (None, 73, 3000)                 0                 concatenate_1[0][0]                               
______________________________________________________________________________________________________________________________________________________
bidirectional_2 (Bidirectional)                  (None, 73, 400)                  5121600           dropout_2[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dropout_3 (Dropout)                              (None, 73, 400)                  0                 bidirectional_2[0][0]                             
______________________________________________________________________________________________________________________________________________________
dense_1 (Dense)                                  (None, 73, 28)                   11228             dropout_3[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dense_2 (Dense)                                  (None, 73, 11)                   4411              dropout_3[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dense_3 (Dense)                                  (None, 73, 5)                    2005              dropout_3[0][0]                                   
______________________________________________________________________________________________________________________________________________________
crf_1 (CRF)                                      (None, 73, 28)                   1652              dense_1[0][0]                                     
______________________________________________________________________________________________________________________________________________________
crf_2 (CRF)                                      (None, 73, 11)                   275               dense_2[0][0]                                     
______________________________________________________________________________________________________________________________________________________
crf_3 (CRF)                                      (None, 73, 5)                    65                dense_3[0][0]                                     
======================================================================================================================================================
Total params: 22,313,236
Trainable params: 22,313,236
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1504s - loss: 0.6568 - crf_1_loss: 0.3055 - crf_2_loss: 0.2552 - crf_3_loss: 0.0961 - crf_1_acc_1: 0.9061 - crf_1_acc_2: 0.7708 - crf_1_acc_3: 0.7735 - crf_2_acc_1: 0.7705 - crf_2_acc_2: 0.8984 - crf_2_acc_3: 0.7724 - crf_3_acc_1: 0.7720 - crf_3_acc_2: 0.7704 - crf_3_acc_3: 0.9578 - val_loss: 0.2481 - val_crf_1_loss: 0.1274 - val_crf_2_loss: 0.1024 - val_crf_3_loss: 0.0182 - val_crf_1_acc_1: 0.9506 - val_crf_1_acc_2: 0.8130 - val_crf_1_acc_3: 0.8134 - val_crf_2_acc_1: 0.8131 - val_crf_2_acc_2: 0.9459 - val_crf_2_acc_3: 0.8154 - val_crf_3_acc_1: 0.8130 - val_crf_3_acc_2: 0.8145 - val_crf_3_acc_3: 0.9897 - val_f1: 0.7780 - val_crf_1_f1: 0.6945 - val_crf_2_f1: 0.6981 - val_crf_3_f1: 0.9414
Epoch 2/25
 - 1477s - loss: 0.2642 - crf_1_loss: 0.1369 - crf_2_loss: 0.0996 - crf_3_loss: 0.0277 - crf_1_acc_1: 0.9417 - crf_1_acc_2: 0.7725 - crf_1_acc_3: 0.7759 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9371 - crf_2_acc_3: 0.7741 - crf_3_acc_1: 0.7745 - crf_3_acc_2: 0.7730 - crf_3_acc_3: 0.9767 - val_loss: 0.1292 - val_crf_1_loss: 0.0700 - val_crf_2_loss: 0.0511 - val_crf_3_loss: 0.0081 - val_crf_1_acc_1: 0.9624 - val_crf_1_acc_2: 0.8134 - val_crf_1_acc_3: 0.8134 - val_crf_2_acc_1: 0.8133 - val_crf_2_acc_2: 0.9528 - val_crf_2_acc_3: 0.8148 - val_crf_3_acc_1: 0.8131 - val_crf_3_acc_2: 0.8154 - val_crf_3_acc_3: 0.9849 - val_f1: 0.8306 - val_crf_1_f1: 0.8043 - val_crf_2_f1: 0.7551 - val_crf_3_f1: 0.9325
Epoch 3/25
 - 1474s - loss: 0.1455 - crf_1_loss: 0.0865 - crf_2_loss: 0.0507 - crf_3_loss: 0.0084 - crf_1_acc_1: 0.9504 - crf_1_acc_2: 0.7724 - crf_1_acc_3: 0.7758 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9442 - crf_2_acc_3: 0.7739 - crf_3_acc_1: 0.7748 - crf_3_acc_2: 0.7731 - crf_3_acc_3: 0.9790 - val_loss: 0.0570 - val_crf_1_loss: 0.0403 - val_crf_2_loss: 0.0215 - val_crf_3_loss: -4.8110e-03 - val_crf_1_acc_1: 0.9681 - val_crf_1_acc_2: 0.8133 - val_crf_1_acc_3: 0.8133 - val_crf_2_acc_1: 0.8134 - val_crf_2_acc_2: 0.9601 - val_crf_2_acc_3: 0.8152 - val_crf_3_acc_1: 0.8133 - val_crf_3_acc_2: 0.8153 - val_crf_3_acc_3: 0.9873 - val_f1: 0.8568 - val_crf_1_f1: 0.8359 - val_crf_2_f1: 0.7962 - val_crf_3_f1: 0.9383
Epoch 4/25
 - 1472s - loss: 0.0790 - crf_1_loss: 0.0583 - crf_2_loss: 0.0247 - crf_3_loss: -3.9803e-03 - crf_1_acc_1: 0.9544 - crf_1_acc_2: 0.7724 - crf_1_acc_3: 0.7756 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9478 - crf_2_acc_3: 0.7738 - crf_3_acc_1: 0.7750 - crf_3_acc_2: 0.7731 - crf_3_acc_3: 0.9801 - val_loss: 0.0102 - val_crf_1_loss: 0.0224 - val_crf_2_loss: 0.0032 - val_crf_3_loss: -1.5325e-02 - val_crf_1_acc_1: 0.9711 - val_crf_1_acc_2: 0.8134 - val_crf_1_acc_3: 0.8134 - val_crf_2_acc_1: 0.8134 - val_crf_2_acc_2: 0.9624 - val_crf_2_acc_3: 0.8151 - val_crf_3_acc_1: 0.8134 - val_crf_3_acc_2: 0.8151 - val_crf_3_acc_3: 0.9906 - val_f1: 0.8647 - val_crf_1_f1: 0.8460 - val_crf_2_f1: 0.8002 - val_crf_3_f1: 0.9479
Epoch 5/25
 - 1468s - loss: 0.0343 - crf_1_loss: 0.0399 - crf_2_loss: 0.0082 - crf_3_loss: -1.3829e-02 - crf_1_acc_1: 0.9567 - crf_1_acc_2: 0.7723 - crf_1_acc_3: 0.7755 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9495 - crf_2_acc_3: 0.7737 - crf_3_acc_1: 0.7750 - crf_3_acc_2: 0.7731 - crf_3_acc_3: 0.9807 - val_loss: -1.2298e-02 - val_crf_1_loss: 0.0097 - val_crf_2_loss: -1.8638e-03 - val_crf_3_loss: -2.0088e-02 - val_crf_1_acc_1: 0.9717 - val_crf_1_acc_2: 0.8133 - val_crf_1_acc_3: 0.8134 - val_crf_2_acc_1: 0.8134 - val_crf_2_acc_2: 0.9488 - val_crf_2_acc_3: 0.8151 - val_crf_3_acc_1: 0.8134 - val_crf_3_acc_2: 0.8149 - val_crf_3_acc_3: 0.9836 - val_f1: 0.8355 - val_crf_1_f1: 0.8560 - val_crf_2_f1: 0.7254 - val_crf_3_f1: 0.9250
Epoch 6/25
 - 1470s - loss: 4.8173e-04 - crf_1_loss: 0.0262 - crf_2_loss: -3.5580e-03 - crf_3_loss: -2.2203e-02 - crf_1_acc_1: 0.9582 - crf_1_acc_2: 0.7723 - crf_1_acc_3: 0.7755 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9499 - crf_2_acc_3: 0.7737 - crf_3_acc_1: 0.7751 - crf_3_acc_2: 0.7731 - crf_3_acc_3: 0.9806 - val_loss: -4.2934e-02 - val_crf_1_loss: -1.8715e-04 - val_crf_2_loss: -1.4163e-02 - val_crf_3_loss: -2.8584e-02 - val_crf_1_acc_1: 0.9719 - val_crf_1_acc_2: 0.8132 - val_crf_1_acc_3: 0.8134 - val_crf_2_acc_1: 0.8134 - val_crf_2_acc_2: 0.9484 - val_crf_2_acc_3: 0.8152 - val_crf_3_acc_1: 0.8135 - val_crf_3_acc_2: 0.8160 - val_crf_3_acc_3: 0.9860 - val_f1: 0.8360 - val_crf_1_f1: 0.8573 - val_crf_2_f1: 0.7253 - val_crf_3_f1: 0.9253
Epoch 7/25
 - 1485s - loss: -2.8318e-02 - crf_1_loss: 0.0151 - crf_2_loss: -1.3431e-02 - crf_3_loss: -2.9986e-02 - crf_1_acc_1: 0.9594 - crf_1_acc_2: 0.7723 - crf_1_acc_3: 0.7755 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9516 - crf_2_acc_3: 0.7736 - crf_3_acc_1: 0.7752 - crf_3_acc_2: 0.7731 - crf_3_acc_3: 0.9807 - val_loss: -7.4549e-02 - val_crf_1_loss: -1.1049e-02 - val_crf_2_loss: -2.5831e-02 - val_crf_3_loss: -3.7669e-02 - val_crf_1_acc_1: 0.9757 - val_crf_1_acc_2: 0.8131 - val_crf_1_acc_3: 0.8134 - val_crf_2_acc_1: 0.8134 - val_crf_2_acc_2: 0.9584 - val_crf_2_acc_3: 0.8151 - val_crf_3_acc_1: 0.8134 - val_crf_3_acc_2: 0.8150 - val_crf_3_acc_3: 0.9888 - val_f1: 0.8595 - val_crf_1_f1: 0.8732 - val_crf_2_f1: 0.7715 - val_crf_3_f1: 0.9339
Epoch 8/25
 - 1480s - loss: -5.4095e-02 - crf_1_loss: 0.0055 - crf_2_loss: -2.2064e-02 - crf_3_loss: -3.7519e-02 - crf_1_acc_1: 0.9601 - crf_1_acc_2: 0.7723 - crf_1_acc_3: 0.7755 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9519 - crf_2_acc_3: 0.7736 - crf_3_acc_1: 0.7752 - crf_3_acc_2: 0.7730 - crf_3_acc_3: 0.9806 - val_loss: -9.0193e-02 - val_crf_1_loss: -1.6594e-02 - val_crf_2_loss: -3.1287e-02 - val_crf_3_loss: -4.2312e-02 - val_crf_1_acc_1: 0.9752 - val_crf_1_acc_2: 0.8130 - val_crf_1_acc_3: 0.8135 - val_crf_2_acc_1: 0.8133 - val_crf_2_acc_2: 0.9579 - val_crf_2_acc_3: 0.8153 - val_crf_3_acc_1: 0.8134 - val_crf_3_acc_2: 0.8152 - val_crf_3_acc_3: 0.9832 - val_f1: 0.8539 - val_crf_1_f1: 0.8684 - val_crf_2_f1: 0.7796 - val_crf_3_f1: 0.9138
Epoch 9/25
 - 1484s - loss: -7.7850e-02 - crf_1_loss: -3.0284e-03 - crf_2_loss: -3.0103e-02 - crf_3_loss: -4.4719e-02 - crf_1_acc_1: 0.9607 - crf_1_acc_2: 0.7723 - crf_1_acc_3: 0.7755 - crf_2_acc_1: 0.7722 - crf_2_acc_2: 0.9529 - crf_2_acc_3: 0.7736 - crf_3_acc_1: 0.7752 - crf_3_acc_2: 0.7730 - crf_3_acc_3: 0.9804 - val_loss: -1.1768e-01 - val_crf_1_loss: -2.5637e-02 - val_crf_2_loss: -4.0808e-02 - val_crf_3_loss: -5.1237e-02 - val_crf_1_acc_1: 0.9755 - val_crf_1_acc_2: 0.8132 - val_crf_1_acc_3: 0.8134 - val_crf_2_acc_1: 0.8134 - val_crf_2_acc_2: 0.9636 - val_crf_2_acc_3: 0.8151 - val_crf_3_acc_1: 0.8136 - val_crf_3_acc_2: 0.8153 - val_crf_3_acc_3: 0.9852 - val_f1: 0.8617 - val_crf_1_f1: 0.8721 - val_crf_2_f1: 0.8084 - val_crf_3_f1: 0.9045

-------------------------------------------
Best F1 score: 0.864698453262   (epoch number 4)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.4865    0.6545       148
        archivalreference     0.6540    0.8441    0.7369       853
              archive_lib     0.9048    0.5534    0.6867       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9105    0.9151    0.9128      4948
                      box     0.8361    0.4636    0.5965       110
              cartulation     0.1702    1.0000    0.2909         8
              conjunction     0.5266    0.7388    0.6149       134
                     date     0.4077    0.9138    0.5638        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3673    0.6429    0.4675        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1590    0.3750    0.2233       120
                        o     0.1886    0.2553    0.2169       752
               pagination     0.9141    0.9535    0.9334      1139
   publicationnumber-year     0.7349    0.5666    0.6399       646
         publicationplace     0.9366    0.8442    0.8880      1592
publicationspecifications     0.1833    0.0591    0.0894       372
                publisher     0.8111    0.8510    0.8306      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.5479    0.2614    0.3540       153
                    title     0.9161    0.9260    0.9211     15560
                     tomo     0.8750    0.0625    0.1167       224
                   volume     0.4597    0.5560    0.5033       277
                     year     0.9213    0.7706    0.8393      2036

              avg / total     0.9739    0.9711    0.9712    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.4865    0.6545       148
        archivalreference     0.6540    0.8441    0.7369       853
              archive_lib     0.9048    0.5534    0.6867       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9105    0.9151    0.9128      4948
                      box     0.8361    0.4636    0.5965       110
              cartulation     0.1702    1.0000    0.2909         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5266    0.7388    0.6149       134
                     date     0.4077    0.9138    0.5638        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3673    0.6429    0.4675        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1590    0.3750    0.2233       120
                        o     0.1886    0.2553    0.2169       752
               pagination     0.9141    0.9535    0.9334      1139
   publicationnumber-year     0.7349    0.5666    0.6399       646
         publicationplace     0.9366    0.8442    0.8880      1592
publicationspecifications     0.1833    0.0591    0.0894       372
                publisher     0.8111    0.8510    0.8306      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.5479    0.2614    0.3540       153
                    title     0.9161    0.9260    0.9211     15560
                     tomo     0.8750    0.0625    0.1167       224
                   volume     0.4597    0.5560    0.5033       277
                     year     0.9213    0.7706    0.8393      2036

              avg / total     0.8605    0.8455    0.8460     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7011    0.5259    0.6010       348
        b-primary     0.8393    0.8952    0.8664       105
      b-secondary     0.7004    0.6831    0.6916       852
e-meta-annotation     0.8713    0.7210    0.7891      1061
        e-primary     0.6594    0.7033    0.6806       300
      e-secondary     0.8323    0.8264    0.8293      1717
i-meta-annotation     0.8194    0.7223    0.7678      9981
        i-primary     0.7688    0.8947    0.8270      1728
      i-secondary     0.8225    0.8710    0.8461     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2061    0.3653    0.2635       427

      avg / total     0.9636    0.9624    0.9626    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7011    0.5259    0.6010       348
        b-primary     0.8393    0.8952    0.8664       105
      b-secondary     0.7004    0.6831    0.6916       852
e-meta-annotation     0.8713    0.7210    0.7891      1061
        e-primary     0.6594    0.7033    0.6806       300
      e-secondary     0.8323    0.8264    0.8293      1717
i-meta-annotation     0.8194    0.7223    0.7678      9981
        i-primary     0.7688    0.8947    0.8270      1728
      i-secondary     0.8225    0.8710    0.8461     14357
                o     0.2061    0.3653    0.2635       427

      avg / total     0.8059    0.7990    0.8002     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8316    0.7341    0.7798      1305
        e-r     0.9625    0.5679    0.7144      1310
        i-r     0.9650    0.9864    0.9756     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3460    0.4052    0.3732       427

avg / total     0.9908    0.9906    0.9902    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8316    0.7341    0.7798      1305
        e-r     0.9625    0.5679    0.7144      1310
        i-r     0.9650    0.9864    0.9756     27834
          o     0.3460    0.4052    0.3732       427

avg / total     0.9507    0.9500    0.9479     30876




Confusion matrix, without normalization
[[    36      0    112      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    72      3    775      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    19      0     84      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   897      1   4035     15      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2    108      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      7      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    130      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      4     54      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     28      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      6    106      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     9     10    557    176      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1    187    947      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2     15    623      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1   1589      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2    346     23      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1443      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      1    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   107      9  15367     77      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      3    221      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    528   1323    185      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.43243243e-01   0.00000000e+00   7.56756757e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.44079719e-02   3.51699883e-03   9.08558030e-01   3.51699883e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.84466019e-01   0.00000000e+00   8.15533981e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.81285368e-01   2.02101859e-04   8.15481002e-01   3.03152789e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.81818182e-02   9.81818182e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.25000000e-01   8.75000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.70149254e-01   2.98507463e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.89655172e-02   9.31034483e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   5.00000000e-02   8.83333333e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.19680851e-02   1.32978723e-02   7.40691489e-01   2.34042553e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   1.64179104e-01   8.31431080e-01   3.51185250e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.09597523e-03   2.32198142e-02   9.64396285e-01   9.28792570e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   6.28140704e-04   9.98115578e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   5.37634409e-03   9.30107527e-01   6.18279570e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   6.49350649e-03   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.87660668e-03   5.78406170e-04   9.87596401e-01   4.94858612e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.33928571e-02   9.86607143e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.59332024e-01   6.49803536e-01   9.08644401e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   258      0     50     40      0      0      0      0      0      0
       0]
 [    88      0     17      0      0      0      0      0      0      0
       0]
 [   612      0    130    110      0      0      0      0      0      0
       0]
 [     1    228    828      4      0      0      0      0      0      0
       0]
 [     0     17    280      3      0      0      0      0      0      0
       0]
 [     0    499   1200     18      0      0      0      0      0      0
       0]
 [    58      7   9861     55      0      0      0      0      0      0
       0]
 [     9      6   1704      9      0      0      0      0      0      0
       0]
 [   122     10  14137     88      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     4      6    244    173      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.41379310e-01   0.00000000e+00   1.43678161e-01   1.14942529e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.38095238e-01   0.00000000e+00   1.61904762e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.18309859e-01   0.00000000e+00   1.52582160e-01   1.29107981e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.42507069e-04   2.14891612e-01   7.80395853e-01   3.77002828e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   5.66666667e-02   9.33333333e-01   1.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.90623180e-01   6.98893419e-01   1.04834013e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.81104098e-03   7.01332532e-04   9.87977157e-01   5.51046989e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.20833333e-03   3.47222222e-03   9.86111111e-01   5.20833333e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.49759699e-03   6.96524344e-04   9.84676464e-01   6.12941422e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  9.36768150e-03   1.40515222e-02   5.71428571e-01   4.05152225e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   958      0    197      0    150]
 [     0    744    554      0     12]
 [   190     23  27456      0    165]
 [     0      0      0 133958      0]
 [     4      6    244      0    173]]
Normalized confusion matrix
[[  7.34099617e-01   0.00000000e+00   1.50957854e-01   0.00000000e+00
    1.14942529e-01]
 [  0.00000000e+00   5.67938931e-01   4.22900763e-01   0.00000000e+00
    9.16030534e-03]
 [  6.82618380e-03   8.26327513e-04   9.86419487e-01   0.00000000e+00
    5.92800172e-03]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  9.36768150e-03   1.40515222e-02   5.71428571e-01   0.00000000e+00
    4.05152225e-01]]
