______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_38 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_38[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_55 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_37 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_37 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_55[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_37 (Embedding)                         (None, 73, 300)                  17130300          input_37[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_38 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_37[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_19 (Concatenate)                     (None, 73, 3000)                 0                 embedding_37[0][0]                                
                                                                                                    time_distributed_38[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_56 (Dropout)                             (None, 73, 3000)                 0                 concatenate_19[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_38 (Bidirectional)                 (None, 73, 400)                  5121600           dropout_56[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_57 (Dropout)                             (None, 73, 400)                  0                 bidirectional_38[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_55 (Dense)                                 (None, 73, 28)                   11228             dropout_57[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_56 (Dense)                                 (None, 73, 11)                   4411              dropout_57[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_57 (Dense)                                 (None, 73, 5)                    2005              dropout_57[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_55 (CRF)                                     (None, 73, 28)                   1652              dense_55[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_56 (CRF)                                     (None, 73, 11)                   275               dense_56[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_57 (CRF)                                     (None, 73, 5)                    65                dense_57[0][0]                                    
======================================================================================================================================================
Total params: 22,313,236
Trainable params: 22,313,236
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 2663s - loss: 0.3981 - crf_55_loss: 0.2050 - crf_56_loss: 0.1418 - crf_57_loss: 0.0513 - crf_55_acc_1: 0.9234 - crf_55_acc_2: 0.7720 - crf_55_acc_3: 0.7755 - crf_56_acc_1: 0.7716 - crf_56_acc_2: 0.9167 - crf_56_acc_3: 0.7740 - crf_57_acc_1: 0.7734 - crf_57_acc_2: 0.7721 - crf_57_acc_3: 0.9678 - val_loss: 0.0684 - val_crf_55_loss: 0.0533 - val_crf_56_loss: 0.0239 - val_crf_57_loss: -8.8406e-03 - val_crf_55_acc_1: 0.9627 - val_crf_55_acc_2: 0.8133 - val_crf_55_acc_3: 0.8135 - val_crf_56_acc_1: 0.8133 - val_crf_56_acc_2: 0.9493 - val_crf_56_acc_3: 0.8151 - val_crf_57_acc_1: 0.8132 - val_crf_57_acc_2: 0.8148 - val_crf_57_acc_3: 0.9898 - val_f1: 0.8240 - val_crf_55_f1: 0.8033 - val_crf_56_f1: 0.7215 - val_crf_57_f1: 0.9471
Epoch 2/25
 - 2675s - loss: 0.0568 - crf_55_loss: 0.0571 - crf_56_loss: 0.0136 - crf_57_loss: -1.3932e-02 - crf_55_acc_1: 0.9488 - crf_55_acc_2: 0.7725 - crf_55_acc_3: 0.7758 - crf_56_acc_1: 0.7722 - crf_56_acc_2: 0.9403 - crf_56_acc_3: 0.7739 - crf_57_acc_1: 0.7749 - crf_57_acc_2: 0.7731 - crf_57_acc_3: 0.9781 - val_loss: -4.3471e-02 - val_crf_55_loss: 0.0074 - val_crf_56_loss: -1.6293e-02 - val_crf_57_loss: -3.4598e-02 - val_crf_55_acc_1: 0.9700 - val_crf_55_acc_2: 0.8131 - val_crf_55_acc_3: 0.8134 - val_crf_56_acc_1: 0.8134 - val_crf_56_acc_2: 0.9598 - val_crf_56_acc_3: 0.8153 - val_crf_57_acc_1: 0.8136 - val_crf_57_acc_2: 0.8149 - val_crf_57_acc_3: 0.9877 - val_f1: 0.8546 - val_crf_55_f1: 0.8399 - val_crf_56_f1: 0.7887 - val_crf_57_f1: 0.9351
Epoch 3/25
 - 2608s - loss: -4.5041e-02 - crf_55_loss: 0.0159 - crf_56_loss: -2.0460e-02 - crf_57_loss: -4.0492e-02 - crf_55_acc_1: 0.9534 - crf_55_acc_2: 0.7724 - crf_55_acc_3: 0.7756 - crf_56_acc_1: 0.7722 - crf_56_acc_2: 0.9440 - crf_56_acc_3: 0.7737 - crf_57_acc_1: 0.7751 - crf_57_acc_2: 0.7731 - crf_57_acc_3: 0.9786 - val_loss: -1.2185e-01 - val_crf_55_loss: -2.0743e-02 - val_crf_56_loss: -4.2395e-02 - val_crf_57_loss: -5.8717e-02 - val_crf_55_acc_1: 0.9711 - val_crf_55_acc_2: 0.8132 - val_crf_55_acc_3: 0.8134 - val_crf_56_acc_1: 0.8134 - val_crf_56_acc_2: 0.9633 - val_crf_56_acc_3: 0.8152 - val_crf_57_acc_1: 0.8135 - val_crf_57_acc_2: 0.8149 - val_crf_57_acc_3: 0.9879 - val_f1: 0.8629 - val_crf_55_f1: 0.8526 - val_crf_56_f1: 0.8047 - val_crf_57_f1: 0.9315
Epoch 4/25
 - 2614s - loss: -1.2024e-01 - crf_55_loss: -1.1198e-02 - crf_56_loss: -4.5145e-02 - crf_57_loss: -6.3894e-02 - crf_55_acc_1: 0.9552 - crf_55_acc_2: 0.7723 - crf_55_acc_3: 0.7755 - crf_56_acc_1: 0.7722 - crf_56_acc_2: 0.9459 - crf_56_acc_3: 0.7737 - crf_57_acc_1: 0.7753 - crf_57_acc_2: 0.7730 - crf_57_acc_3: 0.9782 - val_loss: -1.8902e-01 - val_crf_55_loss: -4.4205e-02 - val_crf_56_loss: -6.4093e-02 - val_crf_57_loss: -8.0719e-02 - val_crf_55_acc_1: 0.9718 - val_crf_55_acc_2: 0.8134 - val_crf_55_acc_3: 0.8134 - val_crf_56_acc_1: 0.8134 - val_crf_56_acc_2: 0.9623 - val_crf_56_acc_3: 0.8151 - val_crf_57_acc_1: 0.8136 - val_crf_57_acc_2: 0.8151 - val_crf_57_acc_3: 0.9856 - val_f1: 0.8538 - val_crf_55_f1: 0.8508 - val_crf_56_f1: 0.8005 - val_crf_57_f1: 0.9100
Epoch 5/25
 - 2673s - loss: -1.8928e-01 - crf_55_loss: -3.4439e-02 - crf_56_loss: -6.7964e-02 - crf_57_loss: -8.6877e-02 - crf_55_acc_1: 0.9562 - crf_55_acc_2: 0.7723 - crf_55_acc_3: 0.7755 - crf_56_acc_1: 0.7722 - crf_56_acc_2: 0.9477 - crf_56_acc_3: 0.7736 - crf_57_acc_1: 0.7753 - crf_57_acc_2: 0.7730 - crf_57_acc_3: 0.9782 - val_loss: -2.5333e-01 - val_crf_55_loss: -6.4458e-02 - val_crf_56_loss: -8.5769e-02 - val_crf_57_loss: -1.0310e-01 - val_crf_55_acc_1: 0.9720 - val_crf_55_acc_2: 0.8133 - val_crf_55_acc_3: 0.8134 - val_crf_56_acc_1: 0.8134 - val_crf_56_acc_2: 0.9620 - val_crf_56_acc_3: 0.8151 - val_crf_57_acc_1: 0.8136 - val_crf_57_acc_2: 0.8151 - val_crf_57_acc_3: 0.9845 - val_f1: 0.8524 - val_crf_55_f1: 0.8562 - val_crf_56_f1: 0.7999 - val_crf_57_f1: 0.9012
Epoch 6/25
 - 2680s - loss: -2.5592e-01 - crf_55_loss: -5.6528e-02 - crf_56_loss: -9.0073e-02 - crf_57_loss: -1.0931e-01 - crf_55_acc_1: 0.9574 - crf_55_acc_2: 0.7723 - crf_55_acc_3: 0.7755 - crf_56_acc_1: 0.7722 - crf_56_acc_2: 0.9487 - crf_56_acc_3: 0.7736 - crf_57_acc_1: 0.7753 - crf_57_acc_2: 0.7730 - crf_57_acc_3: 0.9786 - val_loss: -3.2065e-01 - val_crf_55_loss: -8.7379e-02 - val_crf_56_loss: -1.0784e-01 - val_crf_57_loss: -1.2544e-01 - val_crf_55_acc_1: 0.9746 - val_crf_55_acc_2: 0.8129 - val_crf_55_acc_3: 0.8134 - val_crf_56_acc_1: 0.8134 - val_crf_56_acc_2: 0.9633 - val_crf_56_acc_3: 0.8153 - val_crf_57_acc_1: 0.8135 - val_crf_57_acc_2: 0.8148 - val_crf_57_acc_3: 0.9851 - val_f1: 0.8570 - val_crf_55_f1: 0.8655 - val_crf_56_f1: 0.8025 - val_crf_57_f1: 0.9029
Epoch 7/25
 - 2610s - loss: -3.2121e-01 - crf_55_loss: -7.7695e-02 - crf_56_loss: -1.1185e-01 - crf_57_loss: -1.3167e-01 - crf_55_acc_1: 0.9581 - crf_55_acc_2: 0.7723 - crf_55_acc_3: 0.7755 - crf_56_acc_1: 0.7722 - crf_56_acc_2: 0.9497 - crf_56_acc_3: 0.7736 - crf_57_acc_1: 0.7753 - crf_57_acc_2: 0.7730 - crf_57_acc_3: 0.9788 - val_loss: -3.8243e-01 - val_crf_55_loss: -1.0618e-01 - val_crf_56_loss: -1.2882e-01 - val_crf_57_loss: -1.4743e-01 - val_crf_55_acc_1: 0.9737 - val_crf_55_acc_2: 0.8133 - val_crf_55_acc_3: 0.8134 - val_crf_56_acc_1: 0.8134 - val_crf_56_acc_2: 0.9605 - val_crf_56_acc_3: 0.8151 - val_crf_57_acc_1: 0.8136 - val_crf_57_acc_2: 0.8151 - val_crf_57_acc_3: 0.9853 - val_f1: 0.8523 - val_crf_55_f1: 0.8627 - val_crf_56_f1: 0.7893 - val_crf_57_f1: 0.9048
Epoch 8/25
 - 2627s - loss: -3.8617e-01 - crf_55_loss: -9.8580e-02 - crf_56_loss: -1.3358e-01 - crf_57_loss: -1.5401e-01 - crf_55_acc_1: 0.9588 - crf_55_acc_2: 0.7723 - crf_55_acc_3: 0.7755 - crf_56_acc_1: 0.7722 - crf_56_acc_2: 0.9510 - crf_56_acc_3: 0.7736 - crf_57_acc_1: 0.7754 - crf_57_acc_2: 0.7730 - crf_57_acc_3: 0.9792 - val_loss: -4.4969e-01 - val_crf_55_loss: -1.2826e-01 - val_crf_56_loss: -1.5117e-01 - val_crf_57_loss: -1.7025e-01 - val_crf_55_acc_1: 0.9747 - val_crf_55_acc_2: 0.8130 - val_crf_55_acc_3: 0.8135 - val_crf_56_acc_1: 0.8134 - val_crf_56_acc_2: 0.9624 - val_crf_56_acc_3: 0.8152 - val_crf_57_acc_1: 0.8136 - val_crf_57_acc_2: 0.8154 - val_crf_57_acc_3: 0.9853 - val_f1: 0.8585 - val_crf_55_f1: 0.8692 - val_crf_56_f1: 0.8020 - val_crf_57_f1: 0.9042

-------------------------------------------
Best F1 score: 0.862935149905   (epoch number 3)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5135    0.6786       148
        archivalreference     0.6833    0.8171    0.7443       853
              archive_lib     0.9326    0.8058    0.8646       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9278    0.9169    0.9223      4948
                      box     0.8182    0.4909    0.6136       110
              cartulation     0.6667    1.0000    0.8000         8
              conjunction     0.5258    0.7612    0.6220       134
                     date     0.5510    0.4655    0.5047        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4091    0.6429    0.5000        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1495    0.2667    0.1916       120
                        o     0.2440    0.3245    0.2785       752
               pagination     0.9178    0.9508    0.9340      1139
   publicationnumber-year     0.6010    0.7229    0.6564       646
         publicationplace     0.9264    0.8693    0.8970      1592
publicationspecifications     0.2318    0.1371    0.1723       372
                publisher     0.9297    0.8067    0.8638      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7576    0.3268    0.4566       153
                    title     0.9155    0.9166    0.9160     15560
                     tomo     0.7600    0.1696    0.2774       224
                   volume     0.4791    0.5379    0.5068       277
                     year     0.9314    0.7667    0.8411      2036

              avg / total     0.9756    0.9711    0.9724    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5135    0.6786       148
        archivalreference     0.6833    0.8171    0.7443       853
              archive_lib     0.9326    0.8058    0.8646       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9278    0.9169    0.9223      4948
                      box     0.8182    0.4909    0.6136       110
              cartulation     0.6667    1.0000    0.8000         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5258    0.7612    0.6220       134
                     date     0.5510    0.4655    0.5047        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4091    0.6429    0.5000        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1495    0.2667    0.1916       120
                        o     0.2440    0.3245    0.2785       752
               pagination     0.9178    0.9508    0.9340      1139
   publicationnumber-year     0.6010    0.7229    0.6564       646
         publicationplace     0.9264    0.8693    0.8970      1592
publicationspecifications     0.2318    0.1371    0.1723       372
                publisher     0.9297    0.8067    0.8638      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7576    0.3268    0.4566       153
                    title     0.9155    0.9166    0.9160     15560
                     tomo     0.7600    0.1696    0.2774       224
                   volume     0.4791    0.5379    0.5068       277
                     year     0.9314    0.7667    0.8411      2036

              avg / total     0.8695    0.8459    0.8526     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7280    0.5000    0.5928       348
        b-primary     0.8642    0.6667    0.7527       105
      b-secondary     0.7038    0.6749    0.6890       852
e-meta-annotation     0.8764    0.7286    0.7957      1061
        e-primary     0.7833    0.6867    0.7318       300
      e-secondary     0.8265    0.8602    0.8430      1717
i-meta-annotation     0.8195    0.7215    0.7674      9981
        i-primary     0.8324    0.9051    0.8672      1728
      i-secondary     0.8203    0.8787    0.8485     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2231    0.3981    0.2860       427

      avg / total     0.9645    0.9633    0.9634    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7280    0.5000    0.5928       348
        b-primary     0.8642    0.6667    0.7527       105
      b-secondary     0.7038    0.6749    0.6890       852
e-meta-annotation     0.8764    0.7286    0.7957      1061
        e-primary     0.7833    0.6867    0.7318       300
      e-secondary     0.8265    0.8602    0.8430      1717
i-meta-annotation     0.8195    0.7215    0.7674      9981
        i-primary     0.8324    0.9051    0.8672      1728
      i-secondary     0.8203    0.8787    0.8485     14357
                o     0.2231    0.3981    0.2860       427

      avg / total     0.8103    0.8041    0.8047     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8224    0.6989    0.7556      1305
        e-r     0.9429    0.3656    0.5270      1310
        i-r     0.9549    0.9811    0.9678     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2814    0.4356    0.3419       427

avg / total     0.9887    0.9879    0.9872    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8224    0.6989    0.7556      1305
        e-r     0.9429    0.3656    0.5270      1310
        i-r     0.9549    0.9811    0.9678     27834
          o     0.2814    0.4356    0.3419       427

avg / total     0.9395    0.9355    0.9315     30876




Confusion matrix, without normalization
[[    38      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    32      4    808      9      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    13      0     79     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   905      0   4019     24      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      7      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    127      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1     26      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     11      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      3    109      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     7      4    552    189      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1    173    957      8      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      4    629     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1588      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      2    341     27      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1442      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      1    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   101      5  15272    182      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    307   1546    183      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.56756757e-01   0.00000000e+00   7.43243243e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.75146542e-02   4.68933177e-03   9.47245018e-01   1.05509965e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.26213592e-01   0.00000000e+00   7.66990291e-01   1.06796117e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.82902183e-01   0.00000000e+00   8.12247373e-01   4.85044462e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.25000000e-01   8.75000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.47761194e-01   5.22388060e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   3.57142857e-02   9.28571429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.33333333e-02   9.16666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   2.50000000e-02   9.08333333e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.30851064e-03   5.31914894e-03   7.34042553e-01   2.51329787e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   1.51887621e-01   8.40210711e-01   7.02370500e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.09597523e-03   6.19195046e-03   9.73684211e-01   1.70278638e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.28140704e-04   9.97487437e-01   1.88442211e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.37634409e-03   5.37634409e-03   9.16666667e-01   7.25806452e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.99306999e-01   6.93000693e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   6.49350649e-03   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.49100257e-03   3.21336761e-04   9.81491003e-01   1.16966581e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.50785855e-01   7.59332024e-01   8.98821218e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   268      0     40     40      0      0      0      0      0      0
       0]
 [    43      0     61      1      0      0      0      0      0      0
       0]
 [   601      0    137    114      0      0      0      0      0      0
       0]
 [     0    188    865      8      0      0      0      0      0      0
       0]
 [     0      3    290      7      0      0      0      0      0      0
       0]
 [     0    288   1417     12      0      0      0      0      0      0
       0]
 [    59      8   9811    103      0      0      0      0      0      0
       0]
 [     9     10   1668     41      0      0      0      0      0      0
       0]
 [   124      8  14076    149      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     5      3    233    186      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.70114943e-01   0.00000000e+00   1.14942529e-01   1.14942529e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.09523810e-01   0.00000000e+00   5.80952381e-01   9.52380952e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.05399061e-01   0.00000000e+00   1.60798122e-01   1.33802817e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.77191329e-01   8.15268615e-01   7.54005655e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.00000000e-02   9.66666667e-01   2.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.67734421e-01   8.25276645e-01   6.98893419e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.91123134e-03   8.01522893e-04   9.82967639e-01   1.03196073e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.20833333e-03   5.78703704e-03   9.65277778e-01   2.37268519e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.63690186e-03   5.57219475e-04   9.80427666e-01   1.03782127e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.17096019e-02   7.02576112e-03   5.45667447e-01   4.35597190e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   912      0    238      0    155]
 [     0    479    819      0     12]
 [   192     26  27308      0    308]
 [     0      0      0 133958      0]
 [     5      3    233      0    186]]
Normalized confusion matrix
[[  6.98850575e-01   0.00000000e+00   1.82375479e-01   0.00000000e+00
    1.18773946e-01]
 [  0.00000000e+00   3.65648855e-01   6.25190840e-01   0.00000000e+00
    9.16030534e-03]
 [  6.89803837e-03   9.34109363e-04   9.81102249e-01   0.00000000e+00
    1.10656032e-02]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  1.17096019e-02   7.02576112e-03   5.45667447e-01   0.00000000e+00
    4.35597190e-01]]
