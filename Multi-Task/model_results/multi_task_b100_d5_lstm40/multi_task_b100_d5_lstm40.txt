______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_12 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_12[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_16 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_11 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_11 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_16[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_11 (Embedding)                         (None, 73, 300)                  17130300          input_11[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_12 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_11[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_6 (Concatenate)                      (None, 73, 3000)                 0                 embedding_11[0][0]                                
                                                                                                    time_distributed_12[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_17 (Dropout)                             (None, 73, 3000)                 0                 concatenate_6[0][0]                               
______________________________________________________________________________________________________________________________________________________
bidirectional_12 (Bidirectional)                 (None, 73, 80)                   973120            dropout_17[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_18 (Dropout)                             (None, 73, 80)                   0                 bidirectional_12[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_16 (Dense)                                 (None, 73, 28)                   2268              dropout_18[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_17 (Dense)                                 (None, 73, 11)                   891               dropout_18[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_18 (Dense)                                 (None, 73, 5)                    405               dropout_18[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_16 (CRF)                                     (None, 73, 28)                   1652              dense_16[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_17 (CRF)                                     (None, 73, 11)                   275               dense_17[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_18 (CRF)                                     (None, 73, 5)                    65                dense_18[0][0]                                    
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1541s - loss: 0.7144 - crf_16_loss: 0.3392 - crf_17_loss: 0.2638 - crf_18_loss: 0.1114 - crf_16_acc_1: 0.9010 - crf_16_acc_2: 0.7682 - crf_16_acc_3: 0.7751 - crf_17_acc_1: 0.7698 - crf_17_acc_2: 0.8937 - crf_17_acc_3: 0.7741 - crf_18_acc_1: 0.7705 - crf_18_acc_2: 0.7675 - crf_18_acc_3: 0.9569 - val_loss: 0.2530 - val_crf_16_loss: 0.1311 - val_crf_17_loss: 0.1002 - val_crf_18_loss: 0.0217 - val_crf_16_acc_1: 0.9519 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8132 - val_crf_17_acc_2: 0.9430 - val_crf_17_acc_3: 0.8152 - val_crf_18_acc_1: 0.8130 - val_crf_18_acc_2: 0.8144 - val_crf_18_acc_3: 0.9867 - val_f1: 0.7836 - val_crf_16_f1: 0.7223 - val_crf_17_f1: 0.6941 - val_crf_18_f1: 0.9345
Epoch 2/25
 - 1526s - loss: 0.2703 - crf_16_loss: 0.1449 - crf_17_loss: 0.0947 - crf_18_loss: 0.0308 - crf_16_acc_1: 0.9419 - crf_16_acc_2: 0.7725 - crf_16_acc_3: 0.7759 - crf_17_acc_1: 0.7723 - crf_17_acc_2: 0.9378 - crf_17_acc_3: 0.7740 - crf_18_acc_1: 0.7742 - crf_18_acc_2: 0.7727 - crf_18_acc_3: 0.9770 - val_loss: 0.1174 - val_crf_16_loss: 0.0676 - val_crf_17_loss: 0.0478 - val_crf_18_loss: 0.0020 - val_crf_16_acc_1: 0.9659 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9562 - val_crf_17_acc_3: 0.8153 - val_crf_18_acc_1: 0.8132 - val_crf_18_acc_2: 0.8150 - val_crf_18_acc_3: 0.9898 - val_f1: 0.8377 - val_crf_16_f1: 0.8040 - val_crf_17_f1: 0.7659 - val_crf_18_f1: 0.9430
Epoch 3/25
 - 1541s - loss: 0.1508 - crf_16_loss: 0.0912 - crf_17_loss: 0.0498 - crf_18_loss: 0.0099 - crf_16_acc_1: 0.9502 - crf_16_acc_2: 0.7725 - crf_16_acc_3: 0.7758 - crf_17_acc_1: 0.7723 - crf_17_acc_2: 0.9449 - crf_17_acc_3: 0.7739 - crf_18_acc_1: 0.7746 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9796 - val_loss: 0.0599 - val_crf_16_loss: 0.0423 - val_crf_17_loss: 0.0252 - val_crf_18_loss: -7.5630e-03 - val_crf_16_acc_1: 0.9694 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8135 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9537 - val_crf_17_acc_3: 0.8152 - val_crf_18_acc_1: 0.8132 - val_crf_18_acc_2: 0.8155 - val_crf_18_acc_3: 0.9886 - val_f1: 0.8438 - val_crf_16_f1: 0.8330 - val_crf_17_f1: 0.7567 - val_crf_18_f1: 0.9418
Epoch 4/25
 - 1528s - loss: 0.0840 - crf_16_loss: 0.0618 - crf_17_loss: 0.0254 - crf_18_loss: -3.2116e-03 - crf_16_acc_1: 0.9541 - crf_16_acc_2: 0.7724 - crf_16_acc_3: 0.7756 - crf_17_acc_1: 0.7722 - crf_17_acc_2: 0.9478 - crf_17_acc_3: 0.7738 - crf_18_acc_1: 0.7749 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9807 - val_loss: 0.0146 - val_crf_16_loss: 0.0247 - val_crf_17_loss: 0.0071 - val_crf_18_loss: -1.7191e-02 - val_crf_16_acc_1: 0.9722 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9599 - val_crf_17_acc_3: 0.8152 - val_crf_18_acc_1: 0.8135 - val_crf_18_acc_2: 0.8151 - val_crf_18_acc_3: 0.9905 - val_f1: 0.8596 - val_crf_16_f1: 0.8481 - val_crf_17_f1: 0.7849 - val_crf_18_f1: 0.9459
Epoch 5/25
 - 1541s - loss: 0.0398 - crf_16_loss: 0.0432 - crf_17_loss: 0.0098 - crf_18_loss: -1.3153e-02 - crf_16_acc_1: 0.9564 - crf_16_acc_2: 0.7724 - crf_16_acc_3: 0.7756 - crf_17_acc_1: 0.7723 - crf_17_acc_2: 0.9495 - crf_17_acc_3: 0.7738 - crf_18_acc_1: 0.7750 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9809 - val_loss: -1.4124e-02 - val_crf_16_loss: 0.0134 - val_crf_17_loss: -3.1951e-03 - val_crf_18_loss: -2.4316e-02 - val_crf_16_acc_1: 0.9733 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9594 - val_crf_17_acc_3: 0.8154 - val_crf_18_acc_1: 0.8134 - val_crf_18_acc_2: 0.8152 - val_crf_18_acc_3: 0.9889 - val_f1: 0.8596 - val_crf_16_f1: 0.8544 - val_crf_17_f1: 0.7853 - val_crf_18_f1: 0.9392
Epoch 6/25
 - 1522s - loss: 0.0056 - crf_16_loss: 0.0293 - crf_17_loss: -1.9446e-03 - crf_18_loss: -2.1755e-02 - crf_16_acc_1: 0.9578 - crf_16_acc_2: 0.7724 - crf_16_acc_3: 0.7755 - crf_17_acc_1: 0.7722 - crf_17_acc_2: 0.9513 - crf_17_acc_3: 0.7737 - crf_18_acc_1: 0.7752 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9809 - val_loss: -4.0644e-02 - val_crf_16_loss: 0.0036 - val_crf_17_loss: -1.3134e-02 - val_crf_18_loss: -3.1129e-02 - val_crf_16_acc_1: 0.9722 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9619 - val_crf_17_acc_3: 0.8151 - val_crf_18_acc_1: 0.8135 - val_crf_18_acc_2: 0.8149 - val_crf_18_acc_3: 0.9876 - val_f1: 0.8640 - val_crf_16_f1: 0.8571 - val_crf_17_f1: 0.7980 - val_crf_18_f1: 0.9368
Epoch 7/25
 - 1524s - loss: -2.2891e-02 - crf_16_loss: 0.0185 - crf_17_loss: -1.1719e-02 - crf_18_loss: -2.9659e-02 - crf_16_acc_1: 0.9590 - crf_16_acc_2: 0.7724 - crf_16_acc_3: 0.7755 - crf_17_acc_1: 0.7722 - crf_17_acc_2: 0.9526 - crf_17_acc_3: 0.7737 - crf_18_acc_1: 0.7752 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9808 - val_loss: -6.4513e-02 - val_crf_16_loss: -4.5542e-03 - val_crf_17_loss: -2.1417e-02 - val_crf_18_loss: -3.8541e-02 - val_crf_16_acc_1: 0.9728 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9628 - val_crf_17_acc_3: 0.8152 - val_crf_18_acc_1: 0.8134 - val_crf_18_acc_2: 0.8151 - val_crf_18_acc_3: 0.9858 - val_f1: 0.8598 - val_crf_16_f1: 0.8551 - val_crf_17_f1: 0.8038 - val_crf_18_f1: 0.9206
Epoch 8/25
 - 1524s - loss: -4.8738e-02 - crf_16_loss: 0.0087 - crf_17_loss: -2.0266e-02 - crf_18_loss: -3.7187e-02 - crf_16_acc_1: 0.9599 - crf_16_acc_2: 0.7724 - crf_16_acc_3: 0.7755 - crf_17_acc_1: 0.7723 - crf_17_acc_2: 0.9532 - crf_17_acc_3: 0.7737 - crf_18_acc_1: 0.7752 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9809 - val_loss: -8.8246e-02 - val_crf_16_loss: -1.4080e-02 - val_crf_17_loss: -2.8553e-02 - val_crf_18_loss: -4.5613e-02 - val_crf_16_acc_1: 0.9743 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9598 - val_crf_17_acc_3: 0.8152 - val_crf_18_acc_1: 0.8135 - val_crf_18_acc_2: 0.8154 - val_crf_18_acc_3: 0.9837 - val_f1: 0.8534 - val_crf_16_f1: 0.8652 - val_crf_17_f1: 0.7901 - val_crf_18_f1: 0.9047
Epoch 9/25
 - 1522s - loss: -7.3029e-02 - crf_16_loss: -1.6777e-04 - crf_17_loss: -2.8273e-02 - crf_18_loss: -4.4589e-02 - crf_16_acc_1: 0.9606 - crf_16_acc_2: 0.7723 - crf_16_acc_3: 0.7754 - crf_17_acc_1: 0.7722 - crf_17_acc_2: 0.9544 - crf_17_acc_3: 0.7736 - crf_18_acc_1: 0.7752 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9808 - val_loss: -1.0742e-01 - val_crf_16_loss: -2.0023e-02 - val_crf_17_loss: -3.5072e-02 - val_crf_18_loss: -5.2321e-02 - val_crf_16_acc_1: 0.9704 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8134 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9540 - val_crf_17_acc_3: 0.8152 - val_crf_18_acc_1: 0.8134 - val_crf_18_acc_2: 0.8159 - val_crf_18_acc_3: 0.9829 - val_f1: 0.8392 - val_crf_16_f1: 0.8555 - val_crf_17_f1: 0.7614 - val_crf_18_f1: 0.9006
Epoch 10/25
 - 1523s - loss: -9.6048e-02 - crf_16_loss: -8.4353e-03 - crf_17_loss: -3.5882e-02 - crf_18_loss: -5.1731e-02 - crf_16_acc_1: 0.9614 - crf_16_acc_2: 0.7723 - crf_16_acc_3: 0.7754 - crf_17_acc_1: 0.7722 - crf_17_acc_2: 0.9552 - crf_17_acc_3: 0.7736 - crf_18_acc_1: 0.7753 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9807 - val_loss: -1.3032e-01 - val_crf_16_loss: -2.9105e-02 - val_crf_17_loss: -4.1713e-02 - val_crf_18_loss: -5.9506e-02 - val_crf_16_acc_1: 0.9754 - val_crf_16_acc_2: 0.8131 - val_crf_16_acc_3: 0.8135 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9526 - val_crf_17_acc_3: 0.8154 - val_crf_18_acc_1: 0.8135 - val_crf_18_acc_2: 0.8147 - val_crf_18_acc_3: 0.9848 - val_f1: 0.8361 - val_crf_16_f1: 0.8706 - val_crf_17_f1: 0.7371 - val_crf_18_f1: 0.9007
Epoch 11/25
 - 1525s - loss: -1.1843e-01 - crf_16_loss: -1.6340e-02 - crf_17_loss: -4.3241e-02 - crf_18_loss: -5.8845e-02 - crf_16_acc_1: 0.9619 - crf_16_acc_2: 0.7723 - crf_16_acc_3: 0.7754 - crf_17_acc_1: 0.7722 - crf_17_acc_2: 0.9556 - crf_17_acc_3: 0.7736 - crf_18_acc_1: 0.7753 - crf_18_acc_2: 0.7730 - crf_18_acc_3: 0.9808 - val_loss: -1.5469e-01 - val_crf_16_loss: -3.6728e-02 - val_crf_17_loss: -5.1016e-02 - val_crf_18_loss: -6.6944e-02 - val_crf_16_acc_1: 0.9751 - val_crf_16_acc_2: 0.8130 - val_crf_16_acc_3: 0.8135 - val_crf_17_acc_1: 0.8134 - val_crf_17_acc_2: 0.9630 - val_crf_17_acc_3: 0.8154 - val_crf_18_acc_1: 0.8135 - val_crf_18_acc_2: 0.8149 - val_crf_18_acc_3: 0.9860 - val_f1: 0.8580 - val_crf_16_f1: 0.8681 - val_crf_17_f1: 0.8022 - val_crf_18_f1: 0.9038

-------------------------------------------
Best F1 score: 0.863976458665   (epoch number 6)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9398    0.5270    0.6753       148
        archivalreference     0.8054    0.8347    0.8198       853
              archive_lib     0.7705    0.9126    0.8356       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9281    0.9266    0.9274      4948
                      box     0.8333    0.4545    0.5882       110
              cartulation     0.2667    1.0000    0.4211         8
              conjunction     0.5189    0.7164    0.6019       134
                     date     0.2857    0.5517    0.3765        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3103    0.6429    0.4186        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1961    0.1667    0.1802       120
                        o     0.1792    0.2819    0.2191       752
               pagination     0.9086    0.9429    0.9255      1139
   publicationnumber-year     0.6045    0.8282    0.6989       646
         publicationplace     0.8947    0.8857    0.8902      1592
publicationspecifications     0.1978    0.1935    0.1957       372
                publisher     0.8731    0.8150    0.8430      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.5926    0.1039    0.1768       154
                   series     0.9300    0.6078    0.7352       153
                    title     0.9265    0.9171    0.9218     15560
                     tomo     1.0000    0.1875    0.3158       224
                   volume     0.5128    0.5054    0.5091       277
                     year     0.9329    0.7583    0.8366      2036

              avg / total     0.9762    0.9722    0.9732    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9398    0.5270    0.6753       148
        archivalreference     0.8054    0.8347    0.8198       853
              archive_lib     0.7705    0.9126    0.8356       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9281    0.9266    0.9274      4948
                      box     0.8333    0.4545    0.5882       110
              cartulation     0.2667    1.0000    0.4211         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5189    0.7164    0.6019       134
                     date     0.2857    0.5517    0.3765        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3103    0.6429    0.4186        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1961    0.1667    0.1802       120
                        o     0.1792    0.2819    0.2191       752
               pagination     0.9086    0.9429    0.9255      1139
   publicationnumber-year     0.6045    0.8282    0.6989       646
         publicationplace     0.8947    0.8857    0.8902      1592
publicationspecifications     0.1978    0.1935    0.1957       372
                publisher     0.8731    0.8150    0.8430      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.5926    0.1039    0.1768       154
                   series     0.9300    0.6078    0.7352       153
                    title     0.9265    0.9171    0.9218     15560
                     tomo     1.0000    0.1875    0.3158       224
                   volume     0.5128    0.5054    0.5091       277
                     year     0.9329    0.7583    0.8366      2036

              avg / total     0.8730    0.8515    0.8571     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7500    0.4569    0.5679       348
        b-primary     0.6389    0.2190    0.3262       105
      b-secondary     0.6791    0.6854    0.6822       852
e-meta-annotation     0.8735    0.7352    0.7984      1061
        e-primary     0.7955    0.7000    0.7447       300
      e-secondary     0.8193    0.8317    0.8254      1717
i-meta-annotation     0.8586    0.6842    0.7615      9981
        i-primary     0.8638    0.8663    0.8651      1728
      i-secondary     0.7975    0.9007    0.8460     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.1644    0.3724    0.2281       427

      avg / total     0.9647    0.9619    0.9622    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7500    0.4569    0.5679       348
        b-primary     0.6389    0.2190    0.3262       105
      b-secondary     0.6791    0.6854    0.6822       852
e-meta-annotation     0.8735    0.7352    0.7984      1061
        e-primary     0.7955    0.7000    0.7447       300
      e-secondary     0.8193    0.8317    0.8254      1717
i-meta-annotation     0.8586    0.6842    0.7615      9981
        i-primary     0.8638    0.8663    0.8651      1728
      i-secondary     0.7975    0.9007    0.8460     14357
                o     0.1644    0.3724    0.2281       427

      avg / total     0.8117    0.7967    0.7980     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8097    0.7042    0.7533      1305
        e-r     0.9497    0.5473    0.6944      1310
        i-r     0.9634    0.9706    0.9670     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.1981    0.4379    0.2728       427

avg / total     0.9898    0.9876    0.9882    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8097    0.7042    0.7533      1305
        e-r     0.9497    0.5473    0.6944      1310
        i-r     0.9634    0.9706    0.9670     27834
          o     0.1981    0.4379    0.2728       427

avg / total     0.9457    0.9340    0.9368     30876




Confusion matrix, without normalization
[[    38      0     90     20      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    27      5    802     19      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    17      0     75     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   906      2   4022     18      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      7      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    126      8      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     52      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1     26      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3    112      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     8     11    527    206      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5    175    951      8      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1     11    630      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1   1587      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      5    341     26      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1440      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      1    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   125     12  15036    387      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    276      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    525   1289    222      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.56756757e-01   0.00000000e+00   6.08108108e-01   1.35135135e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.16529894e-02   5.86166471e-03   9.40211020e-01   2.22743259e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.65048544e-01   0.00000000e+00   7.28155340e-01   1.06796117e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.83104285e-01   4.04203719e-04   8.12853678e-01   3.63783347e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.25000000e-01   8.75000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.40298507e-01   5.97014925e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   8.96551724e-01   8.62068966e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   3.57142857e-02   9.28571429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.33333333e-03   2.50000000e-02   9.33333333e-01   3.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.06382979e-02   1.46276596e-02   7.00797872e-01   2.73936170e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.38981563e-03   1.53643547e-01   8.34942932e-01   7.02370500e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   1.70278638e-02   9.75232198e-01   6.19195046e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   6.28140704e-04   9.96859296e-01   1.88442211e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.34408602e-02   9.16666667e-01   6.98924731e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.93000693e-04   9.97920998e-01   1.38600139e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   6.49350649e-03   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.03341902e-03   7.71208226e-04   9.66323907e-01   2.48714653e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.96389892e-01   3.61010830e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.57858546e-01   6.33104126e-01   1.09037328e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   267      0     40     41      0      0      0      0      0      0
       0]
 [    44      0     60      1      0      0      0      0      0      0
       0]
 [   608      0    125    119      0      0      0      0      0      0
       0]
 [     0    208    842     11      0      0      0      0      0      0
       0]
 [     0     10    279     11      0      0      0      0      0      0
       0]
 [     1    499   1194     23      0      0      0      0      0      0
       0]
 [    73      9   9711    188      0      0      0      0      0      0
       0]
 [     8      9   1658     53      0      0      0      0      0      0
       0]
 [   128     14  13905    310      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     6      6    228    187      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.67241379e-01   0.00000000e+00   1.14942529e-01   1.17816092e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.19047619e-01   0.00000000e+00   5.71428571e-01   9.52380952e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.13615023e-01   0.00000000e+00   1.46713615e-01   1.39671362e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.96041470e-01   7.93590952e-01   1.03675778e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.33333333e-02   9.30000000e-01   3.66666667e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.82411182e-04   2.90623180e-01   6.95398952e-01   1.33954572e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.31389640e-03   9.01713255e-04   9.72948602e-01   1.88357880e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.62962963e-03   5.20833333e-03   9.59490741e-01   3.06712963e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.91551160e-03   9.75134081e-04   9.68517100e-01   2.15922546e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.40515222e-02   1.40515222e-02   5.33957845e-01   4.37939110e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   919      0    225      0    161]
 [     0    717    573      0     20]
 [   210     32  27016      0    576]
 [     0      0      0 133958      0]
 [     6      6    228      0    187]]
Normalized confusion matrix
[[ 0.70421456  0.          0.17241379  0.          0.12337165]
 [ 0.          0.54732824  0.43740458  0.          0.01526718]
 [ 0.00754473  0.00114967  0.97061148  0.          0.02069412]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.01405152  0.01405152  0.53395785  0.          0.43793911]]
