______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_54 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_54[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_79 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_53 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_53 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_79[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_53 (Embedding)                         (None, 73, 300)                  17130300          input_53[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_54 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_53[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_27 (Concatenate)                     (None, 73, 3000)                 0                 embedding_53[0][0]                                
                                                                                                    time_distributed_54[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_80 (Dropout)                             (None, 73, 3000)                 0                 concatenate_27[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_54 (Bidirectional)                 (None, 73, 80)                   973120            dropout_80[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_81 (Dropout)                             (None, 73, 80)                   0                 bidirectional_54[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_79 (Dense)                                 (None, 73, 28)                   2268              dropout_81[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_80 (Dense)                                 (None, 73, 11)                   891               dropout_81[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_81 (Dense)                                 (None, 73, 5)                    405               dropout_81[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_79 (CRF)                                     (None, 73, 28)                   1652              dense_79[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_80 (CRF)                                     (None, 73, 11)                   275               dense_80[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_81 (CRF)                                     (None, 73, 5)                    65                dense_81[0][0]                                    
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 2598s - loss: 0.3346 - crf_79_loss: 0.1680 - crf_80_loss: 0.1124 - crf_81_loss: 0.0542 - crf_79_acc_1: 0.9392 - crf_79_acc_2: 0.7715 - crf_79_acc_3: 0.7753 - crf_80_acc_1: 0.7716 - crf_80_acc_2: 0.9302 - crf_80_acc_3: 0.7738 - crf_81_acc_1: 0.7738 - crf_81_acc_2: 0.7717 - crf_81_acc_3: 0.9725 - val_loss: 0.0519 - val_crf_79_loss: 0.0431 - val_crf_80_loss: 0.0194 - val_crf_81_loss: -1.0592e-02 - val_crf_79_acc_1: 0.9708 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8134 - val_crf_80_acc_1: 0.8134 - val_crf_80_acc_2: 0.9565 - val_crf_80_acc_3: 0.8152 - val_crf_81_acc_1: 0.8133 - val_crf_81_acc_2: 0.8153 - val_crf_81_acc_3: 0.9890 - val_f1: 0.8508 - val_crf_79_f1: 0.8415 - val_crf_80_f1: 0.7695 - val_crf_81_f1: 0.9415
Epoch 2/25
 - 2551s - loss: 0.0230 - crf_79_loss: 0.0377 - crf_80_loss: 0.0037 - crf_81_loss: -1.8433e-02 - crf_79_acc_1: 0.9619 - crf_79_acc_2: 0.7724 - crf_79_acc_3: 0.7755 - crf_80_acc_1: 0.7722 - crf_80_acc_2: 0.9524 - crf_80_acc_3: 0.7737 - crf_81_acc_1: 0.7752 - crf_81_acc_2: 0.7731 - crf_81_acc_3: 0.9824 - val_loss: -5.1357e-02 - val_crf_79_loss: 0.0037 - val_crf_80_loss: -1.7063e-02 - val_crf_81_loss: -3.7978e-02 - val_crf_79_acc_1: 0.9737 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8134 - val_crf_80_acc_1: 0.8134 - val_crf_80_acc_2: 0.9586 - val_crf_80_acc_3: 0.8153 - val_crf_81_acc_1: 0.8135 - val_crf_81_acc_2: 0.8147 - val_crf_81_acc_3: 0.9884 - val_f1: 0.8577 - val_crf_79_f1: 0.8627 - val_crf_80_f1: 0.7754 - val_crf_81_f1: 0.9351
Epoch 3/25
 - 2539s - loss: -7.2197e-02 - crf_79_loss: 0.0014 - crf_80_loss: -2.7899e-02 - crf_81_loss: -4.5746e-02 - crf_79_acc_1: 0.9653 - crf_79_acc_2: 0.7723 - crf_79_acc_3: 0.7754 - crf_80_acc_1: 0.7722 - crf_80_acc_2: 0.9568 - crf_80_acc_3: 0.7736 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7731 - crf_81_acc_3: 0.9825 - val_loss: -1.2678e-01 - val_crf_79_loss: -2.2184e-02 - val_crf_80_loss: -4.3080e-02 - val_crf_81_loss: -6.1515e-02 - val_crf_79_acc_1: 0.9720 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8134 - val_crf_80_acc_1: 0.8134 - val_crf_80_acc_2: 0.9625 - val_crf_80_acc_3: 0.8154 - val_crf_81_acc_1: 0.8137 - val_crf_81_acc_2: 0.8149 - val_crf_81_acc_3: 0.9854 - val_f1: 0.8547 - val_crf_79_f1: 0.8584 - val_crf_80_f1: 0.7992 - val_crf_81_f1: 0.9067
Epoch 4/25
 - 2592s - loss: -1.4650e-01 - crf_79_loss: -2.4911e-02 - crf_80_loss: -5.2253e-02 - crf_81_loss: -6.9336e-02 - crf_79_acc_1: 0.9674 - crf_79_acc_2: 0.7722 - crf_79_acc_3: 0.7754 - crf_80_acc_1: 0.7722 - crf_80_acc_2: 0.9599 - crf_80_acc_3: 0.7735 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7731 - crf_81_acc_3: 0.9823 - val_loss: -1.9261e-01 - val_crf_79_loss: -4.4610e-02 - val_crf_80_loss: -6.4459e-02 - val_crf_81_loss: -8.3545e-02 - val_crf_79_acc_1: 0.9758 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8134 - val_crf_80_acc_1: 0.8134 - val_crf_80_acc_2: 0.9606 - val_crf_80_acc_3: 0.8153 - val_crf_81_acc_1: 0.8136 - val_crf_81_acc_2: 0.8155 - val_crf_81_acc_3: 0.9837 - val_f1: 0.8554 - val_crf_79_f1: 0.8742 - val_crf_80_f1: 0.7942 - val_crf_81_f1: 0.8977
Epoch 5/25
 - 2598s - loss: -2.1529e-01 - crf_79_loss: -4.8000e-02 - crf_80_loss: -7.5072e-02 - crf_81_loss: -9.2221e-02 - crf_79_acc_1: 0.9690 - crf_79_acc_2: 0.7722 - crf_79_acc_3: 0.7754 - crf_80_acc_1: 0.7722 - crf_80_acc_2: 0.9625 - crf_80_acc_3: 0.7734 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7731 - crf_81_acc_3: 0.9828 - val_loss: -2.5797e-01 - val_crf_79_loss: -6.5183e-02 - val_crf_80_loss: -8.6674e-02 - val_crf_81_loss: -1.0611e-01 - val_crf_79_acc_1: 0.9756 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8134 - val_crf_80_acc_1: 0.8134 - val_crf_80_acc_2: 0.9627 - val_crf_80_acc_3: 0.8154 - val_crf_81_acc_1: 0.8136 - val_crf_81_acc_2: 0.8150 - val_crf_81_acc_3: 0.9847 - val_f1: 0.8583 - val_crf_79_f1: 0.8725 - val_crf_80_f1: 0.8018 - val_crf_81_f1: 0.9007
Epoch 6/25
 - 2538s - loss: -2.8202e-01 - crf_79_loss: -6.9798e-02 - crf_80_loss: -9.7371e-02 - crf_81_loss: -1.1485e-01 - crf_79_acc_1: 0.9702 - crf_79_acc_2: 0.7722 - crf_79_acc_3: 0.7754 - crf_80_acc_1: 0.7722 - crf_80_acc_2: 0.9646 - crf_80_acc_3: 0.7734 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7731 - crf_81_acc_3: 0.9836 - val_loss: -3.1934e-01 - val_crf_79_loss: -8.4852e-02 - val_crf_80_loss: -1.0728e-01 - val_crf_81_loss: -1.2721e-01 - val_crf_79_acc_1: 0.9743 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8135 - val_crf_80_acc_1: 0.8133 - val_crf_80_acc_2: 0.9628 - val_crf_80_acc_3: 0.8155 - val_crf_81_acc_1: 0.8135 - val_crf_81_acc_2: 0.8150 - val_crf_81_acc_3: 0.9847 - val_f1: 0.8572 - val_crf_79_f1: 0.8688 - val_crf_80_f1: 0.8026 - val_crf_81_f1: 0.9001
Epoch 7/25
 - 2546s - loss: -3.4781e-01 - crf_79_loss: -9.1014e-02 - crf_80_loss: -1.1943e-01 - crf_81_loss: -1.3737e-01 - crf_79_acc_1: 0.9711 - crf_79_acc_2: 0.7722 - crf_79_acc_3: 0.7754 - crf_80_acc_1: 0.7721 - crf_80_acc_2: 0.9668 - crf_80_acc_3: 0.7734 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7731 - crf_81_acc_3: 0.9842 - val_loss: -3.8229e-01 - val_crf_79_loss: -1.0420e-01 - val_crf_80_loss: -1.2839e-01 - val_crf_81_loss: -1.4970e-01 - val_crf_79_acc_1: 0.9754 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8135 - val_crf_80_acc_1: 0.8134 - val_crf_80_acc_2: 0.9607 - val_crf_80_acc_3: 0.8156 - val_crf_81_acc_1: 0.8135 - val_crf_81_acc_2: 0.8151 - val_crf_81_acc_3: 0.9833 - val_f1: 0.8543 - val_crf_79_f1: 0.8731 - val_crf_80_f1: 0.7935 - val_crf_81_f1: 0.8964
Epoch 8/25
 - 2550s - loss: -4.1309e-01 - crf_79_loss: -1.1199e-01 - crf_80_loss: -1.4129e-01 - crf_81_loss: -1.5981e-01 - crf_79_acc_1: 0.9722 - crf_79_acc_2: 0.7722 - crf_79_acc_3: 0.7754 - crf_80_acc_1: 0.7722 - crf_80_acc_2: 0.9682 - crf_80_acc_3: 0.7734 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7731 - crf_81_acc_3: 0.9847 - val_loss: -4.4413e-01 - val_crf_79_loss: -1.2405e-01 - val_crf_80_loss: -1.4850e-01 - val_crf_81_loss: -1.7158e-01 - val_crf_79_acc_1: 0.9735 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8135 - val_crf_80_acc_1: 0.8133 - val_crf_80_acc_2: 0.9571 - val_crf_80_acc_3: 0.8155 - val_crf_81_acc_1: 0.8135 - val_crf_81_acc_2: 0.8148 - val_crf_81_acc_3: 0.9836 - val_f1: 0.8443 - val_crf_79_f1: 0.8671 - val_crf_80_f1: 0.7680 - val_crf_81_f1: 0.8978
Epoch 9/25
 - 2545s - loss: -4.7776e-01 - crf_79_loss: -1.3238e-01 - crf_80_loss: -1.6312e-01 - crf_81_loss: -1.8226e-01 - crf_79_acc_1: 0.9730 - crf_79_acc_2: 0.7722 - crf_79_acc_3: 0.7754 - crf_80_acc_1: 0.7722 - crf_80_acc_2: 0.9702 - crf_80_acc_3: 0.7733 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7730 - crf_81_acc_3: 0.9854 - val_loss: -5.0698e-01 - val_crf_79_loss: -1.4433e-01 - val_crf_80_loss: -1.6940e-01 - val_crf_81_loss: -1.9326e-01 - val_crf_79_acc_1: 0.9755 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8135 - val_crf_80_acc_1: 0.8134 - val_crf_80_acc_2: 0.9591 - val_crf_80_acc_3: 0.8155 - val_crf_81_acc_1: 0.8134 - val_crf_81_acc_2: 0.8152 - val_crf_81_acc_3: 0.9833 - val_f1: 0.8521 - val_crf_79_f1: 0.8736 - val_crf_80_f1: 0.7861 - val_crf_81_f1: 0.8965
Epoch 10/25
 - 2590s - loss: -5.4196e-01 - crf_79_loss: -1.5273e-01 - crf_80_loss: -1.8471e-01 - crf_81_loss: -2.0452e-01 - crf_79_acc_1: 0.9738 - crf_79_acc_2: 0.7722 - crf_79_acc_3: 0.7753 - crf_80_acc_1: 0.7721 - crf_80_acc_2: 0.9711 - crf_80_acc_3: 0.7733 - crf_81_acc_1: 0.7753 - crf_81_acc_2: 0.7730 - crf_81_acc_3: 0.9857 - val_loss: -5.7141e-01 - val_crf_79_loss: -1.6287e-01 - val_crf_80_loss: -1.9215e-01 - val_crf_81_loss: -2.1638e-01 - val_crf_79_acc_1: 0.9744 - val_crf_79_acc_2: 0.8130 - val_crf_79_acc_3: 0.8135 - val_crf_80_acc_1: 0.8133 - val_crf_80_acc_2: 0.9622 - val_crf_80_acc_3: 0.8154 - val_crf_81_acc_1: 0.8137 - val_crf_81_acc_2: 0.8150 - val_crf_81_acc_3: 0.9840 - val_f1: 0.8564 - val_crf_79_f1: 0.8697 - val_crf_80_f1: 0.7999 - val_crf_81_f1: 0.8996

-------------------------------------------
Best F1 score: 0.858316833671   (epoch number 5)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9512    0.5270    0.6783       148
        archivalreference     0.8095    0.7573    0.7826       853
              archive_lib     0.8158    0.9029    0.8571       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9240    0.9218    0.9229      4948
                      box     0.8103    0.4273    0.5595       110
              cartulation     0.6667    1.0000    0.8000         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5200    0.7761    0.6228       134
                     date     0.4444    0.7586    0.5605        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2951    0.6429    0.4045        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1242    0.1667    0.1423       120
                        o     0.2877    0.3271    0.3062       752
               pagination     0.9154    0.9684    0.9411      1139
   publicationnumber-year     0.6960    0.8576    0.7684       646
         publicationplace     0.9093    0.9133    0.9113      1592
publicationspecifications     0.2920    0.2661    0.2785       372
                publisher     0.8958    0.8517    0.8732      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.8696    0.7843    0.8247       153
                    title     0.9357    0.9352    0.9355     15560
                     tomo     0.7952    0.2946    0.4300       224
                   volume     0.4817    0.5704    0.5223       277
                     year     0.9114    0.7932    0.8482      2036

              avg / total     0.9779    0.9756    0.9761    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9512    0.5270    0.6783       148
        archivalreference     0.8095    0.7573    0.7826       853
              archive_lib     0.8158    0.9029    0.8571       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9240    0.9218    0.9229      4948
                      box     0.8103    0.4273    0.5595       110
              cartulation     0.6667    1.0000    0.8000         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5200    0.7761    0.6228       134
                     date     0.4444    0.7586    0.5605        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2951    0.6429    0.4045        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1242    0.1667    0.1423       120
                        o     0.2877    0.3271    0.3062       752
               pagination     0.9154    0.9684    0.9411      1139
   publicationnumber-year     0.6960    0.8576    0.7684       646
         publicationplace     0.9093    0.9133    0.9113      1592
publicationspecifications     0.2920    0.2661    0.2785       372
                publisher     0.8958    0.8517    0.8732      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.8696    0.7843    0.8247       153
                    title     0.9357    0.9352    0.9355     15560
                     tomo     0.7952    0.2946    0.4300       224
                   volume     0.4817    0.5704    0.5223       277
                     year     0.9114    0.7932    0.8482      2036

              avg / total     0.8822    0.8695    0.8725     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6929    0.5316    0.6016       348
        b-primary     0.6250    0.1905    0.2920       105
      b-secondary     0.7110    0.6526    0.6805       852
e-meta-annotation     0.8494    0.7389    0.7903      1061
        e-primary     0.6523    0.5567    0.6007       300
      e-secondary     0.8126    0.8462    0.8291      1717
i-meta-annotation     0.8285    0.7430    0.7834      9981
        i-primary     0.7662    0.8137    0.7892      1728
      i-secondary     0.8250    0.8766    0.8500     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.1954    0.3607    0.2535       427

      avg / total     0.9639    0.9627    0.9629    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6929    0.5316    0.6016       348
        b-primary     0.6250    0.1905    0.2920       105
      b-secondary     0.7110    0.6526    0.6805       852
e-meta-annotation     0.8494    0.7389    0.7903      1061
        e-primary     0.6523    0.5567    0.6007       300
      e-secondary     0.8126    0.8462    0.8291      1717
i-meta-annotation     0.8285    0.7430    0.7834      9981
        i-primary     0.7662    0.8137    0.7892      1728
      i-secondary     0.8250    0.8766    0.8500     14357
                o     0.1954    0.3607    0.2535       427

      avg / total     0.8073    0.8008    0.8018     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8203    0.6751    0.7406      1305
        e-r     0.2500    0.0076    0.0148      1310
        i-r     0.9380    0.9812    0.9592     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2446    0.3700    0.2945       427

avg / total     0.9802    0.9847    0.9814    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8203    0.6751    0.7406      1305
        e-r     0.2500    0.0076    0.0148      1310
        i-r     0.9380    0.9812    0.9592     27834
          o     0.2446    0.3700    0.2945       427

avg / total     0.8943    0.9185    0.9007     30876




Confusion matrix, without normalization
[[    37      0     91     20      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    12      7    820     14      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    17      0     80      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   856      3   4039     50      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    131      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1     26      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     11      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      2    110      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     9      2    567    174      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      4   1097     38      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1    641      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1585      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    352     20      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      0   1435      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    149      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   130      6  15306    118      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2     12   1841    181      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   6.14864865e-01   1.35135135e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.40679953e-02   8.20633060e-03   9.61313013e-01   1.64126612e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.65048544e-01   0.00000000e+00   7.76699029e-01   5.82524272e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.72999192e-01   6.06305578e-04   8.16289410e-01   1.01050930e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.77611940e-01   2.23880597e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   3.57142857e-02   9.28571429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.33333333e-02   9.16666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   1.66666667e-02   9.16666667e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.19680851e-02   2.65957447e-03   7.53989362e-01   2.31382979e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.51185250e-03   9.63125549e-01   3.33625988e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.54798762e-03   9.92260062e-01   6.19195046e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   0.00000000e+00   9.95603015e-01   3.76884422e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.46236559e-01   5.37634409e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.38600139e-03   0.00000000e+00   9.94455994e-01   4.15800416e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   9.67532468e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.35475578e-03   3.85604113e-04   9.83676093e-01   7.58354756e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.82318271e-04   5.89390963e-03   9.04223969e-01   8.88998035e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   264      0     42     42      0      0      0      0      0      0
       0]
 [    27      0     76      2      0      0      0      0      0      0
       0]
 [   590      0    148    114      0      0      0      0      0      0
       0]
 [     0      2   1027     32      0      0      0      0      0      0
       0]
 [     0      0    278     22      0      0      0      0      0      0
       0]
 [     0      8   1692     17      0      0      0      0      0      0
       0]
 [    56      5   9822     98      0      0      0      0      0      0
       0]
 [     8     12   1656     52      0      0      0      0      0      0
       0]
 [   123     12  14113    109      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     6      1    262    158      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.58620690e-01   0.00000000e+00   1.20689655e-01   1.20689655e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.57142857e-01   0.00000000e+00   7.23809524e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.92488263e-01   0.00000000e+00   1.73708920e-01   1.33802817e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.88501414e-03   9.67954760e-01   3.01602262e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.26666667e-01   7.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   4.65928946e-03   9.85439720e-01   9.90099010e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.61066025e-03   5.00951808e-04   9.84069732e-01   9.81865545e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.62962963e-03   6.94444444e-03   9.58333333e-01   3.00925926e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.56724943e-03   8.35829212e-04   9.83004806e-01   7.59211534e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.40515222e-02   2.34192037e-03   6.13583138e-01   3.70023419e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   881      0    266      0    158]
 [     0     10   1276      0     24]
 [   187     29  27312      0    306]
 [     0      0      0 133958      0]
 [     6      1    262      0    158]]
Normalized confusion matrix
[[ 0.67509579  0.          0.20383142  0.          0.1210728 ]
 [ 0.          0.00763359  0.9740458   0.          0.01832061]
 [ 0.0067184   0.00104189  0.98124596  0.          0.01099375]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.01405152  0.00234192  0.61358314  0.          0.37002342]]
