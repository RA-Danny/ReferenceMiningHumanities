______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_36 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_36[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_52 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_35 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_35 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_52[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_35 (Embedding)                         (None, 73, 300)                  17130300          input_35[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_36 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_35[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_18 (Concatenate)                     (None, 73, 3000)                 0                 embedding_35[0][0]                                
                                                                                                    time_distributed_36[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_53 (Dropout)                             (None, 73, 3000)                 0                 concatenate_18[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_36 (Bidirectional)                 (None, 73, 80)                   973120            dropout_53[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_54 (Dropout)                             (None, 73, 80)                   0                 bidirectional_36[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_52 (Dense)                                 (None, 73, 28)                   2268              dropout_54[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_53 (Dense)                                 (None, 73, 11)                   891               dropout_54[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_54 (Dense)                                 (None, 73, 5)                    405               dropout_54[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_52 (CRF)                                     (None, 73, 28)                   1652              dense_52[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_53 (CRF)                                     (None, 73, 11)                   275               dense_53[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_54 (CRF)                                     (None, 73, 5)                    65                dense_54[0][0]                                    
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1743s - loss: 0.5461 - crf_52_loss: 0.2459 - crf_53_loss: 0.1888 - crf_54_loss: 0.1114 - crf_52_acc_1: 0.9234 - crf_52_acc_2: 0.7710 - crf_52_acc_3: 0.7737 - crf_53_acc_1: 0.7701 - crf_53_acc_2: 0.9164 - crf_53_acc_3: 0.7722 - crf_54_acc_1: 0.7719 - crf_54_acc_2: 0.7708 - crf_54_acc_3: 0.9608 - val_loss: 0.1676 - val_crf_52_loss: 0.0869 - val_crf_53_loss: 0.0590 - val_crf_54_loss: 0.0216 - val_crf_52_acc_1: 0.9654 - val_crf_52_acc_2: 0.8129 - val_crf_52_acc_3: 0.8134 - val_crf_53_acc_1: 0.8134 - val_crf_53_acc_2: 0.9527 - val_crf_53_acc_3: 0.8153 - val_crf_54_acc_1: 0.8134 - val_crf_54_acc_2: 0.8147 - val_crf_54_acc_3: 0.9881 - val_f1: 0.8341 - val_crf_52_f1: 0.8158 - val_crf_53_f1: 0.7469 - val_crf_54_f1: 0.9398
Epoch 2/25
 - 1723s - loss: 0.1543 - crf_52_loss: 0.0835 - crf_53_loss: 0.0502 - crf_54_loss: 0.0206 - crf_52_acc_1: 0.9582 - crf_52_acc_2: 0.7723 - crf_52_acc_3: 0.7756 - crf_53_acc_1: 0.7722 - crf_53_acc_2: 0.9496 - crf_53_acc_3: 0.7738 - crf_54_acc_1: 0.7750 - crf_54_acc_2: 0.7731 - crf_54_acc_3: 0.9820 - val_loss: 0.0614 - val_crf_52_loss: 0.0433 - val_crf_53_loss: 0.0170 - val_crf_54_loss: 0.0011 - val_crf_52_acc_1: 0.9717 - val_crf_52_acc_2: 0.8130 - val_crf_52_acc_3: 0.8134 - val_crf_53_acc_1: 0.8134 - val_crf_53_acc_2: 0.9599 - val_crf_53_acc_3: 0.8152 - val_crf_54_acc_1: 0.8136 - val_crf_54_acc_2: 0.8152 - val_crf_54_acc_3: 0.9897 - val_f1: 0.8588 - val_crf_52_f1: 0.8480 - val_crf_53_f1: 0.7849 - val_crf_54_f1: 0.9434
Epoch 3/25
 - 1716s - loss: 0.0595 - crf_52_loss: 0.0460 - crf_53_loss: 0.0154 - crf_54_loss: -1.9377e-03 - crf_52_acc_1: 0.9633 - crf_52_acc_2: 0.7723 - crf_52_acc_3: 0.7755 - crf_53_acc_1: 0.7722 - crf_53_acc_2: 0.9558 - crf_53_acc_3: 0.7736 - crf_54_acc_1: 0.7752 - crf_54_acc_2: 0.7731 - crf_54_acc_3: 0.9836 - val_loss: 0.0072 - val_crf_52_loss: 0.0210 - val_crf_53_loss: -2.5545e-03 - val_crf_54_loss: -1.1233e-02 - val_crf_52_acc_1: 0.9741 - val_crf_52_acc_2: 0.8130 - val_crf_52_acc_3: 0.8134 - val_crf_53_acc_1: 0.8134 - val_crf_53_acc_2: 0.9626 - val_crf_53_acc_3: 0.8155 - val_crf_54_acc_1: 0.8134 - val_crf_54_acc_2: 0.8151 - val_crf_54_acc_3: 0.9879 - val_f1: 0.8654 - val_crf_52_f1: 0.8642 - val_crf_53_f1: 0.8009 - val_crf_54_f1: 0.9311
Epoch 4/25
 - 1730s - loss: 0.0036 - crf_52_loss: 0.0242 - crf_53_loss: -4.1759e-03 - crf_54_loss: -1.6426e-02 - crf_52_acc_1: 0.9661 - crf_52_acc_2: 0.7723 - crf_52_acc_3: 0.7754 - crf_53_acc_1: 0.7722 - crf_53_acc_2: 0.9589 - crf_53_acc_3: 0.7735 - crf_54_acc_1: 0.7752 - crf_54_acc_2: 0.7731 - crf_54_acc_3: 0.9835 - val_loss: -3.3401e-02 - val_crf_52_loss: 0.0057 - val_crf_53_loss: -1.6633e-02 - val_crf_54_loss: -2.2501e-02 - val_crf_52_acc_1: 0.9757 - val_crf_52_acc_2: 0.8130 - val_crf_52_acc_3: 0.8134 - val_crf_53_acc_1: 0.8134 - val_crf_53_acc_2: 0.9628 - val_crf_53_acc_3: 0.8154 - val_crf_54_acc_1: 0.8135 - val_crf_54_acc_2: 0.8153 - val_crf_54_acc_3: 0.9861 - val_f1: 0.8637 - val_crf_52_f1: 0.8710 - val_crf_53_f1: 0.8030 - val_crf_54_f1: 0.9170
Epoch 5/25
 - 1711s - loss: -3.8816e-02 - crf_52_loss: 0.0081 - crf_53_loss: -1.8657e-02 - crf_54_loss: -2.8235e-02 - crf_52_acc_1: 0.9679 - crf_52_acc_2: 0.7722 - crf_52_acc_3: 0.7754 - crf_53_acc_1: 0.7722 - crf_53_acc_2: 0.9620 - crf_53_acc_3: 0.7735 - crf_54_acc_1: 0.7752 - crf_54_acc_2: 0.7731 - crf_54_acc_3: 0.9834 - val_loss: -5.7241e-02 - val_crf_52_loss: -2.4162e-03 - val_crf_53_loss: -2.3477e-02 - val_crf_54_loss: -3.1348e-02 - val_crf_52_acc_1: 0.9679 - val_crf_52_acc_2: 0.8131 - val_crf_52_acc_3: 0.8134 - val_crf_53_acc_1: 0.8134 - val_crf_53_acc_2: 0.9454 - val_crf_53_acc_3: 0.8154 - val_crf_54_acc_1: 0.8137 - val_crf_54_acc_2: 0.8147 - val_crf_54_acc_3: 0.9840 - val_f1: 0.8111 - val_crf_52_f1: 0.8477 - val_crf_53_f1: 0.6871 - val_crf_54_f1: 0.8984
Epoch 6/25
 - 1710s - loss: -7.5509e-02 - crf_52_loss: -5.4649e-03 - crf_53_loss: -3.0905e-02 - crf_54_loss: -3.9139e-02 - crf_52_acc_1: 0.9694 - crf_52_acc_2: 0.7722 - crf_52_acc_3: 0.7754 - crf_53_acc_1: 0.7722 - crf_53_acc_2: 0.9642 - crf_53_acc_3: 0.7734 - crf_54_acc_1: 0.7753 - crf_54_acc_2: 0.7731 - crf_54_acc_3: 0.9836 - val_loss: -9.3988e-02 - val_crf_52_loss: -1.5434e-02 - val_crf_53_loss: -3.6608e-02 - val_crf_54_loss: -4.1946e-02 - val_crf_52_acc_1: 0.9733 - val_crf_52_acc_2: 0.8131 - val_crf_52_acc_3: 0.8134 - val_crf_53_acc_1: 0.8134 - val_crf_53_acc_2: 0.9571 - val_crf_53_acc_3: 0.8154 - val_crf_54_acc_1: 0.8136 - val_crf_54_acc_2: 0.8147 - val_crf_54_acc_3: 0.9850 - val_f1: 0.8430 - val_crf_52_f1: 0.8629 - val_crf_53_f1: 0.7637 - val_crf_54_f1: 0.9023
Epoch 7/25
 - 1716s - loss: -1.0931e-01 - crf_52_loss: -1.7568e-02 - crf_53_loss: -4.2142e-02 - crf_54_loss: -4.9601e-02 - crf_52_acc_1: 0.9708 - crf_52_acc_2: 0.7722 - crf_52_acc_3: 0.7754 - crf_53_acc_1: 0.7721 - crf_53_acc_2: 0.9662 - crf_53_acc_3: 0.7734 - crf_54_acc_1: 0.7753 - crf_54_acc_2: 0.7731 - crf_54_acc_3: 0.9839 - val_loss: -1.2443e-01 - val_crf_52_loss: -2.6092e-02 - val_crf_53_loss: -4.6942e-02 - val_crf_54_loss: -5.1394e-02 - val_crf_52_acc_1: 0.9729 - val_crf_52_acc_2: 0.8130 - val_crf_52_acc_3: 0.8135 - val_crf_53_acc_1: 0.8135 - val_crf_53_acc_2: 0.9572 - val_crf_53_acc_3: 0.8153 - val_crf_54_acc_1: 0.8135 - val_crf_54_acc_2: 0.8155 - val_crf_54_acc_3: 0.9846 - val_f1: 0.8453 - val_crf_52_f1: 0.8617 - val_crf_53_f1: 0.7736 - val_crf_54_f1: 0.9007
Epoch 8/25
 - 1713s - loss: -1.4156e-01 - crf_52_loss: -2.8846e-02 - crf_53_loss: -5.2868e-02 - crf_54_loss: -5.9851e-02 - crf_52_acc_1: 0.9716 - crf_52_acc_2: 0.7722 - crf_52_acc_3: 0.7753 - crf_53_acc_1: 0.7722 - crf_53_acc_2: 0.9683 - crf_53_acc_3: 0.7734 - crf_54_acc_1: 0.7753 - crf_54_acc_2: 0.7731 - crf_54_acc_3: 0.9844 - val_loss: -1.5522e-01 - val_crf_52_loss: -3.4721e-02 - val_crf_53_loss: -5.8454e-02 - val_crf_54_loss: -6.2048e-02 - val_crf_52_acc_1: 0.9729 - val_crf_52_acc_2: 0.8130 - val_crf_52_acc_3: 0.8135 - val_crf_53_acc_1: 0.8134 - val_crf_53_acc_2: 0.9636 - val_crf_53_acc_3: 0.8154 - val_crf_54_acc_1: 0.8135 - val_crf_54_acc_2: 0.8152 - val_crf_54_acc_3: 0.9858 - val_f1: 0.8567 - val_crf_52_f1: 0.8603 - val_crf_53_f1: 0.8054 - val_crf_54_f1: 0.9045

-------------------------------------------
Best F1 score: 0.865378810183   (epoch number 3)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9167    0.5946    0.7213       148
        archivalreference     0.7769    0.8206    0.7982       853
              archive_lib     0.7961    0.7961    0.7961       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9019    0.9359    0.9186      4948
                      box     0.8542    0.3727    0.5190       110
              cartulation     0.4706    1.0000    0.6400         8
              conjunction     0.5028    0.6716    0.5751       134
                     date     0.3281    0.7241    0.4516        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2745    0.5000    0.3544        28
                foliation     0.5455    1.0000    0.7059        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.2247    0.1667    0.1914       120
                        o     0.2366    0.2992    0.2642       752
               pagination     0.9181    0.9543    0.9359      1139
   publicationnumber-year     0.7084    0.7709    0.7383       646
         publicationplace     0.8974    0.8737    0.8854      1592
publicationspecifications     0.2727    0.3468    0.3053       372
                publisher     0.8987    0.7990    0.8459      1443
                      ref     0.1667    0.6667    0.2667         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.9495    0.6144    0.7460       153
                    title     0.9289    0.9283    0.9286     15560
                     tomo     0.8378    0.2768    0.4161       224
                   volume     0.5552    0.5632    0.5591       277
                     year     0.9109    0.7981    0.8508      2036

              avg / total     0.9764    0.9741    0.9746    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9167    0.5946    0.7213       148
        archivalreference     0.7769    0.8206    0.7982       853
              archive_lib     0.7961    0.7961    0.7961       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9019    0.9359    0.9186      4948
                      box     0.8542    0.3727    0.5190       110
              cartulation     0.4706    1.0000    0.6400         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5028    0.6716    0.5751       134
                     date     0.3281    0.7241    0.4516        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2745    0.5000    0.3544        28
                foliation     0.5455    1.0000    0.7059        12
             numbered_ref     0.2247    0.1667    0.1914       120
                        o     0.2366    0.2992    0.2642       752
               pagination     0.9181    0.9543    0.9359      1139
   publicationnumber-year     0.7084    0.7709    0.7383       646
         publicationplace     0.8974    0.8737    0.8854      1592
publicationspecifications     0.2727    0.3468    0.3053       372
                publisher     0.8987    0.7990    0.8459      1443
                      ref     0.1667    0.6667    0.2667         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.9495    0.6144    0.7460       153
                    title     0.9289    0.9283    0.9286     15560
                     tomo     0.8378    0.2768    0.4161       224
                   volume     0.5552    0.5632    0.5591       277
                     year     0.9109    0.7981    0.8508      2036

              avg / total     0.8740    0.8620    0.8642     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7397    0.5144    0.6068       348
        b-primary     0.6071    0.1619    0.2556       105
      b-secondary     0.6944    0.6455    0.6691       852
e-meta-annotation     0.8806    0.7436    0.8063      1061
        e-primary     0.6786    0.5067    0.5802       300
      e-secondary     0.8263    0.8200    0.8232      1717
i-meta-annotation     0.8190    0.7544    0.7854      9981
        i-primary     0.8518    0.7685    0.8080      1728
      i-secondary     0.8141    0.8780    0.8448     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2056    0.3630    0.2625       427

      avg / total     0.9637    0.9626    0.9627    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7397    0.5144    0.6068       348
        b-primary     0.6071    0.1619    0.2556       105
      b-secondary     0.6944    0.6455    0.6691       852
e-meta-annotation     0.8806    0.7436    0.8063      1061
        e-primary     0.6786    0.5067    0.5802       300
      e-secondary     0.8263    0.8200    0.8232      1717
i-meta-annotation     0.8190    0.7544    0.7854      9981
        i-primary     0.8518    0.7685    0.8080      1728
      i-secondary     0.8141    0.8780    0.8448     14357
                o     0.2056    0.3630    0.2625       427

      avg / total     0.8062    0.8004    0.8009     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8162    0.6398    0.7174      1305
        e-r     0.9561    0.3992    0.5633      1310
        i-r     0.9533    0.9828    0.9678     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2700    0.3864    0.3179       427

avg / total     0.9884    0.9879    0.9871    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8162    0.6398    0.7174      1305
        e-r     0.9561    0.3992    0.5633      1310
        i-r     0.9533    0.9828    0.9678     27834
          o     0.2700    0.3864    0.3179       427

avg / total     0.9382    0.9353    0.9311     30876




Confusion matrix, without normalization
[[    37      0     95     16      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     9      5    826     13      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    13      0     77     13      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   840      1   4090     17      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      7      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    131      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     53      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1     26      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3    106     10      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     7      3    565    177      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    130    981     28      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      3    643      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1587      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1    343     27      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1440      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    149      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   104      2  15339    115      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1    223      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    276      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     4    395   1457    180      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   6.41891892e-01   1.08108108e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.05509965e-02   5.86166471e-03   9.68347011e-01   1.52403283e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.26213592e-01   0.00000000e+00   7.47572816e-01   1.26213592e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.69765562e-01   2.02101859e-04   8.26596605e-01   3.43573161e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.25000000e-01   8.75000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.77611940e-01   2.23880597e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.13793103e-01   8.62068966e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   3.57142857e-02   9.28571429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.33333333e-03   2.50000000e-02   8.83333333e-01   8.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.30851064e-03   3.98936170e-03   7.51329787e-01   2.35372340e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.14135206e-01   8.61281826e-01   2.45829675e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   4.64396285e-03   9.95356037e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.28140704e-04   9.96859296e-01   2.51256281e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   2.68817204e-03   9.22043011e-01   7.25806452e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   0.00000000e+00   9.97920998e-01   1.38600139e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   9.67532468e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.68380463e-03   1.28534704e-04   9.85796915e-01   7.39074550e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   4.46428571e-03   9.95535714e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.96389892e-01   3.61010830e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.96463654e-03   1.94007859e-01   7.15618861e-01   8.84086444e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   253      0     56     39      0      0      0      0      0      0
       0]
 [    19      0     84      2      0      0      0      0      0      0
       0]
 [   563      0    180    109      0      0      0      0      0      0
       0]
 [     0    156    881     24      0      0      0      0      0      0
       0]
 [     0      2    290      8      0      0      0      0      0      0
       0]
 [     1    365   1330     21      0      0      0      0      0      0
       0]
 [    50      3   9850     78      0      0      0      0      0      0
       0]
 [    11      9   1661     47      0      0      0      0      0      0
       0]
 [   121      9  14109    118      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     5      3    254    165      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.27011494e-01   0.00000000e+00   1.60919540e-01   1.12068966e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.80952381e-01   0.00000000e+00   8.00000000e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.60798122e-01   0.00000000e+00   2.11267606e-01   1.27934272e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.47031103e-01   8.30348728e-01   2.26201697e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.66666667e-03   9.66666667e-01   2.66666667e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.82411182e-04   2.12580082e-01   7.74606872e-01   1.22306348e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.00951808e-03   3.00571085e-04   9.86875063e-01   7.81484821e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.36574074e-03   5.20833333e-03   9.61226852e-01   2.71990741e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.42794456e-03   6.26871909e-04   9.82726196e-01   8.21898725e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.17096019e-02   7.02576112e-03   5.94847775e-01   3.86416862e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   835      0    320      0    150]
 [     0    523    766      0     21]
 [   183     21  27355      0    275]
 [     0      0      0 133958      0]
 [     5      3    254      0    165]]
Normalized confusion matrix
[[  6.39846743e-01   0.00000000e+00   2.45210728e-01   0.00000000e+00
    1.14942529e-01]
 [  0.00000000e+00   3.99236641e-01   5.84732824e-01   0.00000000e+00
    1.60305344e-02]
 [  6.57469282e-03   7.54472947e-04   9.82790831e-01   0.00000000e+00
    9.88000287e-03]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  1.17096019e-02   7.02576112e-03   5.94847775e-01   0.00000000e+00
    3.86416862e-01]]
