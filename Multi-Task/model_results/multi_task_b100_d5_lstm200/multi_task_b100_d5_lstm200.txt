______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_8 (InputLayer)                             (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_8[0][0]                                     
______________________________________________________________________________________________________________________________________________________
dropout_10 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_7 (InputLayer)                             (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_7 (TimeDistributed)             (None, 73, 54, 50)               25200             dropout_10[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_7 (Embedding)                          (None, 73, 300)                  17130300          input_7[0][0]                                     
______________________________________________________________________________________________________________________________________________________
time_distributed_8 (TimeDistributed)             (None, 73, 2700)                 0                 time_distributed_7[0][0]                          
______________________________________________________________________________________________________________________________________________________
concatenate_4 (Concatenate)                      (None, 73, 3000)                 0                 embedding_7[0][0]                                 
                                                                                                    time_distributed_8[0][0]                          
______________________________________________________________________________________________________________________________________________________
dropout_11 (Dropout)                             (None, 73, 3000)                 0                 concatenate_4[0][0]                               
______________________________________________________________________________________________________________________________________________________
bidirectional_8 (Bidirectional)                  (None, 73, 400)                  5121600           dropout_11[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_12 (Dropout)                             (None, 73, 400)                  0                 bidirectional_8[0][0]                             
______________________________________________________________________________________________________________________________________________________
dense_10 (Dense)                                 (None, 73, 28)                   11228             dropout_12[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_11 (Dense)                                 (None, 73, 11)                   4411              dropout_12[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_12 (Dense)                                 (None, 73, 5)                    2005              dropout_12[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_10 (CRF)                                     (None, 73, 28)                   1652              dense_10[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_11 (CRF)                                     (None, 73, 11)                   275               dense_11[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_12 (CRF)                                     (None, 73, 5)                    65                dense_12[0][0]                                    
======================================================================================================================================================
Total params: 22,313,236
Trainable params: 22,313,236
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1487s - loss: 0.5685 - crf_10_loss: 0.2597 - crf_11_loss: 0.2138 - crf_12_loss: 0.0951 - crf_10_acc_1: 0.9211 - crf_10_acc_2: 0.7702 - crf_10_acc_3: 0.7745 - crf_11_acc_1: 0.7707 - crf_11_acc_2: 0.9134 - crf_11_acc_3: 0.7731 - crf_12_acc_1: 0.7724 - crf_12_acc_2: 0.7698 - crf_12_acc_3: 0.9634 - val_loss: 0.2143 - val_crf_10_loss: 0.0946 - val_crf_11_loss: 0.0909 - val_crf_12_loss: 0.0288 - val_crf_10_acc_1: 0.9654 - val_crf_10_acc_2: 0.8130 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9461 - val_crf_11_acc_3: 0.8154 - val_crf_12_acc_1: 0.8133 - val_crf_12_acc_2: 0.8147 - val_crf_12_acc_3: 0.9841 - val_f1: 0.8235 - val_crf_10_f1: 0.8196 - val_crf_11_f1: 0.7235 - val_crf_12_f1: 0.9273
Epoch 2/25
 - 1470s - loss: 0.2112 - crf_10_loss: 0.1055 - crf_11_loss: 0.0783 - crf_12_loss: 0.0275 - crf_10_acc_1: 0.9555 - crf_10_acc_2: 0.7723 - crf_10_acc_3: 0.7757 - crf_11_acc_1: 0.7722 - crf_11_acc_2: 0.9464 - crf_11_acc_3: 0.7738 - crf_12_acc_1: 0.7749 - crf_12_acc_2: 0.7729 - crf_12_acc_3: 0.9809 - val_loss: 0.0984 - val_crf_10_loss: 0.0543 - val_crf_11_loss: 0.0381 - val_crf_12_loss: 0.0060 - val_crf_10_acc_1: 0.9727 - val_crf_10_acc_2: 0.8130 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9580 - val_crf_11_acc_3: 0.8155 - val_crf_12_acc_1: 0.8135 - val_crf_12_acc_2: 0.8147 - val_crf_12_acc_3: 0.9893 - val_f1: 0.8563 - val_crf_10_f1: 0.8553 - val_crf_11_f1: 0.7735 - val_crf_12_f1: 0.9400
Epoch 3/25
 - 1465s - loss: 0.1094 - crf_10_loss: 0.0644 - crf_11_loss: 0.0374 - crf_12_loss: 0.0076 - crf_10_acc_1: 0.9618 - crf_10_acc_2: 0.7723 - crf_10_acc_3: 0.7755 - crf_11_acc_1: 0.7722 - crf_11_acc_2: 0.9534 - crf_11_acc_3: 0.7737 - crf_12_acc_1: 0.7751 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9833 - val_loss: 0.0397 - val_crf_10_loss: 0.0308 - val_crf_11_loss: 0.0148 - val_crf_12_loss: -5.8628e-03 - val_crf_10_acc_1: 0.9743 - val_crf_10_acc_2: 0.8130 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9619 - val_crf_11_acc_3: 0.8152 - val_crf_12_acc_1: 0.8135 - val_crf_12_acc_2: 0.8150 - val_crf_12_acc_3: 0.9899 - val_f1: 0.8696 - val_crf_10_f1: 0.8683 - val_crf_11_f1: 0.7940 - val_crf_12_f1: 0.9466
Epoch 4/25
 - 1457s - loss: 0.0506 - crf_10_loss: 0.0409 - crf_11_loss: 0.0148 - crf_12_loss: -5.1560e-03 - crf_10_acc_1: 0.9647 - crf_10_acc_2: 0.7723 - crf_10_acc_3: 0.7755 - crf_11_acc_1: 0.7722 - crf_11_acc_2: 0.9564 - crf_11_acc_3: 0.7736 - crf_12_acc_1: 0.7752 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9843 - val_loss: 0.0121 - val_crf_10_loss: 0.0238 - val_crf_11_loss: 0.0019 - val_crf_12_loss: -1.3710e-02 - val_crf_10_acc_1: 0.9669 - val_crf_10_acc_2: 0.8130 - val_crf_10_acc_3: 0.8135 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9617 - val_crf_11_acc_3: 0.8155 - val_crf_12_acc_1: 0.8138 - val_crf_12_acc_2: 0.8147 - val_crf_12_acc_3: 0.9887 - val_f1: 0.8569 - val_crf_10_f1: 0.8414 - val_crf_11_f1: 0.7926 - val_crf_12_f1: 0.9365
Epoch 5/25
 - 1473s - loss: 0.0103 - crf_10_loss: 0.0251 - crf_11_loss: 1.3970e-04 - crf_12_loss: -1.4938e-02 - crf_10_acc_1: 0.9664 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7754 - crf_11_acc_1: 0.7722 - crf_11_acc_2: 0.9586 - crf_11_acc_3: 0.7735 - crf_12_acc_1: 0.7752 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9847 - val_loss: -2.5165e-02 - val_crf_10_loss: 0.0058 - val_crf_11_loss: -9.2756e-03 - val_crf_12_loss: -2.1692e-02 - val_crf_10_acc_1: 0.9773 - val_crf_10_acc_2: 0.8130 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9613 - val_crf_11_acc_3: 0.8151 - val_crf_12_acc_1: 0.8134 - val_crf_12_acc_2: 0.8148 - val_crf_12_acc_3: 0.9898 - val_f1: 0.8707 - val_crf_10_f1: 0.8793 - val_crf_11_f1: 0.7895 - val_crf_12_f1: 0.9435
Epoch 6/25
 - 1468s - loss: -2.1888e-02 - crf_10_loss: 0.0126 - crf_11_loss: -1.1057e-02 - crf_12_loss: -2.3395e-02 - crf_10_acc_1: 0.9678 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7754 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9599 - crf_11_acc_3: 0.7735 - crf_12_acc_1: 0.7752 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9847 - val_loss: -4.8488e-02 - val_crf_10_loss: -3.3916e-03 - val_crf_11_loss: -1.7233e-02 - val_crf_12_loss: -2.7863e-02 - val_crf_10_acc_1: 0.9766 - val_crf_10_acc_2: 0.8129 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9625 - val_crf_11_acc_3: 0.8151 - val_crf_12_acc_1: 0.8134 - val_crf_12_acc_2: 0.8152 - val_crf_12_acc_3: 0.9886 - val_f1: 0.8729 - val_crf_10_f1: 0.8807 - val_crf_11_f1: 0.7987 - val_crf_12_f1: 0.9392
Epoch 7/25
 - 1469s - loss: -4.9585e-02 - crf_10_loss: 0.0022 - crf_11_loss: -2.0506e-02 - crf_12_loss: -3.1308e-02 - crf_10_acc_1: 0.9689 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7754 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9611 - crf_11_acc_3: 0.7735 - crf_12_acc_1: 0.7752 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9848 - val_loss: -7.2033e-02 - val_crf_10_loss: -1.0718e-02 - val_crf_11_loss: -2.5532e-02 - val_crf_12_loss: -3.5782e-02 - val_crf_10_acc_1: 0.9774 - val_crf_10_acc_2: 0.8130 - val_crf_10_acc_3: 0.8135 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9612 - val_crf_11_acc_3: 0.8151 - val_crf_12_acc_1: 0.8135 - val_crf_12_acc_2: 0.8151 - val_crf_12_acc_3: 0.9878 - val_f1: 0.8673 - val_crf_10_f1: 0.8816 - val_crf_11_f1: 0.7905 - val_crf_12_f1: 0.9300
Epoch 8/25
 - 1467s - loss: -7.4807e-02 - crf_10_loss: -7.0106e-03 - crf_11_loss: -2.8991e-02 - crf_12_loss: -3.8805e-02 - crf_10_acc_1: 0.9696 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7754 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9627 - crf_11_acc_3: 0.7734 - crf_12_acc_1: 0.7753 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9847 - val_loss: -9.6572e-02 - val_crf_10_loss: -1.8718e-02 - val_crf_11_loss: -3.4811e-02 - val_crf_12_loss: -4.3043e-02 - val_crf_10_acc_1: 0.9772 - val_crf_10_acc_2: 0.8131 - val_crf_10_acc_3: 0.8135 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9665 - val_crf_11_acc_3: 0.8152 - val_crf_12_acc_1: 0.8134 - val_crf_12_acc_2: 0.8153 - val_crf_12_acc_3: 0.9876 - val_f1: 0.8775 - val_crf_10_f1: 0.8817 - val_crf_11_f1: 0.8238 - val_crf_12_f1: 0.9269
Epoch 9/25
 - 1483s - loss: -9.8468e-02 - crf_10_loss: -1.5532e-02 - crf_11_loss: -3.6874e-02 - crf_12_loss: -4.6062e-02 - crf_10_acc_1: 0.9705 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7754 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9634 - crf_11_acc_3: 0.7734 - crf_12_acc_1: 0.7753 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9849 - val_loss: -1.1519e-01 - val_crf_10_loss: -2.4204e-02 - val_crf_11_loss: -4.1249e-02 - val_crf_12_loss: -4.9736e-02 - val_crf_10_acc_1: 0.9765 - val_crf_10_acc_2: 0.8132 - val_crf_10_acc_3: 0.8135 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9657 - val_crf_11_acc_3: 0.8153 - val_crf_12_acc_1: 0.8134 - val_crf_12_acc_2: 0.8150 - val_crf_12_acc_3: 0.9852 - val_f1: 0.8683 - val_crf_10_f1: 0.8809 - val_crf_11_f1: 0.8168 - val_crf_12_f1: 0.9071
Epoch 10/25
 - 1470s - loss: -1.2143e-01 - crf_10_loss: -2.3635e-02 - crf_11_loss: -4.4507e-02 - crf_12_loss: -5.3284e-02 - crf_10_acc_1: 0.9710 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7754 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9648 - crf_11_acc_3: 0.7734 - crf_12_acc_1: 0.7753 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9847 - val_loss: -1.3406e-01 - val_crf_10_loss: -3.2218e-02 - val_crf_11_loss: -4.6885e-02 - val_crf_12_loss: -5.4961e-02 - val_crf_10_acc_1: 0.9776 - val_crf_10_acc_2: 0.8132 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9669 - val_crf_11_acc_3: 0.8152 - val_crf_12_acc_1: 0.8135 - val_crf_12_acc_2: 0.8151 - val_crf_12_acc_3: 0.9849 - val_f1: 0.8705 - val_crf_10_f1: 0.8836 - val_crf_11_f1: 0.8243 - val_crf_12_f1: 0.9036
Epoch 11/25
 - 1464s - loss: -1.4378e-01 - crf_10_loss: -3.1503e-02 - crf_11_loss: -5.1923e-02 - crf_12_loss: -6.0350e-02 - crf_10_acc_1: 0.9720 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7754 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9660 - crf_11_acc_3: 0.7734 - crf_12_acc_1: 0.7753 - crf_12_acc_2: 0.7731 - crf_12_acc_3: 0.9846 - val_loss: -1.5623e-01 - val_crf_10_loss: -4.0116e-02 - val_crf_11_loss: -5.4099e-02 - val_crf_12_loss: -6.2018e-02 - val_crf_10_acc_1: 0.9784 - val_crf_10_acc_2: 0.8129 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9646 - val_crf_11_acc_3: 0.8153 - val_crf_12_acc_1: 0.8134 - val_crf_12_acc_2: 0.8153 - val_crf_12_acc_3: 0.9836 - val_f1: 0.8678 - val_crf_10_f1: 0.8876 - val_crf_11_f1: 0.8164 - val_crf_12_f1: 0.8993
Epoch 12/25
 - 1486s - loss: -1.6560e-01 - crf_10_loss: -3.9111e-02 - crf_11_loss: -5.9089e-02 - crf_12_loss: -6.7396e-02 - crf_10_acc_1: 0.9723 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7753 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9665 - crf_11_acc_3: 0.7734 - crf_12_acc_1: 0.7753 - crf_12_acc_2: 0.7731 - crf_12_acc_3: 0.9849 - val_loss: -1.7804e-01 - val_crf_10_loss: -4.7234e-02 - val_crf_11_loss: -6.1191e-02 - val_crf_12_loss: -6.9611e-02 - val_crf_10_acc_1: 0.9790 - val_crf_10_acc_2: 0.8132 - val_crf_10_acc_3: 0.8134 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9657 - val_crf_11_acc_3: 0.8151 - val_crf_12_acc_1: 0.8136 - val_crf_12_acc_2: 0.8151 - val_crf_12_acc_3: 0.9866 - val_f1: 0.8709 - val_crf_10_f1: 0.8877 - val_crf_11_f1: 0.8156 - val_crf_12_f1: 0.9093
Epoch 13/25
 - 1470s - loss: -1.8703e-01 - crf_10_loss: -4.6418e-02 - crf_11_loss: -6.6241e-02 - crf_12_loss: -7.4367e-02 - crf_10_acc_1: 0.9729 - crf_10_acc_2: 0.7722 - crf_10_acc_3: 0.7753 - crf_11_acc_1: 0.7721 - crf_11_acc_2: 0.9676 - crf_11_acc_3: 0.7734 - crf_12_acc_1: 0.7753 - crf_12_acc_2: 0.7730 - crf_12_acc_3: 0.9850 - val_loss: -1.9631e-01 - val_crf_10_loss: -5.4249e-02 - val_crf_11_loss: -6.6813e-02 - val_crf_12_loss: -7.5249e-02 - val_crf_10_acc_1: 0.9777 - val_crf_10_acc_2: 0.8130 - val_crf_10_acc_3: 0.8135 - val_crf_11_acc_1: 0.8134 - val_crf_11_acc_2: 0.9635 - val_crf_11_acc_3: 0.8152 - val_crf_12_acc_1: 0.8134 - val_crf_12_acc_2: 0.8153 - val_crf_12_acc_3: 0.9829 - val_f1: 0.8647 - val_crf_10_f1: 0.8859 - val_crf_11_f1: 0.8104 - val_crf_12_f1: 0.8977

-------------------------------------------
Best F1 score: 0.877461651017   (epoch number 8)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9535    0.5541    0.7009       148
        archivalreference     0.7724    0.8910    0.8274       853
              archive_lib     0.8857    0.9029    0.8942       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9382    0.9384    0.9383      4948
                      box     0.8846    0.4182    0.5679       110
              cartulation     0.3333    0.5000    0.4000         8
              conjunction     0.5427    0.8060    0.6486       134
                     date     0.3800    0.6552    0.4810        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4792    0.8214    0.6053        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.2907    0.2083    0.2427       120
                        o     0.2522    0.3790    0.3029       752
               pagination     0.9131    0.9596    0.9358      1139
   publicationnumber-year     0.6488    0.8235    0.7258       646
         publicationplace     0.9332    0.9296    0.9314      1592
publicationspecifications     0.3325    0.3683    0.3495       372
                publisher     0.9392    0.8455    0.8899      1443
                      ref     0.4000    0.6667    0.5000         3
                 registry     0.8000    0.1039    0.1839       154
                   series     0.9286    0.6797    0.7849       153
                    title     0.9421    0.9385    0.9403     15560
                     tomo     0.8193    0.3036    0.4430       224
                   volume     0.5344    0.4765    0.5038       277
                     year     0.9544    0.7913    0.8652      2036

              avg / total     0.9801    0.9772    0.9778    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9535    0.5541    0.7009       148
        archivalreference     0.7724    0.8910    0.8274       853
              archive_lib     0.8857    0.9029    0.8942       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9382    0.9384    0.9383      4948
                      box     0.8846    0.4182    0.5679       110
              cartulation     0.3333    0.5000    0.4000         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5427    0.8060    0.6486       134
                     date     0.3800    0.6552    0.4810        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4792    0.8214    0.6053        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.2907    0.2083    0.2427       120
                        o     0.2522    0.3790    0.3029       752
               pagination     0.9131    0.9596    0.9358      1139
   publicationnumber-year     0.6488    0.8235    0.7258       646
         publicationplace     0.9332    0.9296    0.9314      1592
publicationspecifications     0.3325    0.3683    0.3495       372
                publisher     0.9392    0.8455    0.8899      1443
                      ref     0.4000    0.6667    0.5000         3
                 registry     0.8000    0.1039    0.1839       154
                   series     0.9286    0.6797    0.7849       153
                    title     0.9421    0.9385    0.9403     15560
                     tomo     0.8193    0.3036    0.4430       224
                   volume     0.5344    0.4765    0.5038       277
                     year     0.9544    0.7913    0.8652      2036

              avg / total     0.8939    0.8784    0.8817     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6912    0.6753    0.6831       348
        b-primary     0.7812    0.4762    0.5917       105
      b-secondary     0.7770    0.6749    0.7224       852
e-meta-annotation     0.8694    0.7842    0.8246      1061
        e-primary     0.7143    0.6667    0.6897       300
      e-secondary     0.8477    0.8626    0.8551      1717
i-meta-annotation     0.7917    0.8369    0.8137      9981
        i-primary     0.7700    0.8252    0.7966      1728
      i-secondary     0.8812    0.8346    0.8573     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.3043    0.5316    0.3870       427

      avg / total     0.9679    0.9665    0.9670    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6912    0.6753    0.6831       348
        b-primary     0.7812    0.4762    0.5917       105
      b-secondary     0.7770    0.6749    0.7224       852
e-meta-annotation     0.8694    0.7842    0.8246      1061
        e-primary     0.7143    0.6667    0.6897       300
      e-secondary     0.8477    0.8626    0.8551      1717
i-meta-annotation     0.7917    0.8369    0.8137      9981
        i-primary     0.7700    0.8252    0.7966      1728
      i-secondary     0.8812    0.8346    0.8573     14357
                o     0.3043    0.5316    0.3870       427

      avg / total     0.8288    0.8214    0.8238     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8457    0.7142    0.7744      1305
        e-r     0.9044    0.2527    0.3950      1310
        i-r     0.9518    0.9826    0.9670     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3363    0.5316    0.4120       427

avg / total     0.9882    0.9876    0.9863    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8457    0.7142    0.7744      1305
        e-r     0.9044    0.2527    0.3950      1310
        i-r     0.9518    0.9826    0.9670     27834
          o     0.3363    0.5316    0.4120       427

avg / total     0.9368    0.9340    0.9269     30876




Confusion matrix, without normalization
[[    37      0    103      8      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    15      7    828      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    17      0     86      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   904      3   4006     35      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    129      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     27      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     11      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2    107     10      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     8      2    490    252      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    114   1013     12      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2    643      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1588      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0    348     23      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1441      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    134     15      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   105      5  15301    149      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1    275      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     8    225   1645    158      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   6.95945946e-01   5.40540541e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.75849941e-02   8.20633060e-03   9.70691676e-01   3.51699883e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.65048544e-01   0.00000000e+00   8.34951456e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.82700081e-01   6.06305578e-04   8.09620049e-01   7.07356508e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.62686567e-01   3.73134328e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.57142857e-02   9.64285714e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.33333333e-02   9.16666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.33333333e-03   1.66666667e-02   8.91666667e-01   8.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.06382979e-02   2.65957447e-03   6.51595745e-01   3.35106383e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.00087796e-01   8.89376646e-01   1.05355575e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   3.09597523e-03   9.95356037e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.28140704e-04   9.97487437e-01   1.88442211e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   0.00000000e+00   9.35483871e-01   6.18279570e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.93000693e-04   9.98613999e-01   6.93000693e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   8.70129870e-01   9.74025974e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.74807198e-03   3.21336761e-04   9.83354756e-01   9.57583548e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.61010830e-03   9.92779783e-01   3.61010830e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.92927308e-03   1.10510806e-01   8.07956778e-01   7.76031434e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   277      0     36     35      0      0      0      0      0      0
       0]
 [    30      0     75      0      0      0      0      0      0      0
       0]
 [   625      0    122    105      0      0      0      0      0      0
       0]
 [     0    120    929     12      0      0      0      0      0      0
       0]
 [     0      2    274     24      0      0      0      0      0      0
       0]
 [     0    209   1494     14      0      0      0      0      0      0
       0]
 [    45      8   9841     87      0      0      0      0      0      0
       0]
 [     5     11   1639     73      0      0      0      0      0      0
       0]
 [   114     13  14132     98      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     6      3    191    227      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.95977011e-01   0.00000000e+00   1.03448276e-01   1.00574713e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.85714286e-01   0.00000000e+00   7.14285714e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.33568075e-01   0.00000000e+00   1.43192488e-01   1.23239437e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.13100848e-01   8.75589067e-01   1.13100848e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.66666667e-03   9.13333333e-01   8.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.21723937e-01   8.70122306e-01   8.15375655e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.50856628e-03   8.01522893e-04   9.85973349e-01   8.71656147e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.89351852e-03   6.36574074e-03   9.48495370e-01   4.22453704e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.94037752e-03   9.05481647e-04   9.84328202e-01   6.82593857e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.40515222e-02   7.02576112e-03   4.47306792e-01   5.31615925e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   932      0    233      0    140]
 [     0    331    960      0     19]
 [   164     32  27349      0    289]
 [     0      0      0 133958      0]
 [     6      3    191      0    227]]
Normalized confusion matrix
[[ 0.71417625  0.          0.17854406  0.          0.10727969]
 [ 0.          0.25267176  0.73282443  0.          0.01450382]
 [ 0.00589207  0.00114967  0.98257527  0.          0.01038298]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.01405152  0.00702576  0.44730679  0.          0.53161593]]
