______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_18 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_18[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_25 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_17 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_17 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_25[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_17 (Embedding)                         (None, 73, 300)                  17130300          input_17[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_18 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_17[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_9 (Concatenate)                      (None, 73, 3000)                 0                 embedding_17[0][0]                                
                                                                                                    time_distributed_18[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_26 (Dropout)                             (None, 73, 3000)                 0                 concatenate_9[0][0]                               
______________________________________________________________________________________________________________________________________________________
bidirectional_18 (Bidirectional)                 (None, 73, 80)                   973120            dropout_26[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_27 (Dropout)                             (None, 73, 80)                   0                 bidirectional_18[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_25 (Dense)                                 (None, 73, 28)                   2268              dropout_27[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_26 (Dense)                                 (None, 73, 11)                   891               dropout_27[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_27 (Dense)                                 (None, 73, 5)                    405               dropout_27[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_25 (CRF)                                     (None, 73, 28)                   1652              dense_25[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_26 (CRF)                                     (None, 73, 11)                   275               dense_26[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_27 (CRF)                                     (None, 73, 5)                    65                dense_27[0][0]                                    
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1542s - loss: 0.6639 - crf_25_loss: 0.3046 - crf_26_loss: 0.2445 - crf_27_loss: 0.1148 - crf_25_acc_1: 0.9126 - crf_25_acc_2: 0.7707 - crf_25_acc_3: 0.7746 - crf_26_acc_1: 0.7695 - crf_26_acc_2: 0.9059 - crf_26_acc_3: 0.7734 - crf_27_acc_1: 0.7708 - crf_27_acc_2: 0.7705 - crf_27_acc_3: 0.9592 - val_loss: 0.2267 - val_crf_25_loss: 0.1111 - val_crf_26_loss: 0.0889 - val_crf_27_loss: 0.0267 - val_crf_25_acc_1: 0.9600 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8134 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9544 - val_crf_26_acc_3: 0.8156 - val_crf_27_acc_1: 0.8131 - val_crf_27_acc_2: 0.8148 - val_crf_27_acc_3: 0.9886 - val_f1: 0.8218 - val_crf_25_f1: 0.7700 - val_crf_26_f1: 0.7567 - val_crf_27_f1: 0.9387
Epoch 2/25
 - 1518s - loss: 0.2275 - crf_25_loss: 0.1117 - crf_26_loss: 0.0821 - crf_27_loss: 0.0337 - crf_25_acc_1: 0.9548 - crf_25_acc_2: 0.7724 - crf_25_acc_3: 0.7758 - crf_26_acc_1: 0.7722 - crf_26_acc_2: 0.9467 - crf_26_acc_3: 0.7739 - crf_27_acc_1: 0.7750 - crf_27_acc_2: 0.7729 - crf_27_acc_3: 0.9811 - val_loss: 0.1152 - val_crf_25_loss: 0.0644 - val_crf_26_loss: 0.0409 - val_crf_27_loss: 0.0099 - val_crf_25_acc_1: 0.9680 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9589 - val_crf_26_acc_3: 0.8154 - val_crf_27_acc_1: 0.8133 - val_crf_27_acc_2: 0.8149 - val_crf_27_acc_3: 0.9910 - val_f1: 0.8514 - val_crf_25_f1: 0.8225 - val_crf_26_f1: 0.7808 - val_crf_27_f1: 0.9510
Epoch 3/25
 - 1519s - loss: 0.1179 - crf_25_loss: 0.0677 - crf_26_loss: 0.0378 - crf_27_loss: 0.0125 - crf_25_acc_1: 0.9619 - crf_25_acc_2: 0.7723 - crf_25_acc_3: 0.7756 - crf_26_acc_1: 0.7722 - crf_26_acc_2: 0.9546 - crf_26_acc_3: 0.7737 - crf_27_acc_1: 0.7752 - crf_27_acc_2: 0.7730 - crf_27_acc_3: 0.9841 - val_loss: 0.0530 - val_crf_25_loss: 0.0400 - val_crf_26_loss: 0.0147 - val_crf_27_loss: -1.7672e-03 - val_crf_25_acc_1: 0.9715 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9597 - val_crf_26_acc_3: 0.8154 - val_crf_27_acc_1: 0.8136 - val_crf_27_acc_2: 0.8146 - val_crf_27_acc_3: 0.9911 - val_f1: 0.8607 - val_crf_25_f1: 0.8494 - val_crf_26_f1: 0.7811 - val_crf_27_f1: 0.9515
Epoch 4/25
 - 1516s - loss: 0.0564 - crf_25_loss: 0.0436 - crf_26_loss: 0.0137 - crf_27_loss: -7.8446e-04 - crf_25_acc_1: 0.9652 - crf_25_acc_2: 0.7723 - crf_25_acc_3: 0.7755 - crf_26_acc_1: 0.7722 - crf_26_acc_2: 0.9589 - crf_26_acc_3: 0.7736 - crf_27_acc_1: 0.7753 - crf_27_acc_2: 0.7731 - crf_27_acc_3: 0.9855 - val_loss: 0.0162 - val_crf_25_loss: 0.0248 - val_crf_26_loss: 0.0017 - val_crf_27_loss: -1.0344e-02 - val_crf_25_acc_1: 0.9742 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8134 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9538 - val_crf_26_acc_3: 0.8153 - val_crf_27_acc_1: 0.8134 - val_crf_27_acc_2: 0.8158 - val_crf_27_acc_3: 0.9910 - val_f1: 0.8546 - val_crf_25_f1: 0.8592 - val_crf_26_f1: 0.7541 - val_crf_27_f1: 0.9504
Epoch 5/25
 - 1507s - loss: 0.0144 - crf_25_loss: 0.0272 - crf_26_loss: -1.9482e-03 - crf_27_loss: -1.0786e-02 - crf_25_acc_1: 0.9673 - crf_25_acc_2: 0.7722 - crf_25_acc_3: 0.7755 - crf_26_acc_1: 0.7721 - crf_26_acc_2: 0.9619 - crf_26_acc_3: 0.7735 - crf_27_acc_1: 0.7753 - crf_27_acc_2: 0.7731 - crf_27_acc_3: 0.9862 - val_loss: -1.6765e-02 - val_crf_25_loss: 0.0129 - val_crf_26_loss: -1.1941e-02 - val_crf_27_loss: -1.7680e-02 - val_crf_25_acc_1: 0.9748 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9617 - val_crf_26_acc_3: 0.8151 - val_crf_27_acc_1: 0.8134 - val_crf_27_acc_2: 0.8152 - val_crf_27_acc_3: 0.9896 - val_f1: 0.8680 - val_crf_25_f1: 0.8672 - val_crf_26_f1: 0.7933 - val_crf_27_f1: 0.9435
Epoch 6/25
 - 1511s - loss: -1.8385e-02 - crf_25_loss: 0.0145 - crf_26_loss: -1.3511e-02 - crf_27_loss: -1.9415e-02 - crf_25_acc_1: 0.9688 - crf_25_acc_2: 0.7722 - crf_25_acc_3: 0.7754 - crf_26_acc_1: 0.7721 - crf_26_acc_2: 0.9643 - crf_26_acc_3: 0.7735 - crf_27_acc_1: 0.7753 - crf_27_acc_2: 0.7730 - crf_27_acc_3: 0.9867 - val_loss: -4.1785e-02 - val_crf_25_loss: 0.0031 - val_crf_26_loss: -2.0349e-02 - val_crf_27_loss: -2.4490e-02 - val_crf_25_acc_1: 0.9746 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9600 - val_crf_26_acc_3: 0.8152 - val_crf_27_acc_1: 0.8136 - val_crf_27_acc_2: 0.8149 - val_crf_27_acc_3: 0.9896 - val_f1: 0.8627 - val_crf_25_f1: 0.8644 - val_crf_26_f1: 0.7817 - val_crf_27_f1: 0.9420
Epoch 7/25
 - 1508s - loss: -4.6734e-02 - crf_25_loss: 0.0040 - crf_26_loss: -2.3293e-02 - crf_27_loss: -2.7443e-02 - crf_25_acc_1: 0.9701 - crf_25_acc_2: 0.7722 - crf_25_acc_3: 0.7754 - crf_26_acc_1: 0.7721 - crf_26_acc_2: 0.9666 - crf_26_acc_3: 0.7735 - crf_27_acc_1: 0.7753 - crf_27_acc_2: 0.7731 - crf_27_acc_3: 0.9869 - val_loss: -6.3832e-02 - val_crf_25_loss: -3.4949e-03 - val_crf_26_loss: -2.8723e-02 - val_crf_27_loss: -3.1614e-02 - val_crf_25_acc_1: 0.9722 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9620 - val_crf_26_acc_3: 0.8153 - val_crf_27_acc_1: 0.8136 - val_crf_27_acc_2: 0.8152 - val_crf_27_acc_3: 0.9883 - val_f1: 0.8652 - val_crf_25_f1: 0.8594 - val_crf_26_f1: 0.8006 - val_crf_27_f1: 0.9356
Epoch 8/25
 - 1511s - loss: -7.2910e-02 - crf_25_loss: -5.7444e-03 - crf_26_loss: -3.2065e-02 - crf_27_loss: -3.5101e-02 - crf_25_acc_1: 0.9713 - crf_25_acc_2: 0.7722 - crf_25_acc_3: 0.7753 - crf_26_acc_1: 0.7721 - crf_26_acc_2: 0.9684 - crf_26_acc_3: 0.7734 - crf_27_acc_1: 0.7753 - crf_27_acc_2: 0.7731 - crf_27_acc_3: 0.9870 - val_loss: -8.2477e-02 - val_crf_25_loss: -1.0861e-02 - val_crf_26_loss: -3.4078e-02 - val_crf_27_loss: -3.7537e-02 - val_crf_25_acc_1: 0.9719 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9556 - val_crf_26_acc_3: 0.8153 - val_crf_27_acc_1: 0.8136 - val_crf_27_acc_2: 0.8149 - val_crf_27_acc_3: 0.9857 - val_f1: 0.8514 - val_crf_25_f1: 0.8608 - val_crf_26_f1: 0.7648 - val_crf_27_f1: 0.9285
Epoch 9/25
 - 1514s - loss: -9.7219e-02 - crf_25_loss: -1.4510e-02 - crf_26_loss: -4.0184e-02 - crf_27_loss: -4.2526e-02 - crf_25_acc_1: 0.9723 - crf_25_acc_2: 0.7722 - crf_25_acc_3: 0.7753 - crf_26_acc_1: 0.7721 - crf_26_acc_2: 0.9699 - crf_26_acc_3: 0.7734 - crf_27_acc_1: 0.7753 - crf_27_acc_2: 0.7731 - crf_27_acc_3: 0.9870 - val_loss: -1.0780e-01 - val_crf_25_loss: -1.8904e-02 - val_crf_26_loss: -4.3427e-02 - val_crf_27_loss: -4.5472e-02 - val_crf_25_acc_1: 0.9736 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9629 - val_crf_26_acc_3: 0.8153 - val_crf_27_acc_1: 0.8136 - val_crf_27_acc_2: 0.8148 - val_crf_27_acc_3: 0.9892 - val_f1: 0.8655 - val_crf_25_f1: 0.8616 - val_crf_26_f1: 0.7986 - val_crf_27_f1: 0.9363
Epoch 10/25
 - 1527s - loss: -1.2067e-01 - crf_25_loss: -2.2894e-02 - crf_26_loss: -4.7979e-02 - crf_27_loss: -4.9800e-02 - crf_25_acc_1: 0.9733 - crf_25_acc_2: 0.7721 - crf_25_acc_3: 0.7753 - crf_26_acc_1: 0.7721 - crf_26_acc_2: 0.9717 - crf_26_acc_3: 0.7734 - crf_27_acc_1: 0.7753 - crf_27_acc_2: 0.7731 - crf_27_acc_3: 0.9869 - val_loss: -1.2569e-01 - val_crf_25_loss: -2.5689e-02 - val_crf_26_loss: -4.8574e-02 - val_crf_27_loss: -5.1428e-02 - val_crf_25_acc_1: 0.9745 - val_crf_25_acc_2: 0.8130 - val_crf_25_acc_3: 0.8135 - val_crf_26_acc_1: 0.8134 - val_crf_26_acc_2: 0.9579 - val_crf_26_acc_3: 0.8154 - val_crf_27_acc_1: 0.8137 - val_crf_27_acc_2: 0.8148 - val_crf_27_acc_3: 0.9864 - val_f1: 0.8533 - val_crf_25_f1: 0.8686 - val_crf_26_f1: 0.7710 - val_crf_27_f1: 0.9203

-------------------------------------------
Best F1 score: 0.868006803246   (epoch number 5)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5270    0.6903       148
        archivalreference     0.8487    0.7890    0.8177       853
              archive_lib     0.9184    0.8738    0.8955       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9069    0.9309    0.9187      4948
                      box     0.8571    0.5455    0.6667       110
              cartulation     0.1356    1.0000    0.2388         8
              conjunction     0.5327    0.7910    0.6366       134
                     date     0.2673    0.4655    0.3396        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4375    0.5000    0.4667        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.2778    0.1667    0.2083       120
                        o     0.2301    0.3112    0.2646       752
               pagination     0.9168    0.9579    0.9369      1139
   publicationnumber-year     0.6218    0.8297    0.7109       646
         publicationplace     0.9176    0.8675    0.8918      1592
publicationspecifications     0.3333    0.3011    0.3164       372
                publisher     0.9333    0.7949    0.8585      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.9551    0.5556    0.7025       153
                    title     0.9253    0.9407    0.9330     15560
                     tomo     0.8136    0.2143    0.3392       224
                   volume     0.5414    0.5668    0.5538       277
                     year     0.9264    0.7790    0.8463      2036

              avg / total     0.9775    0.9748    0.9751    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5270    0.6903       148
        archivalreference     0.8487    0.7890    0.8177       853
              archive_lib     0.9184    0.8738    0.8955       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9069    0.9309    0.9187      4948
                      box     0.8571    0.5455    0.6667       110
              cartulation     0.1356    1.0000    0.2388         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5327    0.7910    0.6366       134
                     date     0.2673    0.4655    0.3396        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4375    0.5000    0.4667        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.2778    0.1667    0.2083       120
                        o     0.2301    0.3112    0.2646       752
               pagination     0.9168    0.9579    0.9369      1139
   publicationnumber-year     0.6218    0.8297    0.7109       646
         publicationplace     0.9176    0.8675    0.8918      1592
publicationspecifications     0.3333    0.3011    0.3164       372
                publisher     0.9333    0.7949    0.8585      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.9551    0.5556    0.7025       153
                    title     0.9253    0.9407    0.9330     15560
                     tomo     0.8136    0.2143    0.3392       224
                   volume     0.5414    0.5668    0.5538       277
                     year     0.9264    0.7790    0.8463      2036

              avg / total     0.8796    0.8657    0.8672     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7246    0.4914    0.5856       348
        b-primary     0.6471    0.2095    0.3165       105
      b-secondary     0.6625    0.6772    0.6698       852
e-meta-annotation     0.9226    0.6513    0.7635      1061
        e-primary     0.6125    0.4900    0.5444       300
      e-secondary     0.7614    0.8550    0.8055      1717
i-meta-annotation     0.8637    0.6981    0.7721      9981
        i-primary     0.8626    0.6904    0.7670      1728
      i-secondary     0.7892    0.9192    0.8493     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2043    0.3091    0.2460       427

      avg / total     0.9636    0.9617    0.9613    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7246    0.4914    0.5856       348
        b-primary     0.6471    0.2095    0.3165       105
      b-secondary     0.6625    0.6772    0.6698       852
e-meta-annotation     0.9226    0.6513    0.7635      1061
        e-primary     0.6125    0.4900    0.5444       300
      e-secondary     0.7614    0.8550    0.8055      1717
i-meta-annotation     0.8637    0.6981    0.7721      9981
        i-primary     0.8626    0.6904    0.7670      1728
      i-secondary     0.7892    0.9192    0.8493     14357
                o     0.2043    0.3091    0.2460       427

      avg / total     0.8059    0.7956    0.7933     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.7810    0.6805    0.7273      1305
        e-r     0.9414    0.6130    0.7425      1310
        i-r     0.9644    0.9819    0.9731     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2624    0.3349    0.2942       427

avg / total     0.9899    0.9896    0.9894    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.7810    0.6805    0.7273      1305
        e-r     0.9414    0.6130    0.7425      1310
        i-r     0.9644    0.9819    0.9731     27834
          o     0.2624    0.3349    0.2942       427

avg / total     0.9459    0.9446    0.9435     30876




Confusion matrix, without normalization
[[    39      0     99     10      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    14     15    810     14      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    17      0     80      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   898      6   3994     50      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      3    107      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2      6      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    128      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      4     54      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      2      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1     26      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2     10      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      6    106      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    11     12    580    149      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2    189    948      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2     17    627      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1590      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3    342     26      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0   1437      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      5    144      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   139     24  15301     96      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      7    217      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    275      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1    555   1302    178      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.63513514e-01   0.00000000e+00   6.68918919e-01   6.75675676e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.64126612e-02   1.75849941e-02   9.49589683e-01   1.64126612e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.65048544e-01   0.00000000e+00   7.76699029e-01   5.82524272e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.81487470e-01   1.21261116e-03   8.07194826e-01   1.01050930e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.72727273e-02   9.72727273e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.50000000e-01   7.50000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.55223881e-01   4.47761194e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.89655172e-02   9.31034483e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.33333333e-01   6.66666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   3.57142857e-02   9.28571429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.66666667e-01   8.33333333e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   5.00000000e-02   8.83333333e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.46276596e-02   1.59574468e-02   7.71276596e-01   1.98138298e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.75592625e-03   1.65935031e-01   8.32309043e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.09597523e-03   2.63157895e-02   9.70588235e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.28140704e-04   9.98743719e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   8.06451613e-03   9.19354839e-01   6.98924731e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.46500347e-03   0.00000000e+00   9.95841996e-01   6.93000693e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   3.24675325e-02   9.35064935e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.93316195e-03   1.54241645e-03   9.83354756e-01   6.16966581e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.12500000e-02   9.68750000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.92779783e-01   7.22021661e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.91159136e-04   2.72593320e-01   6.39489194e-01   8.74263261e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   260      0     41     47      0      0      0      0      0      0
       0]
 [    28      0     75      2      0      0      0      0      0      0
       0]
 [   600      0    131    121      0      0      0      0      0      0
       0]
 [     0    253    808      0      0      0      0      0      0      0
       0]
 [     0     28    268      4      0      0      0      0      0      0
       0]
 [     0    522   1177     18      0      0      0      0      0      0
       0]
 [    71      7   9819     84      0      0      0      0      0      0
       0]
 [    24     21   1645     38      0      0      0      0      0      0
       0]
 [   145     16  14108     88      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     9      6    269    143      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.47126437e-01   0.00000000e+00   1.17816092e-01   1.35057471e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.66666667e-01   0.00000000e+00   7.14285714e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.04225352e-01   0.00000000e+00   1.53755869e-01   1.42018779e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.38454288e-01   7.61545712e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   9.33333333e-02   8.93333333e-01   1.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.04018637e-01   6.85497962e-01   1.04834013e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.11351568e-03   7.01332532e-04   9.83769161e-01   8.41599038e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.38888889e-02   1.21527778e-02   9.51967593e-01   2.19907407e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.00996030e-02   1.11443895e-03   9.82656544e-01   6.12941422e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  2.10772834e-02   1.40515222e-02   6.29976581e-01   3.34894614e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   888      0    247      0    170]
 [     0    803    494      0     13]
 [   240     44  27331      0    219]
 [     0      0      0 133958      0]
 [     9      6    269      0    143]]
Normalized confusion matrix
[[ 0.68045977  0.          0.18927203  0.          0.1302682 ]
 [ 0.          0.6129771   0.37709924  0.          0.00992366]
 [ 0.00862255  0.0015808   0.98192858  0.          0.00786808]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.02107728  0.01405152  0.62997658  0.          0.33489461]]
