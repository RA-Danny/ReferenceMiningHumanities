______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_50 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_50[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_73 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_49 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_49 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_73[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_49 (Embedding)                         (None, 73, 300)                  17130300          input_49[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_50 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_49[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_25 (Concatenate)                     (None, 73, 3000)                 0                 embedding_49[0][0]                                
                                                                                                    time_distributed_50[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_74 (Dropout)                             (None, 73, 3000)                 0                 concatenate_25[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_50 (Bidirectional)                 (None, 73, 400)                  5121600           dropout_74[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_75 (Dropout)                             (None, 73, 400)                  0                 bidirectional_50[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_73 (Dense)                                 (None, 73, 28)                   11228             dropout_75[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_74 (Dense)                                 (None, 73, 11)                   4411              dropout_75[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_75 (Dense)                                 (None, 73, 5)                    2005              dropout_75[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_73 (CRF)                                     (None, 73, 28)                   1652              dense_73[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_74 (CRF)                                     (None, 73, 11)                   275               dense_74[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_75 (CRF)                                     (None, 73, 5)                    65                dense_75[0][0]                                    
======================================================================================================================================================
Total params: 22,313,236
Trainable params: 22,313,236
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 2664s - loss: 0.2836 - crf_73_loss: 0.1399 - crf_74_loss: 0.1188 - crf_75_loss: 0.0249 - crf_73_acc_1: 0.9481 - crf_73_acc_2: 0.7720 - crf_73_acc_3: 0.7738 - crf_74_acc_1: 0.7718 - crf_74_acc_2: 0.9373 - crf_74_acc_3: 0.7721 - crf_75_acc_1: 0.7745 - crf_75_acc_2: 0.7727 - crf_75_acc_3: 0.9750 - val_loss: 0.0332 - val_crf_73_loss: 0.0329 - val_crf_74_loss: 0.0179 - val_crf_75_loss: -1.7623e-02 - val_crf_73_acc_1: 0.9762 - val_crf_73_acc_2: 0.8131 - val_crf_73_acc_3: 0.8134 - val_crf_74_acc_1: 0.8134 - val_crf_74_acc_2: 0.9597 - val_crf_74_acc_3: 0.8152 - val_crf_75_acc_1: 0.8136 - val_crf_75_acc_2: 0.8152 - val_crf_75_acc_3: 0.9920 - val_f1: 0.8708 - val_crf_73_f1: 0.8722 - val_crf_74_f1: 0.7832 - val_crf_75_f1: 0.9570
Epoch 2/25
 - 2664s - loss: 6.7103e-04 - crf_73_loss: 0.0258 - crf_74_loss: 9.4896e-04 - crf_75_loss: -2.6112e-02 - crf_73_acc_1: 0.9677 - crf_73_acc_2: 0.7723 - crf_73_acc_3: 0.7755 - crf_74_acc_1: 0.7721 - crf_74_acc_2: 0.9587 - crf_74_acc_3: 0.7735 - crf_75_acc_1: 0.7753 - crf_75_acc_2: 0.7731 - crf_75_acc_3: 0.9859 - val_loss: -6.2790e-02 - val_crf_73_loss: -1.0901e-03 - val_crf_74_loss: -2.0232e-02 - val_crf_75_loss: -4.1468e-02 - val_crf_73_acc_1: 0.9752 - val_crf_73_acc_2: 0.8130 - val_crf_73_acc_3: 0.8135 - val_crf_74_acc_1: 0.8134 - val_crf_74_acc_2: 0.9624 - val_crf_74_acc_3: 0.8151 - val_crf_75_acc_1: 0.8133 - val_crf_75_acc_2: 0.8151 - val_crf_75_acc_3: 0.9901 - val_f1: 0.8733 - val_crf_73_f1: 0.8702 - val_crf_74_f1: 0.8009 - val_crf_75_f1: 0.9489
Epoch 3/25
 - 2596s - loss: -9.1462e-02 - crf_73_loss: -8.5276e-03 - crf_74_loss: -3.1717e-02 - crf_75_loss: -5.1218e-02 - crf_73_acc_1: 0.9713 - crf_73_acc_2: 0.7722 - crf_73_acc_3: 0.7754 - crf_74_acc_1: 0.7721 - crf_74_acc_2: 0.9632 - crf_74_acc_3: 0.7734 - crf_75_acc_1: 0.7753 - crf_75_acc_2: 0.7731 - crf_75_acc_3: 0.9871 - val_loss: -1.3713e-01 - val_crf_73_loss: -2.7030e-02 - val_crf_74_loss: -4.5723e-02 - val_crf_75_loss: -6.4381e-02 - val_crf_73_acc_1: 0.9786 - val_crf_73_acc_2: 0.8130 - val_crf_73_acc_3: 0.8135 - val_crf_74_acc_1: 0.8134 - val_crf_74_acc_2: 0.9653 - val_crf_74_acc_3: 0.8151 - val_crf_75_acc_1: 0.8135 - val_crf_75_acc_2: 0.8153 - val_crf_75_acc_3: 0.9905 - val_f1: 0.8829 - val_crf_73_f1: 0.8849 - val_crf_74_f1: 0.8150 - val_crf_75_f1: 0.9487
Epoch 4/25
 - 2614s - loss: -1.6564e-01 - crf_73_loss: -3.4671e-02 - crf_74_loss: -5.6389e-02 - crf_75_loss: -7.4585e-02 - crf_73_acc_1: 0.9738 - crf_73_acc_2: 0.7722 - crf_73_acc_3: 0.7754 - crf_74_acc_1: 0.7721 - crf_74_acc_2: 0.9663 - crf_74_acc_3: 0.7734 - crf_75_acc_1: 0.7753 - crf_75_acc_2: 0.7731 - crf_75_acc_3: 0.9878 - val_loss: -1.9672e-01 - val_crf_73_loss: -4.6986e-02 - val_crf_74_loss: -6.4718e-02 - val_crf_75_loss: -8.5015e-02 - val_crf_73_acc_1: 0.9786 - val_crf_73_acc_2: 0.8130 - val_crf_73_acc_3: 0.8135 - val_crf_74_acc_1: 0.8134 - val_crf_74_acc_2: 0.9613 - val_crf_74_acc_3: 0.8151 - val_crf_75_acc_1: 0.8136 - val_crf_75_acc_2: 0.8155 - val_crf_75_acc_3: 0.9881 - val_f1: 0.8719 - val_crf_73_f1: 0.8849 - val_crf_74_f1: 0.7946 - val_crf_75_f1: 0.9363
Epoch 5/25
 - 2614s - loss: -2.3486e-01 - crf_73_loss: -5.7907e-02 - crf_74_loss: -7.9387e-02 - crf_75_loss: -9.7562e-02 - crf_73_acc_1: 0.9758 - crf_73_acc_2: 0.7721 - crf_73_acc_3: 0.7753 - crf_74_acc_1: 0.7721 - crf_74_acc_2: 0.9697 - crf_74_acc_3: 0.7733 - crf_75_acc_1: 0.7753 - crf_75_acc_2: 0.7731 - crf_75_acc_3: 0.9879 - val_loss: -2.5989e-01 - val_crf_73_loss: -6.6083e-02 - val_crf_74_loss: -8.6857e-02 - val_crf_75_loss: -1.0695e-01 - val_crf_73_acc_1: 0.9755 - val_crf_73_acc_2: 0.8131 - val_crf_73_acc_3: 0.8135 - val_crf_74_acc_1: 0.8133 - val_crf_74_acc_2: 0.9647 - val_crf_74_acc_3: 0.8152 - val_crf_75_acc_1: 0.8135 - val_crf_75_acc_2: 0.8150 - val_crf_75_acc_3: 0.9866 - val_f1: 0.8725 - val_crf_73_f1: 0.8760 - val_crf_74_f1: 0.8137 - val_crf_75_f1: 0.9276
Epoch 6/25
 - 2662s - loss: -3.0223e-01 - crf_73_loss: -8.0000e-02 - crf_74_loss: -1.0184e-01 - crf_75_loss: -1.2039e-01 - crf_73_acc_1: 0.9775 - crf_73_acc_2: 0.7721 - crf_73_acc_3: 0.7753 - crf_74_acc_1: 0.7721 - crf_74_acc_2: 0.9728 - crf_74_acc_3: 0.7733 - crf_75_acc_1: 0.7753 - crf_75_acc_2: 0.7730 - crf_75_acc_3: 0.9876 - val_loss: -3.2324e-01 - val_crf_73_loss: -8.6505e-02 - val_crf_74_loss: -1.0765e-01 - val_crf_75_loss: -1.2908e-01 - val_crf_73_acc_1: 0.9783 - val_crf_73_acc_2: 0.8131 - val_crf_73_acc_3: 0.8135 - val_crf_74_acc_1: 0.8134 - val_crf_74_acc_2: 0.9622 - val_crf_74_acc_3: 0.8152 - val_crf_75_acc_1: 0.8135 - val_crf_75_acc_2: 0.8153 - val_crf_75_acc_3: 0.9847 - val_f1: 0.8637 - val_crf_73_f1: 0.8833 - val_crf_74_f1: 0.8030 - val_crf_75_f1: 0.9048
Epoch 7/25
 - 2604s - loss: -3.6862e-01 - crf_73_loss: -1.0141e-01 - crf_74_loss: -1.2408e-01 - crf_75_loss: -1.4313e-01 - crf_73_acc_1: 0.9792 - crf_73_acc_2: 0.7721 - crf_73_acc_3: 0.7753 - crf_74_acc_1: 0.7721 - crf_74_acc_2: 0.9752 - crf_74_acc_3: 0.7732 - crf_75_acc_1: 0.7753 - crf_75_acc_2: 0.7731 - crf_75_acc_3: 0.9879 - val_loss: -3.8284e-01 - val_crf_73_loss: -1.0317e-01 - val_crf_74_loss: -1.2839e-01 - val_crf_75_loss: -1.5127e-01 - val_crf_73_acc_1: 0.9765 - val_crf_73_acc_2: 0.8132 - val_crf_73_acc_3: 0.8135 - val_crf_74_acc_1: 0.8134 - val_crf_74_acc_2: 0.9637 - val_crf_74_acc_3: 0.8151 - val_crf_75_acc_1: 0.8136 - val_crf_75_acc_2: 0.8153 - val_crf_75_acc_3: 0.9850 - val_f1: 0.8640 - val_crf_73_f1: 0.8764 - val_crf_74_f1: 0.8092 - val_crf_75_f1: 0.9066
Epoch 8/25
 - 2616s - loss: -4.3406e-01 - crf_73_loss: -1.2253e-01 - crf_74_loss: -1.4592e-01 - crf_75_loss: -1.6562e-01 - crf_73_acc_1: 0.9808 - crf_73_acc_2: 0.7721 - crf_73_acc_3: 0.7753 - crf_74_acc_1: 0.7721 - crf_74_acc_2: 0.9770 - crf_74_acc_3: 0.7732 - crf_75_acc_1: 0.7753 - crf_75_acc_2: 0.7730 - crf_75_acc_3: 0.9882 - val_loss: -4.4186e-01 - val_crf_73_loss: -1.2304e-01 - val_crf_74_loss: -1.4760e-01 - val_crf_75_loss: -1.7121e-01 - val_crf_73_acc_1: 0.9759 - val_crf_73_acc_2: 0.8129 - val_crf_73_acc_3: 0.8135 - val_crf_74_acc_1: 0.8133 - val_crf_74_acc_2: 0.9610 - val_crf_74_acc_3: 0.8153 - val_crf_75_acc_1: 0.8135 - val_crf_75_acc_2: 0.8153 - val_crf_75_acc_3: 0.9838 - val_f1: 0.8560 - val_crf_73_f1: 0.8743 - val_crf_74_f1: 0.7944 - val_crf_75_f1: 0.8993

-------------------------------------------
Best F1 score: 0.882873715243   (epoch number 3)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5270    0.6903       148
        archivalreference     0.8418    0.8546    0.8482       853
              archive_lib     0.9375    0.8738    0.9045       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9522    0.9262    0.9390      4948
                      box     0.6984    0.4000    0.5087       110
              cartulation     0.4000    1.0000    0.5714         8
              conjunction     0.5536    0.6940    0.6159       134
                     date     0.4316    0.7069    0.5359        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4792    0.8214    0.6053        28
                foliation     0.6667    1.0000    0.8000        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.4255    0.1667    0.2395       120
                        o     0.3250    0.3816    0.3511       752
               pagination     0.9325    0.9824    0.9568      1139
   publicationnumber-year     0.6426    0.8684    0.7386       646
         publicationplace     0.9517    0.8794    0.9141      1592
publicationspecifications     0.3678    0.4113    0.3883       372
                publisher     0.9179    0.8441    0.8794      1443
                      ref     0.2000    0.6667    0.3077         3
                 registry     0.6154    0.1039    0.1778       154
                   series     0.9291    0.7712    0.8429       153
                    title     0.9274    0.9584    0.9427     15560
                     tomo     0.7541    0.2054    0.3228       224
                   volume     0.6157    0.5668    0.5902       277
                     year     0.9443    0.7996    0.8660      2036

              avg / total     0.9799    0.9786    0.9784    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     1.0000    0.5270    0.6903       148
        archivalreference     0.8418    0.8546    0.8482       853
              archive_lib     0.9375    0.8738    0.9045       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9522    0.9262    0.9390      4948
                      box     0.6984    0.4000    0.5087       110
              cartulation     0.4000    1.0000    0.5714         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5536    0.6940    0.6159       134
                     date     0.4316    0.7069    0.5359        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4792    0.8214    0.6053        28
                foliation     0.6667    1.0000    0.8000        12
             numbered_ref     0.4255    0.1667    0.2395       120
                        o     0.3250    0.3816    0.3511       752
               pagination     0.9325    0.9824    0.9568      1139
   publicationnumber-year     0.6426    0.8684    0.7386       646
         publicationplace     0.9517    0.8794    0.9141      1592
publicationspecifications     0.3678    0.4113    0.3883       372
                publisher     0.9179    0.8441    0.8794      1443
                      ref     0.2000    0.6667    0.3077         3
                 registry     0.6154    0.1039    0.1778       154
                   series     0.9291    0.7712    0.8429       153
                    title     0.9274    0.9584    0.9427     15560
                     tomo     0.7541    0.2054    0.3228       224
                   volume     0.6157    0.5668    0.5902       277
                     year     0.9443    0.7996    0.8660      2036

              avg / total     0.8925    0.8855    0.8849     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6959    0.6379    0.6657       348
        b-primary     0.6429    0.1714    0.2707       105
      b-secondary     0.7416    0.6972    0.7187       852
e-meta-annotation     0.8683    0.7455    0.8022      1061
        e-primary     0.6812    0.6267    0.6528       300
      e-secondary     0.7932    0.8777    0.8333      1717
i-meta-annotation     0.8167    0.7858    0.8010      9981
        i-primary     0.7902    0.7760    0.7831      1728
      i-secondary     0.8469    0.8653    0.8560     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.3408    0.5363    0.4167       427

      avg / total     0.9659    0.9653    0.9654    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6959    0.6379    0.6657       348
        b-primary     0.6429    0.1714    0.2707       105
      b-secondary     0.7416    0.6972    0.7187       852
e-meta-annotation     0.8683    0.7455    0.8022      1061
        e-primary     0.6812    0.6267    0.6528       300
      e-secondary     0.7932    0.8777    0.8333      1717
i-meta-annotation     0.8167    0.7858    0.8010      9981
        i-primary     0.7902    0.7760    0.7831      1728
      i-secondary     0.8469    0.8653    0.8560     14357
                o     0.3408    0.5363    0.4167       427

      avg / total     0.8178    0.8147    0.8150     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8169    0.7111    0.7603      1305
        e-r     0.9541    0.6183    0.7503      1310
        i-r     0.9672    0.9837    0.9754     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3413    0.4660    0.3941       427

avg / total     0.9909    0.9905    0.9904    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8169    0.7111    0.7603      1305
        e-r     0.9541    0.6183    0.7503      1310
        i-r     0.9672    0.9837    0.9754     27834
          o     0.3413    0.4660    0.3941       427

avg / total     0.9517    0.9495    0.9487     30876




Confusion matrix, without normalization
[[    36      0    112      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    11     12    810     20      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    13      0     90      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   916      2   3991     39      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2    108      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2      6      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    131      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      3     55      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     28      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2     10      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      3    109      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    11      8    520    213      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1    189    947      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     3     14    629      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      7   1580      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2    347     23      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1442      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      5    144      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   131     12  15324     93      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      7    216      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1    275      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5    578   1275    178      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.43243243e-01   0.00000000e+00   7.56756757e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.28956624e-02   1.40679953e-02   9.49589683e-01   2.34466589e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.26213592e-01   0.00000000e+00   8.73786408e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.85125303e-01   4.04203719e-04   8.06588521e-01   7.88197251e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.81818182e-02   9.81818182e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.50000000e-01   7.50000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.77611940e-01   2.23880597e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   5.17241379e-02   9.48275862e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.66666667e-01   8.33333333e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   2.50000000e-02   9.08333333e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.46276596e-02   1.06382979e-02   6.91489362e-01   2.83244681e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   1.65935031e-01   8.31431080e-01   1.75592625e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.64396285e-03   2.16718266e-02   9.73684211e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   4.39698492e-03   9.92462312e-01   2.51256281e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   5.37634409e-03   9.32795699e-01   6.18279570e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   0.00000000e+00   9.99306999e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   3.24675325e-02   9.35064935e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.41902314e-03   7.71208226e-04   9.84832905e-01   5.97686375e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.12500000e-02   9.64285714e-01   4.46428571e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.61010830e-03   9.92779783e-01   3.61010830e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.45579568e-03   2.83889980e-01   6.26227898e-01   8.74263261e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   275      0     33     40      0      0      0      0      0      0
       0]
 [    22      0     81      2      0      0      0      0      0      0
       0]
 [   631      0    108    113      0      0      0      0      0      0
       0]
 [     1    243    810      7      0      0      0      0      0      0
       0]
 [     1     21    277      1      0      0      0      0      0      0
       0]
 [     0    546   1159     12      0      0      0      0      0      0
       0]
 [    53      8   9845     75      0      0      0      0      0      0
       0]
 [    18     16   1655     39      0      0      0      0      0      0
       0]
 [   127     11  14124     95      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     8      4    216    199      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.90229885e-01   0.00000000e+00   9.48275862e-02   1.14942529e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.09523810e-01   0.00000000e+00   7.71428571e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.40610329e-01   0.00000000e+00   1.26760563e-01   1.32629108e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.42507069e-04   2.29029218e-01   7.63430726e-01   6.59754948e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.33333333e-03   7.00000000e-02   9.23333333e-01   3.33333333e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.17996506e-01   6.75014560e-01   6.98893419e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.31008917e-03   8.01522893e-04   9.86374111e-01   7.51427713e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.04166667e-02   9.25925926e-03   9.57754630e-01   2.25694444e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.84585916e-03   7.66176778e-04   9.83770983e-01   6.61698126e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.87353630e-02   9.36768150e-03   5.05854801e-01   4.66042155e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   928      0    222      0    155]
 [     0    810    490      0     10]
 [   200     35  27380      0    219]
 [     0      0      0 133958      0]
 [     8      4    216      0    199]]
Normalized confusion matrix
[[ 0.71111111  0.          0.17011494  0.          0.11877395]
 [ 0.          0.61832061  0.3740458   0.          0.00763359]
 [ 0.00718546  0.00125745  0.98368901  0.          0.00786808]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.01873536  0.00936768  0.5058548   0.          0.46604215]]
