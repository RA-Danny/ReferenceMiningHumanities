______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_40 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_40[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_58 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_39 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_39 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_58[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_39 (Embedding)                         (None, 73, 300)                  17130300          input_39[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_40 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_39[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_20 (Concatenate)                     (None, 73, 3000)                 0                 embedding_39[0][0]                                
                                                                                                    time_distributed_40[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_59 (Dropout)                             (None, 73, 3000)                 0                 concatenate_20[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_40 (Bidirectional)                 (None, 73, 200)                  2480800           dropout_59[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_60 (Dropout)                             (None, 73, 200)                  0                 bidirectional_40[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_58 (Dense)                                 (None, 73, 28)                   5628              dropout_60[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_59 (Dense)                                 (None, 73, 11)                   2211              dropout_60[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_60 (Dense)                                 (None, 73, 5)                    1005              dropout_60[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_58 (CRF)                                     (None, 73, 28)                   1652              dense_58[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_59 (CRF)                                     (None, 73, 11)                   275               dense_59[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_60 (CRF)                                     (None, 73, 5)                    65                dense_60[0][0]                                    
======================================================================================================================================================
Total params: 19,663,636
Trainable params: 19,663,636
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 2632s - loss: 0.4303 - crf_58_loss: 0.2212 - crf_59_loss: 0.1496 - crf_60_loss: 0.0595 - crf_58_acc_1: 0.9158 - crf_58_acc_2: 0.7725 - crf_58_acc_3: 0.7754 - crf_59_acc_1: 0.7716 - crf_59_acc_2: 0.9107 - crf_59_acc_3: 0.7740 - crf_60_acc_1: 0.7731 - crf_60_acc_2: 0.7722 - crf_60_acc_3: 0.9649 - val_loss: 0.0860 - val_crf_58_loss: 0.0589 - val_crf_59_loss: 0.0276 - val_crf_60_loss: -5.2042e-04 - val_crf_58_acc_1: 0.9563 - val_crf_58_acc_2: 0.8129 - val_crf_58_acc_3: 0.8133 - val_crf_59_acc_1: 0.8133 - val_crf_59_acc_2: 0.9466 - val_crf_59_acc_3: 0.8151 - val_crf_60_acc_1: 0.8129 - val_crf_60_acc_2: 0.8149 - val_crf_60_acc_3: 0.9865 - val_f1: 0.7981 - val_crf_58_f1: 0.7475 - val_crf_59_f1: 0.7148 - val_crf_60_f1: 0.9322
Epoch 2/25
 - 2604s - loss: 0.0785 - crf_58_loss: 0.0677 - crf_59_loss: 0.0184 - crf_60_loss: -7.5614e-03 - crf_58_acc_1: 0.9408 - crf_58_acc_2: 0.7725 - crf_58_acc_3: 0.7758 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9340 - crf_59_acc_3: 0.7740 - crf_60_acc_1: 0.7746 - crf_60_acc_2: 0.7731 - crf_60_acc_3: 0.9755 - val_loss: -3.0948e-02 - val_crf_58_loss: 0.0112 - val_crf_59_loss: -1.2965e-02 - val_crf_60_loss: -2.9177e-02 - val_crf_58_acc_1: 0.9672 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9517 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8133 - val_crf_60_acc_2: 0.8154 - val_crf_60_acc_3: 0.9873 - val_f1: 0.8303 - val_crf_58_f1: 0.8153 - val_crf_59_f1: 0.7451 - val_crf_60_f1: 0.9304
Epoch 3/25
 - 2650s - loss: -2.6580e-02 - crf_58_loss: 0.0240 - crf_59_loss: -1.6268e-02 - crf_60_loss: -3.4347e-02 - crf_58_acc_1: 0.9466 - crf_58_acc_2: 0.7724 - crf_58_acc_3: 0.7757 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9377 - crf_59_acc_3: 0.7739 - crf_60_acc_1: 0.7750 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9756 - val_loss: -1.0716e-01 - val_crf_58_loss: -1.9096e-02 - val_crf_59_loss: -3.6928e-02 - val_crf_60_loss: -5.1134e-02 - val_crf_58_acc_1: 0.9690 - val_crf_58_acc_2: 0.8132 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9527 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8153 - val_crf_60_acc_3: 0.9824 - val_f1: 0.8282 - val_crf_58_f1: 0.8356 - val_crf_59_f1: 0.7542 - val_crf_60_f1: 0.8950
Epoch 4/25
 - 2586s - loss: -1.0361e-01 - crf_58_loss: -4.1817e-03 - crf_59_loss: -4.1323e-02 - crf_60_loss: -5.8102e-02 - crf_58_acc_1: 0.9492 - crf_58_acc_2: 0.7725 - crf_58_acc_3: 0.7756 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9402 - crf_59_acc_3: 0.7738 - crf_60_acc_1: 0.7752 - crf_60_acc_2: 0.7731 - crf_60_acc_3: 0.9756 - val_loss: -1.7588e-01 - val_crf_58_loss: -4.1771e-02 - val_crf_59_loss: -6.0071e-02 - val_crf_60_loss: -7.4038e-02 - val_crf_58_acc_1: 0.9699 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8133 - val_crf_59_acc_2: 0.9571 - val_crf_59_acc_3: 0.8151 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8152 - val_crf_60_acc_3: 0.9832 - val_f1: 0.8370 - val_crf_58_f1: 0.8395 - val_crf_59_f1: 0.7751 - val_crf_60_f1: 0.8964
Epoch 5/25
 - 2585s - loss: -1.7341e-01 - crf_58_loss: -2.8223e-02 - crf_59_loss: -6.4203e-02 - crf_60_loss: -8.0980e-02 - crf_58_acc_1: 0.9509 - crf_58_acc_2: 0.7724 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9415 - crf_59_acc_3: 0.7738 - crf_60_acc_1: 0.7752 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9762 - val_loss: -2.4534e-01 - val_crf_58_loss: -6.5829e-02 - val_crf_59_loss: -8.2468e-02 - val_crf_60_loss: -9.7040e-02 - val_crf_58_acc_1: 0.9729 - val_crf_58_acc_2: 0.8131 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9557 - val_crf_59_acc_3: 0.8155 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8154 - val_crf_60_acc_3: 0.9845 - val_f1: 0.8396 - val_crf_58_f1: 0.8541 - val_crf_59_f1: 0.7654 - val_crf_60_f1: 0.8994
Epoch 6/25
 - 2576s - loss: -2.4043e-01 - crf_58_loss: -5.0468e-02 - crf_59_loss: -8.6418e-02 - crf_60_loss: -1.0354e-01 - crf_58_acc_1: 0.9520 - crf_58_acc_2: 0.7724 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9430 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7753 - crf_60_acc_2: 0.7731 - crf_60_acc_3: 0.9767 - val_loss: -3.1043e-01 - val_crf_58_loss: -8.5666e-02 - val_crf_59_loss: -1.0462e-01 - val_crf_60_loss: -1.2015e-01 - val_crf_58_acc_1: 0.9708 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9549 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8137 - val_crf_60_acc_2: 0.8148 - val_crf_60_acc_3: 0.9843 - val_f1: 0.8348 - val_crf_58_f1: 0.8484 - val_crf_59_f1: 0.7557 - val_crf_60_f1: 0.9004
Epoch 7/25
 - 2648s - loss: -3.0599e-01 - crf_58_loss: -7.1850e-02 - crf_59_loss: -1.0823e-01 - crf_60_loss: -1.2591e-01 - crf_58_acc_1: 0.9527 - crf_58_acc_2: 0.7724 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9440 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9770 - val_loss: -3.7337e-01 - val_crf_58_loss: -1.0641e-01 - val_crf_59_loss: -1.2557e-01 - val_crf_60_loss: -1.4139e-01 - val_crf_58_acc_1: 0.9692 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8133 - val_crf_59_acc_2: 0.9563 - val_crf_59_acc_3: 0.8153 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8150 - val_crf_60_acc_3: 0.9817 - val_f1: 0.8375 - val_crf_58_f1: 0.8473 - val_crf_59_f1: 0.7739 - val_crf_60_f1: 0.8912
Epoch 8/25
 - 2584s - loss: -3.7098e-01 - crf_58_loss: -9.2769e-02 - crf_59_loss: -1.2995e-01 - crf_60_loss: -1.4826e-01 - crf_58_acc_1: 0.9532 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9452 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7753 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9775 - val_loss: -4.4233e-01 - val_crf_58_loss: -1.2782e-01 - val_crf_59_loss: -1.4909e-01 - val_crf_60_loss: -1.6542e-01 - val_crf_58_acc_1: 0.9727 - val_crf_58_acc_2: 0.8134 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9580 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8150 - val_crf_60_acc_3: 0.9855 - val_f1: 0.8434 - val_crf_58_f1: 0.8543 - val_crf_59_f1: 0.7717 - val_crf_60_f1: 0.9040
Epoch 9/25
 - 2654s - loss: -4.3568e-01 - crf_58_loss: -1.1342e-01 - crf_59_loss: -1.5173e-01 - crf_60_loss: -1.7053e-01 - crf_58_acc_1: 0.9539 - crf_58_acc_2: 0.7724 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9461 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9775 - val_loss: -5.0567e-01 - val_crf_58_loss: -1.4950e-01 - val_crf_59_loss: -1.6951e-01 - val_crf_60_loss: -1.8666e-01 - val_crf_58_acc_1: 0.9731 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9593 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8150 - val_crf_60_acc_3: 0.9843 - val_f1: 0.8466 - val_crf_58_f1: 0.8569 - val_crf_59_f1: 0.7833 - val_crf_60_f1: 0.8997
Epoch 10/25
 - 2592s - loss: -5.0026e-01 - crf_58_loss: -1.3412e-01 - crf_59_loss: -1.7331e-01 - crf_60_loss: -1.9282e-01 - crf_58_acc_1: 0.9546 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9467 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9779 - val_loss: -5.6898e-01 - val_crf_58_loss: -1.6827e-01 - val_crf_59_loss: -1.9158e-01 - val_crf_60_loss: -2.0913e-01 - val_crf_58_acc_1: 0.9711 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8133 - val_crf_59_acc_2: 0.9596 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8152 - val_crf_60_acc_3: 0.9833 - val_f1: 0.8463 - val_crf_58_f1: 0.8514 - val_crf_59_f1: 0.7904 - val_crf_60_f1: 0.8971
Epoch 11/25
 - 2649s - loss: -5.6447e-01 - crf_58_loss: -1.5435e-01 - crf_59_loss: -1.9502e-01 - crf_60_loss: -2.1510e-01 - crf_58_acc_1: 0.9547 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7754 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9472 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9781 - val_loss: -6.3365e-01 - val_crf_58_loss: -1.8908e-01 - val_crf_59_loss: -2.1267e-01 - val_crf_60_loss: -2.3189e-01 - val_crf_58_acc_1: 0.9718 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9545 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8147 - val_crf_60_acc_3: 0.9845 - val_f1: 0.8355 - val_crf_58_f1: 0.8571 - val_crf_59_f1: 0.7490 - val_crf_60_f1: 0.9003
Epoch 12/25
 - 2593s - loss: -6.2847e-01 - crf_58_loss: -1.7470e-01 - crf_59_loss: -2.1649e-01 - crf_60_loss: -2.3728e-01 - crf_58_acc_1: 0.9554 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9471 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9783 - val_loss: -6.9908e-01 - val_crf_58_loss: -2.0971e-01 - val_crf_59_loss: -2.3489e-01 - val_crf_60_loss: -2.5448e-01 - val_crf_58_acc_1: 0.9724 - val_crf_58_acc_2: 0.8133 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9570 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8149 - val_crf_60_acc_3: 0.9839 - val_f1: 0.8405 - val_crf_58_f1: 0.8563 - val_crf_59_f1: 0.7659 - val_crf_60_f1: 0.8994
Epoch 13/25
 - 2598s - loss: -6.9254e-01 - crf_58_loss: -1.9497e-01 - crf_59_loss: -2.3809e-01 - crf_60_loss: -2.5948e-01 - crf_58_acc_1: 0.9557 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9482 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7753 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9784 - val_loss: -7.6339e-01 - val_crf_58_loss: -2.2959e-01 - val_crf_59_loss: -2.5692e-01 - val_crf_60_loss: -2.7689e-01 - val_crf_58_acc_1: 0.9727 - val_crf_58_acc_2: 0.8134 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9600 - val_crf_59_acc_3: 0.8151 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8152 - val_crf_60_acc_3: 0.9843 - val_f1: 0.8494 - val_crf_58_f1: 0.8589 - val_crf_59_f1: 0.7885 - val_crf_60_f1: 0.9010
Epoch 14/25
 - 2591s - loss: -7.5629e-01 - crf_58_loss: -2.1502e-01 - crf_59_loss: -2.5964e-01 - crf_60_loss: -2.8163e-01 - crf_58_acc_1: 0.9559 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9489 - crf_59_acc_3: 0.7737 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9785 - val_loss: -8.2755e-01 - val_crf_58_loss: -2.5002e-01 - val_crf_59_loss: -2.7829e-01 - val_crf_60_loss: -2.9924e-01 - val_crf_58_acc_1: 0.9741 - val_crf_58_acc_2: 0.8134 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9583 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8154 - val_crf_60_acc_3: 0.9853 - val_f1: 0.8481 - val_crf_58_f1: 0.8629 - val_crf_59_f1: 0.7781 - val_crf_60_f1: 0.9033
Epoch 15/25
 - 2593s - loss: -8.1987e-01 - crf_58_loss: -2.3506e-01 - crf_59_loss: -2.8103e-01 - crf_60_loss: -3.0378e-01 - crf_58_acc_1: 0.9562 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9493 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9787 - val_loss: -8.9150e-01 - val_crf_58_loss: -2.7022e-01 - val_crf_59_loss: -3.0009e-01 - val_crf_60_loss: -3.2119e-01 - val_crf_58_acc_1: 0.9741 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9604 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8152 - val_crf_60_acc_3: 0.9850 - val_f1: 0.8520 - val_crf_58_f1: 0.8648 - val_crf_59_f1: 0.7894 - val_crf_60_f1: 0.9019
Epoch 16/25
 - 2651s - loss: -8.8350e-01 - crf_58_loss: -2.5505e-01 - crf_59_loss: -3.0253e-01 - crf_60_loss: -3.2592e-01 - crf_58_acc_1: 0.9563 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7754 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9492 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7753 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9789 - val_loss: -9.5502e-01 - val_crf_58_loss: -2.9035e-01 - val_crf_59_loss: -3.2124e-01 - val_crf_60_loss: -3.4343e-01 - val_crf_58_acc_1: 0.9739 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9583 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8149 - val_crf_60_acc_3: 0.9848 - val_f1: 0.8466 - val_crf_58_f1: 0.8644 - val_crf_59_f1: 0.7735 - val_crf_60_f1: 0.9020
Epoch 17/25
 - 2647s - loss: -9.4713e-01 - crf_58_loss: -2.7502e-01 - crf_59_loss: -3.2401e-01 - crf_60_loss: -3.4810e-01 - crf_58_acc_1: 0.9565 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9497 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7754 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9790 - val_loss: -1.0173e+00 - val_crf_58_loss: -3.0924e-01 - val_crf_59_loss: -3.4271e-01 - val_crf_60_loss: -3.6540e-01 - val_crf_58_acc_1: 0.9735 - val_crf_58_acc_2: 0.8133 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9607 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8154 - val_crf_60_acc_3: 0.9848 - val_f1: 0.8526 - val_crf_58_f1: 0.8624 - val_crf_59_f1: 0.7930 - val_crf_60_f1: 0.9025
Epoch 18/25
 - 2593s - loss: -1.0105e+00 - crf_58_loss: -2.9502e-01 - crf_59_loss: -3.4533e-01 - crf_60_loss: -3.7019e-01 - crf_58_acc_1: 0.9565 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9496 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7753 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9790 - val_loss: -1.0831e+00 - val_crf_58_loss: -3.3064e-01 - val_crf_59_loss: -3.6463e-01 - val_crf_60_loss: -3.8778e-01 - val_crf_58_acc_1: 0.9751 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9614 - val_crf_59_acc_3: 0.8153 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8150 - val_crf_60_acc_3: 0.9850 - val_f1: 0.8535 - val_crf_58_f1: 0.8652 - val_crf_59_f1: 0.7929 - val_crf_60_f1: 0.9025
Epoch 19/25
 - 2597s - loss: -1.0743e+00 - crf_58_loss: -3.1502e-01 - crf_59_loss: -3.6689e-01 - crf_60_loss: -3.9237e-01 - crf_58_acc_1: 0.9567 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9501 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7752 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9793 - val_loss: -1.1458e+00 - val_crf_58_loss: -3.4983e-01 - val_crf_59_loss: -3.8592e-01 - val_crf_60_loss: -4.1008e-01 - val_crf_58_acc_1: 0.9741 - val_crf_58_acc_2: 0.8131 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9606 - val_crf_59_acc_3: 0.8153 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8154 - val_crf_60_acc_3: 0.9851 - val_f1: 0.8518 - val_crf_58_f1: 0.8609 - val_crf_59_f1: 0.7920 - val_crf_60_f1: 0.9024
Epoch 20/25
 - 2575s - loss: -1.1377e+00 - crf_58_loss: -3.3494e-01 - crf_59_loss: -3.8825e-01 - crf_60_loss: -4.1447e-01 - crf_58_acc_1: 0.9570 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7754 - crf_59_acc_1: 0.7723 - crf_59_acc_2: 0.9502 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7752 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9791 - val_loss: -1.2092e+00 - val_crf_58_loss: -3.6993e-01 - val_crf_59_loss: -4.0720e-01 - val_crf_60_loss: -4.3207e-01 - val_crf_58_acc_1: 0.9744 - val_crf_58_acc_2: 0.8131 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9608 - val_crf_59_acc_3: 0.8153 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8153 - val_crf_60_acc_3: 0.9840 - val_f1: 0.8526 - val_crf_58_f1: 0.8653 - val_crf_59_f1: 0.7934 - val_crf_60_f1: 0.8991
Epoch 21/25
 - 2596s - loss: -1.2014e+00 - crf_58_loss: -3.5493e-01 - crf_59_loss: -4.0980e-01 - crf_60_loss: -4.3667e-01 - crf_58_acc_1: 0.9571 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9509 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7752 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9794 - val_loss: -1.2735e+00 - val_crf_58_loss: -3.8988e-01 - val_crf_59_loss: -4.2921e-01 - val_crf_60_loss: -4.5444e-01 - val_crf_58_acc_1: 0.9747 - val_crf_58_acc_2: 0.8133 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9646 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8136 - val_crf_60_acc_2: 0.8150 - val_crf_60_acc_3: 0.9857 - val_f1: 0.8608 - val_crf_58_f1: 0.8658 - val_crf_59_f1: 0.8109 - val_crf_60_f1: 0.9055
Epoch 22/25
 - 2651s - loss: -1.2643e+00 - crf_58_loss: -3.7462e-01 - crf_59_loss: -4.3103e-01 - crf_60_loss: -4.5866e-01 - crf_58_acc_1: 0.9571 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9513 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7751 - crf_60_acc_2: 0.7730 - crf_60_acc_3: 0.9795 - val_loss: -1.3370e+00 - val_crf_58_loss: -4.0987e-01 - val_crf_59_loss: -4.5043e-01 - val_crf_60_loss: -4.7672e-01 - val_crf_58_acc_1: 0.9752 - val_crf_58_acc_2: 0.8132 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9626 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8135 - val_crf_60_acc_2: 0.8152 - val_crf_60_acc_3: 0.9855 - val_f1: 0.8571 - val_crf_58_f1: 0.8649 - val_crf_59_f1: 0.8023 - val_crf_60_f1: 0.9040
Epoch 23/25
 - 2583s - loss: -1.3277e+00 - crf_58_loss: -3.9443e-01 - crf_59_loss: -4.5246e-01 - crf_60_loss: -4.8077e-01 - crf_58_acc_1: 0.9571 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7755 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9513 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7751 - crf_60_acc_2: 0.7729 - crf_60_acc_3: 0.9794 - val_loss: -1.4006e+00 - val_crf_58_loss: -4.2975e-01 - val_crf_59_loss: -4.7190e-01 - val_crf_60_loss: -4.9893e-01 - val_crf_58_acc_1: 0.9733 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9604 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8134 - val_crf_60_acc_2: 0.8153 - val_crf_60_acc_3: 0.9841 - val_f1: 0.8502 - val_crf_58_f1: 0.8600 - val_crf_59_f1: 0.7912 - val_crf_60_f1: 0.8994
Epoch 24/25
 - 2650s - loss: -1.3913e+00 - crf_58_loss: -4.1449e-01 - crf_59_loss: -4.7389e-01 - crf_60_loss: -5.0292e-01 - crf_58_acc_1: 0.9572 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7754 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9516 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7751 - crf_60_acc_2: 0.7729 - crf_60_acc_3: 0.9795 - val_loss: -1.4649e+00 - val_crf_58_loss: -4.4985e-01 - val_crf_59_loss: -4.9371e-01 - val_crf_60_loss: -5.2137e-01 - val_crf_58_acc_1: 0.9752 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8134 - val_crf_59_acc_2: 0.9631 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8134 - val_crf_60_acc_2: 0.8150 - val_crf_60_acc_3: 0.9857 - val_f1: 0.8576 - val_crf_58_f1: 0.8661 - val_crf_59_f1: 0.8017 - val_crf_60_f1: 0.9049
Epoch 25/25
 - 2591s - loss: -1.4546e+00 - crf_58_loss: -4.3443e-01 - crf_59_loss: -4.9517e-01 - crf_60_loss: -5.2495e-01 - crf_58_acc_1: 0.9574 - crf_58_acc_2: 0.7723 - crf_58_acc_3: 0.7754 - crf_59_acc_1: 0.7722 - crf_59_acc_2: 0.9516 - crf_59_acc_3: 0.7736 - crf_60_acc_1: 0.7750 - crf_60_acc_2: 0.7729 - crf_60_acc_3: 0.9795 - val_loss: -1.5290e+00 - val_crf_58_loss: -4.6992e-01 - val_crf_59_loss: -5.1535e-01 - val_crf_60_loss: -5.4377e-01 - val_crf_58_acc_1: 0.9743 - val_crf_58_acc_2: 0.8130 - val_crf_58_acc_3: 0.8134 - val_crf_59_acc_1: 0.8133 - val_crf_59_acc_2: 0.9604 - val_crf_59_acc_3: 0.8152 - val_crf_60_acc_1: 0.8134 - val_crf_60_acc_2: 0.8153 - val_crf_60_acc_3: 0.9858 - val_f1: 0.8522 - val_crf_58_f1: 0.8623 - val_crf_59_f1: 0.7891 - val_crf_60_f1: 0.9052

-------------------------------------------
Best F1 score: 0.860758561649   (epoch number 21)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9589    0.4730    0.6335       148
        archivalreference     0.6972    0.7937    0.7423       853
              archive_lib     0.8067    0.9320    0.8649       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9325    0.9236    0.9280      4948
                      box     0.8600    0.3909    0.5375       110
              cartulation     0.2667    1.0000    0.4211         8
              conjunction     0.5340    0.8209    0.6471       134
                     date     0.3529    0.9310    0.5118        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4107    0.8214    0.5476        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.2295    0.2333    0.2314       120
                        o     0.2862    0.3285    0.3059       752
               pagination     0.9301    0.9579    0.9438      1139
   publicationnumber-year     0.6783    0.7508    0.7127       646
         publicationplace     0.9377    0.8788    0.9073      1592
publicationspecifications     0.2222    0.1452    0.1756       372
                publisher     0.8958    0.8517    0.8732      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7736    0.5359    0.6332       153
                    title     0.9216    0.9342    0.9279     15560
                     tomo     0.8214    0.3080    0.4481       224
                   volume     0.4784    0.5596    0.5158       277
                     year     0.9189    0.8070    0.8593      2036

              avg / total     0.9766    0.9747    0.9749    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9589    0.4730    0.6335       148
        archivalreference     0.6972    0.7937    0.7423       853
              archive_lib     0.8067    0.9320    0.8649       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9325    0.9236    0.9280      4948
                      box     0.8600    0.3909    0.5375       110
              cartulation     0.2667    1.0000    0.4211         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5340    0.8209    0.6471       134
                     date     0.3529    0.9310    0.5118        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4107    0.8214    0.5476        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.2295    0.2333    0.2314       120
                        o     0.2862    0.3285    0.3059       752
               pagination     0.9301    0.9579    0.9438      1139
   publicationnumber-year     0.6783    0.7508    0.7127       646
         publicationplace     0.9377    0.8788    0.9073      1592
publicationspecifications     0.2222    0.1452    0.1756       372
                publisher     0.8958    0.8517    0.8732      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7736    0.5359    0.6332       153
                    title     0.9216    0.9342    0.9279     15560
                     tomo     0.8214    0.3080    0.4481       224
                   volume     0.4784    0.5596    0.5158       277
                     year     0.9189    0.8070    0.8593      2036

              avg / total     0.8748    0.8647    0.8658     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7480    0.5374    0.6254       348
        b-primary     0.8318    0.8476    0.8396       105
      b-secondary     0.7143    0.7042    0.7092       852
e-meta-annotation     0.8812    0.7549    0.8132      1061
        e-primary     0.6688    0.6933    0.6809       300
      e-secondary     0.8174    0.8550    0.8358      1717
i-meta-annotation     0.8337    0.7361    0.7818      9981
        i-primary     0.8221    0.8507    0.8362      1728
      i-secondary     0.8238    0.8867    0.8541     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2315    0.3302    0.2722       427

      avg / total     0.9653    0.9646    0.9646    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7480    0.5374    0.6254       348
        b-primary     0.8318    0.8476    0.8396       105
      b-secondary     0.7143    0.7042    0.7092       852
e-meta-annotation     0.8812    0.7549    0.8132      1061
        e-primary     0.6688    0.6933    0.6809       300
      e-secondary     0.8174    0.8550    0.8358      1717
i-meta-annotation     0.8337    0.7361    0.7818      9981
        i-primary     0.8221    0.8507    0.8362      1728
      i-secondary     0.8238    0.8867    0.8541     14357
                o     0.2315    0.3302    0.2722       427

      avg / total     0.8150    0.8110    0.8109     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8297    0.7502    0.7879      1305
        e-r     0.3111    0.0107    0.0207      1310
        i-r     0.9409    0.9832    0.9616     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2845    0.3770    0.3243       427

avg / total     0.9813    0.9857    0.9823    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8297    0.7502    0.7879      1305
        e-r     0.3111    0.0107    0.0207      1310
        i-r     0.9409    0.9832    0.9616     27834
          o     0.2845    0.3770    0.3243       427

avg / total     0.9004    0.9237    0.9055     30876




Confusion matrix, without normalization
[[    36      0    112      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    78      3    769      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    16      0     76     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   896      3   4032     17      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    129      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2     25      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      2    110      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    12      1    565    174      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      8   1128      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      3    637      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1590      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0    345     26      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1   1440      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    149      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   127      3  15289    141      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0    276      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0     18   1843    175      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.43243243e-01   0.00000000e+00   7.56756757e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.14419695e-02   3.51699883e-03   9.01524033e-01   3.51699883e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.55339806e-01   0.00000000e+00   7.37864078e-01   1.06796117e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.81083266e-01   6.06305578e-04   8.14874697e-01   3.43573161e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.62686567e-01   3.73134328e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   7.14285714e-02   8.92857143e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   1.66666667e-02   9.16666667e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.59574468e-02   1.32978723e-03   7.51329787e-01   2.31382979e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   7.02370500e-03   9.90342406e-01   1.75592625e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.09597523e-03   4.64396285e-03   9.86068111e-01   6.19195046e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   0.00000000e+00   9.98743719e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   0.00000000e+00   9.27419355e-01   6.98924731e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   6.93000693e-04   9.97920998e-01   6.93000693e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   9.67532468e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.16195373e-03   1.92802057e-04   9.82583548e-01   9.06169666e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.61010830e-03   0.00000000e+00   9.96389892e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.84086444e-03   9.05206287e-01   8.59528487e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   273      0     36     39      0      0      0      0      0      0
       0]
 [    92      0     12      1      0      0      0      0      0      0
       0]
 [   614      0    128    110      0      0      0      0      0      0
       0]
 [     1      4   1048      8      0      0      0      0      0      0
       0]
 [     0      0    293      7      0      0      0      0      0      0
       0]
 [     0     10   1694     13      0      0      0      0      0      0
       0]
 [    59      9   9842     71      0      0      0      0      0      0
       0]
 [     9      9   1684     26      0      0      0      0      0      0
       0]
 [   124     13  14090    130      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     8      0    258    161      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.84482759e-01   0.00000000e+00   1.03448276e-01   1.12068966e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.76190476e-01   0.00000000e+00   1.14285714e-01   9.52380952e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.20657277e-01   0.00000000e+00   1.50234742e-01   1.29107981e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.42507069e-04   3.77002828e-03   9.87747408e-01   7.54005655e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.76666667e-01   2.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   5.82411182e-03   9.86604543e-01   7.57134537e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.91123134e-03   9.01713255e-04   9.86073540e-01   7.11351568e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.20833333e-03   5.20833333e-03   9.74537037e-01   1.50462963e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.63690186e-03   9.05481647e-04   9.81402800e-01   9.05481647e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.87353630e-02   0.00000000e+00   6.04215457e-01   3.77049180e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   979      0    176      0    150]
 [     0     14   1284      0     12]
 [   193     31  27367      0    243]
 [     0      0      0 133958      0]
 [     8      0    258      0    161]]
Normalized confusion matrix
[[ 0.75019157  0.          0.1348659   0.          0.11494253]
 [ 0.          0.01068702  0.98015267  0.          0.00916031]
 [ 0.00693397  0.00111375  0.98322196  0.          0.00873033]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.01873536  0.          0.60421546  0.          0.37704918]]
