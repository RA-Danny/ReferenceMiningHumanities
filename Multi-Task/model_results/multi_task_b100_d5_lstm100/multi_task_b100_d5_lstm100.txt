______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_10 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_10[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_13 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_9 (InputLayer)                             (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_9 (TimeDistributed)             (None, 73, 54, 50)               25200             dropout_13[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_9 (Embedding)                          (None, 73, 300)                  17130300          input_9[0][0]                                     
______________________________________________________________________________________________________________________________________________________
time_distributed_10 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_9[0][0]                          
______________________________________________________________________________________________________________________________________________________
concatenate_5 (Concatenate)                      (None, 73, 3000)                 0                 embedding_9[0][0]                                 
                                                                                                    time_distributed_10[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_14 (Dropout)                             (None, 73, 3000)                 0                 concatenate_5[0][0]                               
______________________________________________________________________________________________________________________________________________________
bidirectional_10 (Bidirectional)                 (None, 73, 200)                  2480800           dropout_14[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_15 (Dropout)                             (None, 73, 200)                  0                 bidirectional_10[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_13 (Dense)                                 (None, 73, 28)                   5628              dropout_15[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_14 (Dense)                                 (None, 73, 11)                   2211              dropout_15[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_15 (Dense)                                 (None, 73, 5)                    1005              dropout_15[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_13 (CRF)                                     (None, 73, 28)                   1652              dense_13[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_14 (CRF)                                     (None, 73, 11)                   275               dense_14[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_15 (CRF)                                     (None, 73, 5)                    65                dense_15[0][0]                                    
======================================================================================================================================================
Total params: 19,663,636
Trainable params: 19,663,636
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1474s - loss: 0.5802 - crf_13_loss: 0.2679 - crf_14_loss: 0.2349 - crf_15_loss: 0.0774 - crf_13_acc_1: 0.9165 - crf_13_acc_2: 0.7712 - crf_13_acc_3: 0.7743 - crf_14_acc_1: 0.7706 - crf_14_acc_2: 0.9082 - crf_14_acc_3: 0.7731 - crf_15_acc_1: 0.7721 - crf_15_acc_2: 0.7709 - crf_15_acc_3: 0.9615 - val_loss: 0.2119 - val_crf_13_loss: 0.1036 - val_crf_14_loss: 0.0913 - val_crf_15_loss: 0.0170 - val_crf_13_acc_1: 0.9590 - val_crf_13_acc_2: 0.8129 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8133 - val_crf_14_acc_2: 0.9538 - val_crf_14_acc_3: 0.8154 - val_crf_15_acc_1: 0.8134 - val_crf_15_acc_2: 0.8148 - val_crf_15_acc_3: 0.9886 - val_f1: 0.8212 - val_crf_13_f1: 0.7651 - val_crf_14_f1: 0.7581 - val_crf_15_f1: 0.9402
Epoch 2/25
 - 1452s - loss: 0.2212 - crf_13_loss: 0.1130 - crf_14_loss: 0.0870 - crf_15_loss: 0.0212 - crf_13_acc_1: 0.9514 - crf_13_acc_2: 0.7724 - crf_13_acc_3: 0.7758 - crf_14_acc_1: 0.7723 - crf_14_acc_2: 0.9439 - crf_14_acc_3: 0.7740 - crf_15_acc_1: 0.7747 - crf_15_acc_2: 0.7729 - crf_15_acc_3: 0.9794 - val_loss: 0.1182 - val_crf_13_loss: 0.0623 - val_crf_14_loss: 0.0490 - val_crf_15_loss: 0.0069 - val_crf_13_acc_1: 0.9665 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9495 - val_crf_14_acc_3: 0.8154 - val_crf_15_acc_1: 0.8133 - val_crf_15_acc_2: 0.8147 - val_crf_15_acc_3: 0.9838 - val_f1: 0.8298 - val_crf_13_f1: 0.8297 - val_crf_14_f1: 0.7328 - val_crf_15_f1: 0.9270
Epoch 3/25
 - 1451s - loss: 0.1185 - crf_13_loss: 0.0716 - crf_14_loss: 0.0420 - crf_15_loss: 0.0049 - crf_13_acc_1: 0.9582 - crf_13_acc_2: 0.7724 - crf_13_acc_3: 0.7756 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9508 - crf_14_acc_3: 0.7738 - crf_15_acc_1: 0.7751 - crf_15_acc_2: 0.7731 - crf_15_acc_3: 0.9818 - val_loss: 0.0470 - val_crf_13_loss: 0.0374 - val_crf_14_loss: 0.0164 - val_crf_15_loss: -6.8503e-03 - val_crf_13_acc_1: 0.9708 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9604 - val_crf_14_acc_3: 0.8153 - val_crf_15_acc_1: 0.8135 - val_crf_15_acc_2: 0.8148 - val_crf_15_acc_3: 0.9901 - val_f1: 0.8583 - val_crf_13_f1: 0.8451 - val_crf_14_f1: 0.7851 - val_crf_15_f1: 0.9447
Epoch 4/25
 - 1445s - loss: 0.0596 - crf_13_loss: 0.0479 - crf_14_loss: 0.0176 - crf_15_loss: -5.9797e-03 - crf_13_acc_1: 0.9611 - crf_13_acc_2: 0.7723 - crf_13_acc_3: 0.7755 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9539 - crf_14_acc_3: 0.7737 - crf_15_acc_1: 0.7751 - crf_15_acc_2: 0.7731 - crf_15_acc_3: 0.9826 - val_loss: 0.0069 - val_crf_13_loss: 0.0211 - val_crf_14_loss: 3.2282e-04 - val_crf_15_loss: -1.4571e-02 - val_crf_13_acc_1: 0.9726 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9607 - val_crf_14_acc_3: 0.8153 - val_crf_15_acc_1: 0.8135 - val_crf_15_acc_2: 0.8151 - val_crf_15_acc_3: 0.9884 - val_f1: 0.8649 - val_crf_13_f1: 0.8610 - val_crf_14_f1: 0.7937 - val_crf_15_f1: 0.9400
Epoch 5/25
 - 1461s - loss: 0.0188 - crf_13_loss: 0.0318 - crf_14_loss: 0.0020 - crf_15_loss: -1.5004e-02 - crf_13_acc_1: 0.9630 - crf_13_acc_2: 0.7723 - crf_13_acc_3: 0.7755 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9562 - crf_14_acc_3: 0.7736 - crf_15_acc_1: 0.7752 - crf_15_acc_2: 0.7731 - crf_15_acc_3: 0.9829 - val_loss: -2.5753e-02 - val_crf_13_loss: 0.0085 - val_crf_14_loss: -1.1975e-02 - val_crf_15_loss: -2.2303e-02 - val_crf_13_acc_1: 0.9769 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9648 - val_crf_14_acc_3: 0.8152 - val_crf_15_acc_1: 0.8135 - val_crf_15_acc_2: 0.8151 - val_crf_15_acc_3: 0.9890 - val_f1: 0.8762 - val_crf_13_f1: 0.8777 - val_crf_14_f1: 0.8122 - val_crf_15_f1: 0.9386
Epoch 6/25
 - 1445s - loss: -1.3163e-02 - crf_13_loss: 0.0196 - crf_14_loss: -9.6603e-03 - crf_15_loss: -2.3146e-02 - crf_13_acc_1: 0.9643 - crf_13_acc_2: 0.7723 - crf_13_acc_3: 0.7754 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9578 - crf_14_acc_3: 0.7736 - crf_15_acc_1: 0.7752 - crf_15_acc_2: 0.7731 - crf_15_acc_3: 0.9831 - val_loss: -4.8967e-02 - val_crf_13_loss: 8.5464e-04 - val_crf_14_loss: -2.0471e-02 - val_crf_15_loss: -2.9351e-02 - val_crf_13_acc_1: 0.9750 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9608 - val_crf_14_acc_3: 0.8153 - val_crf_15_acc_1: 0.8134 - val_crf_15_acc_2: 0.8156 - val_crf_15_acc_3: 0.9884 - val_f1: 0.8663 - val_crf_13_f1: 0.8722 - val_crf_14_f1: 0.7918 - val_crf_15_f1: 0.9348
Epoch 7/25
 - 1445s - loss: -4.1007e-02 - crf_13_loss: 0.0090 - crf_14_loss: -1.9244e-02 - crf_15_loss: -3.0762e-02 - crf_13_acc_1: 0.9652 - crf_13_acc_2: 0.7723 - crf_13_acc_3: 0.7755 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9583 - crf_14_acc_3: 0.7735 - crf_15_acc_1: 0.7753 - crf_15_acc_2: 0.7731 - crf_15_acc_3: 0.9828 - val_loss: -7.2294e-02 - val_crf_13_loss: -7.9957e-03 - val_crf_14_loss: -2.8571e-02 - val_crf_15_loss: -3.5728e-02 - val_crf_13_acc_1: 0.9769 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9637 - val_crf_14_acc_3: 0.8154 - val_crf_15_acc_1: 0.8134 - val_crf_15_acc_2: 0.8151 - val_crf_15_acc_3: 0.9869 - val_f1: 0.8679 - val_crf_13_f1: 0.8760 - val_crf_14_f1: 0.8045 - val_crf_15_f1: 0.9231
Epoch 8/25
 - 1436s - loss: -6.6154e-02 - crf_13_loss: -2.3973e-04 - crf_14_loss: -2.7764e-02 - crf_15_loss: -3.8150e-02 - crf_13_acc_1: 0.9661 - crf_13_acc_2: 0.7722 - crf_13_acc_3: 0.7754 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9596 - crf_14_acc_3: 0.7735 - crf_15_acc_1: 0.7753 - crf_15_acc_2: 0.7731 - crf_15_acc_3: 0.9829 - val_loss: -9.3380e-02 - val_crf_13_loss: -1.5120e-02 - val_crf_14_loss: -3.5886e-02 - val_crf_15_loss: -4.2374e-02 - val_crf_13_acc_1: 0.9738 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9622 - val_crf_14_acc_3: 0.8152 - val_crf_15_acc_1: 0.8135 - val_crf_15_acc_2: 0.8149 - val_crf_15_acc_3: 0.9834 - val_f1: 0.8554 - val_crf_13_f1: 0.8702 - val_crf_14_f1: 0.7975 - val_crf_15_f1: 0.8985
Epoch 9/25
 - 1436s - loss: -8.9859e-02 - crf_13_loss: -8.7706e-03 - crf_14_loss: -3.5760e-02 - crf_15_loss: -4.5329e-02 - crf_13_acc_1: 0.9668 - crf_13_acc_2: 0.7722 - crf_13_acc_3: 0.7754 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9602 - crf_14_acc_3: 0.7735 - crf_15_acc_1: 0.7753 - crf_15_acc_2: 0.7730 - crf_15_acc_3: 0.9827 - val_loss: -1.1385e-01 - val_crf_13_loss: -2.3096e-02 - val_crf_14_loss: -4.1711e-02 - val_crf_15_loss: -4.9040e-02 - val_crf_13_acc_1: 0.9758 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9588 - val_crf_14_acc_3: 0.8155 - val_crf_15_acc_1: 0.8133 - val_crf_15_acc_2: 0.8147 - val_crf_15_acc_3: 0.9845 - val_f1: 0.8497 - val_crf_13_f1: 0.8743 - val_crf_14_f1: 0.7737 - val_crf_15_f1: 0.9012
Epoch 10/25
 - 1438s - loss: -1.1280e-01 - crf_13_loss: -1.6854e-02 - crf_14_loss: -4.3451e-02 - crf_15_loss: -5.2492e-02 - crf_13_acc_1: 0.9675 - crf_13_acc_2: 0.7722 - crf_13_acc_3: 0.7754 - crf_14_acc_1: 0.7722 - crf_14_acc_2: 0.9611 - crf_14_acc_3: 0.7735 - crf_15_acc_1: 0.7753 - crf_15_acc_2: 0.7731 - crf_15_acc_3: 0.9830 - val_loss: -1.3628e-01 - val_crf_13_loss: -3.0377e-02 - val_crf_14_loss: -4.9926e-02 - val_crf_15_loss: -5.5982e-02 - val_crf_13_acc_1: 0.9758 - val_crf_13_acc_2: 0.8130 - val_crf_13_acc_3: 0.8134 - val_crf_14_acc_1: 0.8134 - val_crf_14_acc_2: 0.9646 - val_crf_14_acc_3: 0.8153 - val_crf_15_acc_1: 0.8134 - val_crf_15_acc_2: 0.8153 - val_crf_15_acc_3: 0.9838 - val_f1: 0.8634 - val_crf_13_f1: 0.8759 - val_crf_14_f1: 0.8149 - val_crf_15_f1: 0.8995

-------------------------------------------
Best F1 score: 0.876159492912   (epoch number 5)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9737    0.5000    0.6607       148
        archivalreference     0.7863    0.8453    0.8147       853
              archive_lib     0.8257    0.8738    0.8491       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9409    0.9305    0.9357      4948
                      box     0.8372    0.3273    0.4706       110
              cartulation     0.1311    1.0000    0.2319         8
              conjunction     0.5233    0.7537    0.6177       134
                     date     0.3524    0.6379    0.4540        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2059    0.5000    0.2917        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.4444    0.1667    0.2424       120
                        o     0.2825    0.3178    0.2991       752
               pagination     0.9299    0.9543    0.9419      1139
   publicationnumber-year     0.6185    0.8282    0.7081       646
         publicationplace     0.9318    0.9014    0.9163      1592
publicationspecifications     0.4675    0.2903    0.3582       372
                publisher     0.8674    0.8704    0.8689      1443
                      ref     0.4000    0.6667    0.5000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.9545    0.5490    0.6971       153
                    title     0.9351    0.9472    0.9411     15560
                     tomo     0.7733    0.2589    0.3880       224
                   volume     0.5866    0.5993    0.5929       277
                     year     0.9260    0.7991    0.8579      2036

              avg / total     0.9790    0.9769    0.9771    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9737    0.5000    0.6607       148
        archivalreference     0.7863    0.8453    0.8147       853
              archive_lib     0.8257    0.8738    0.8491       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9409    0.9305    0.9357      4948
                      box     0.8372    0.3273    0.4706       110
              cartulation     0.1311    1.0000    0.2319         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5233    0.7537    0.6177       134
                     date     0.3524    0.6379    0.4540        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2059    0.5000    0.2917        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.4444    0.1667    0.2424       120
                        o     0.2825    0.3178    0.2991       752
               pagination     0.9299    0.9543    0.9419      1139
   publicationnumber-year     0.6185    0.8282    0.7081       646
         publicationplace     0.9318    0.9014    0.9163      1592
publicationspecifications     0.4675    0.2903    0.3582       372
                publisher     0.8674    0.8704    0.8689      1443
                      ref     0.4000    0.6667    0.5000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.9545    0.5490    0.6971       153
                    title     0.9351    0.9472    0.9411     15560
                     tomo     0.7733    0.2589    0.3880       224
                   volume     0.5866    0.5993    0.5929       277
                     year     0.9260    0.7991    0.8579      2036

              avg / total     0.8880    0.8768    0.8777     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6846    0.5862    0.6316       348
        b-primary     0.6000    0.1714    0.2667       105
      b-secondary     0.7349    0.6444    0.6867       852
e-meta-annotation     0.8806    0.7785    0.8264      1061
        e-primary     0.7519    0.6467    0.6953       300
      e-secondary     0.8514    0.8311    0.8411      1717
i-meta-annotation     0.8032    0.7887    0.7959      9981
        i-primary     0.7774    0.8588    0.8161      1728
      i-secondary     0.8448    0.8597    0.8522     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.2500    0.3560    0.2937       427

      avg / total     0.9652    0.9648    0.9648    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6846    0.5862    0.6316       348
        b-primary     0.6000    0.1714    0.2667       105
      b-secondary     0.7349    0.6444    0.6867       852
e-meta-annotation     0.8806    0.7785    0.8264      1061
        e-primary     0.7519    0.6467    0.6953       300
      e-secondary     0.8514    0.8311    0.8411      1717
i-meta-annotation     0.8032    0.7887    0.7959      9981
        i-primary     0.7774    0.8588    0.8161      1728
      i-secondary     0.8448    0.8597    0.8522     14357
                o     0.2500    0.3560    0.2937       427

      avg / total     0.8144    0.8119    0.8122     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8258    0.6828    0.7475      1305
        e-r     0.9516    0.4649    0.6246      1310
        i-r     0.9588    0.9837    0.9711     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3133    0.4403    0.3661       427

avg / total     0.9895    0.9890    0.9885    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8258    0.6828    0.7475      1305
        e-r     0.9516    0.4649    0.6246      1310
        i-r     0.9588    0.9837    0.9711     27834
          o     0.3133    0.4403    0.3661       427

avg / total     0.9440    0.9415    0.9386     30876




Confusion matrix, without normalization
[[    38      0    102      8      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    10      5    830      8      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    15      0     71     17      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   893      2   4031     22      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      7      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    127      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2     25      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      3    109      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     7      7    530    208      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1    149    975     14      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3    642      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1590      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2    335     35      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1443      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      1    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   104      4  15355     97      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    275      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2    459   1400    175      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.56756757e-01   0.00000000e+00   6.89189189e-01   5.40540541e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.17233294e-02   5.86166471e-03   9.73036342e-01   9.37866354e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.45631068e-01   0.00000000e+00   6.89320388e-01   1.65048544e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.80476960e-01   4.04203719e-04   8.14672595e-01   4.44624091e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.25000000e-01   8.75000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.47761194e-01   5.22388060e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   7.14285714e-02   8.92857143e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   2.50000000e-02   9.08333333e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.30851064e-03   9.30851064e-03   7.04787234e-01   2.76595745e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   1.30816506e-01   8.56014047e-01   1.22914838e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   4.64396285e-03   9.93808050e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.28140704e-04   9.98743719e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   5.37634409e-03   9.00537634e-01   9.40860215e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   6.49350649e-03   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.68380463e-03   2.57069409e-04   9.86825193e-01   6.23393316e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.92779783e-01   7.22021661e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.82318271e-04   2.25442043e-01   6.87622790e-01   8.59528487e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   262      0     46     40      0      0      0      0      0      0
       0]
 [    23      0     79      3      0      0      0      0      0      0
       0]
 [   606      0    139    107      0      0      0      0      0      0
       0]
 [     1    169    875     16      0      0      0      0      0      0
       0]
 [     0      4    283     13      0      0      0      0      0      0
       0]
 [     0    436   1263     18      0      0      0      0      0      0
       0]
 [    54      5   9852     70      0      0      0      0      0      0
       0]
 [     9     10   1652     57      0      0      0      0      0      0
       0]
 [   119     13  14137     88      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     5      3    231    188      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.52873563e-01   0.00000000e+00   1.32183908e-01   1.14942529e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.19047619e-01   0.00000000e+00   7.52380952e-01   2.85714286e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.11267606e-01   0.00000000e+00   1.63145540e-01   1.25586854e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.42507069e-04   1.59283695e-01   8.24693685e-01   1.50801131e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.33333333e-02   9.43333333e-01   4.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.53931275e-01   7.35585323e-01   1.04834013e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.41027953e-03   5.00951808e-04   9.87075443e-01   7.01332532e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.20833333e-03   5.78703704e-03   9.56018519e-01   3.29861111e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.28863969e-03   9.05481647e-04   9.84676464e-01   6.12941422e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.17096019e-02   7.02576112e-03   5.40983607e-01   4.40281030e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   891      0    264      0    150]
 [     0    609    681      0     20]
 [   183     28  27381      0    242]
 [     0      0      0 133958      0]
 [     5      3    231      0    188]]
Normalized confusion matrix
[[ 0.68275862  0.          0.20229885  0.          0.11494253]
 [ 0.          0.4648855   0.51984733  0.          0.01526718]
 [ 0.00657469  0.00100596  0.98372494  0.          0.0086944 ]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.0117096   0.00702576  0.54098361  0.          0.44028103]]
