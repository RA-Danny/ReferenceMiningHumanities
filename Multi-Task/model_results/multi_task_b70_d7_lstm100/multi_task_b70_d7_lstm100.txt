______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_22 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_22[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_31 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_21 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_21 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_31[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_21 (Embedding)                         (None, 73, 300)                  17130300          input_21[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_22 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_21[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_11 (Concatenate)                     (None, 73, 3000)                 0                 embedding_21[0][0]                                
                                                                                                    time_distributed_22[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_32 (Dropout)                             (None, 73, 3000)                 0                 concatenate_11[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_22 (Bidirectional)                 (None, 73, 200)                  2480800           dropout_32[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_33 (Dropout)                             (None, 73, 200)                  0                 bidirectional_22[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_31 (Dense)                                 (None, 73, 28)                   5628              dropout_33[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_32 (Dense)                                 (None, 73, 11)                   2211              dropout_33[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_33 (Dense)                                 (None, 73, 5)                    1005              dropout_33[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_31 (CRF)                                     (None, 73, 28)                   1652              dense_31[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_32 (CRF)                                     (None, 73, 11)                   275               dense_32[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_33 (CRF)                                     (None, 73, 5)                    65                dense_33[0][0]                                    
======================================================================================================================================================
Total params: 19,663,636
Trainable params: 19,663,636
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1628s - loss: 0.6582 - crf_31_loss: 0.2977 - crf_32_loss: 0.2424 - crf_33_loss: 0.1181 - crf_31_acc_1: 0.9054 - crf_31_acc_2: 0.7712 - crf_31_acc_3: 0.7746 - crf_32_acc_1: 0.7712 - crf_32_acc_2: 0.8971 - crf_32_acc_3: 0.7737 - crf_33_acc_1: 0.7721 - crf_33_acc_2: 0.7707 - crf_33_acc_3: 0.9557 - val_loss: 0.2135 - val_crf_31_loss: 0.1066 - val_crf_32_loss: 0.0881 - val_crf_33_loss: 0.0188 - val_crf_31_acc_1: 0.9525 - val_crf_31_acc_2: 0.8128 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8133 - val_crf_32_acc_2: 0.9342 - val_crf_32_acc_3: 0.8153 - val_crf_33_acc_1: 0.8129 - val_crf_33_acc_2: 0.8147 - val_crf_33_acc_3: 0.9877 - val_f1: 0.7647 - val_crf_31_f1: 0.7102 - val_crf_32_f1: 0.6475 - val_crf_33_f1: 0.9366
Epoch 2/25
 - 1606s - loss: 0.2364 - crf_31_loss: 0.1290 - crf_32_loss: 0.0797 - crf_33_loss: 0.0277 - crf_31_acc_1: 0.9365 - crf_31_acc_2: 0.7725 - crf_31_acc_3: 0.7759 - crf_32_acc_1: 0.7723 - crf_32_acc_2: 0.9335 - crf_32_acc_3: 0.7741 - crf_33_acc_1: 0.7741 - crf_33_acc_2: 0.7729 - crf_33_acc_3: 0.9756 - val_loss: 0.0861 - val_crf_31_loss: 0.0566 - val_crf_32_loss: 0.0316 - val_crf_33_loss: -2.0269e-03 - val_crf_31_acc_1: 0.9624 - val_crf_31_acc_2: 0.8130 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8133 - val_crf_32_acc_2: 0.9529 - val_crf_32_acc_3: 0.8154 - val_crf_33_acc_1: 0.8132 - val_crf_33_acc_2: 0.8151 - val_crf_33_acc_3: 0.9885 - val_f1: 0.8239 - val_crf_31_f1: 0.7824 - val_crf_32_f1: 0.7512 - val_crf_33_f1: 0.9380
Epoch 3/25
 - 1602s - loss: 0.1129 - crf_31_loss: 0.0775 - crf_32_loss: 0.0342 - crf_33_loss: 0.0012 - crf_31_acc_1: 0.9441 - crf_31_acc_2: 0.7725 - crf_31_acc_3: 0.7758 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9390 - crf_32_acc_3: 0.7740 - crf_33_acc_1: 0.7745 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9773 - val_loss: 0.0198 - val_crf_31_loss: 0.0283 - val_crf_32_loss: 0.0080 - val_crf_33_loss: -1.6431e-02 - val_crf_31_acc_1: 0.9686 - val_crf_31_acc_2: 0.8131 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9493 - val_crf_32_acc_3: 0.8152 - val_crf_33_acc_1: 0.8133 - val_crf_33_acc_2: 0.8159 - val_crf_33_acc_3: 0.9890 - val_f1: 0.8307 - val_crf_31_f1: 0.8241 - val_crf_32_f1: 0.7303 - val_crf_33_f1: 0.9378
Epoch 4/25
 - 1599s - loss: 0.0454 - crf_31_loss: 0.0494 - crf_32_loss: 0.0106 - crf_33_loss: -1.4572e-02 - crf_31_acc_1: 0.9482 - crf_31_acc_2: 0.7725 - crf_31_acc_3: 0.7756 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9412 - crf_32_acc_3: 0.7739 - crf_33_acc_1: 0.7748 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9775 - val_loss: -2.4626e-02 - val_crf_31_loss: 0.0104 - val_crf_32_loss: -7.9764e-03 - val_crf_33_loss: -2.7056e-02 - val_crf_31_acc_1: 0.9695 - val_crf_31_acc_2: 0.8130 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9566 - val_crf_32_acc_3: 0.8153 - val_crf_33_acc_1: 0.8134 - val_crf_33_acc_2: 0.8152 - val_crf_33_acc_3: 0.9860 - val_f1: 0.8418 - val_crf_31_f1: 0.8360 - val_crf_32_f1: 0.7721 - val_crf_33_f1: 0.9175
Epoch 5/25
 - 1601s - loss: -2.0471e-03 - crf_31_loss: 0.0304 - crf_32_loss: -5.3779e-03 - crf_33_loss: -2.7035e-02 - crf_31_acc_1: 0.9512 - crf_31_acc_2: 0.7724 - crf_31_acc_3: 0.7756 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9432 - crf_32_acc_3: 0.7738 - crf_33_acc_1: 0.7750 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9775 - val_loss: -5.9926e-02 - val_crf_31_loss: -2.6806e-03 - val_crf_32_loss: -2.0109e-02 - val_crf_33_loss: -3.7136e-02 - val_crf_31_acc_1: 0.9706 - val_crf_31_acc_2: 0.8130 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9545 - val_crf_32_acc_3: 0.8151 - val_crf_33_acc_1: 0.8133 - val_crf_33_acc_2: 0.8148 - val_crf_33_acc_3: 0.9829 - val_f1: 0.8342 - val_crf_31_f1: 0.8441 - val_crf_32_f1: 0.7561 - val_crf_33_f1: 0.9024
Epoch 6/25
 - 1607s - loss: -4.0516e-02 - crf_31_loss: 0.0156 - crf_32_loss: -1.8080e-02 - crf_33_loss: -3.8038e-02 - crf_31_acc_1: 0.9526 - crf_31_acc_2: 0.7724 - crf_31_acc_3: 0.7756 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9444 - crf_32_acc_3: 0.7738 - crf_33_acc_1: 0.7751 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9773 - val_loss: -9.5301e-02 - val_crf_31_loss: -1.5344e-02 - val_crf_32_loss: -3.2189e-02 - val_crf_33_loss: -4.7769e-02 - val_crf_31_acc_1: 0.9722 - val_crf_31_acc_2: 0.8129 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9614 - val_crf_32_acc_3: 0.8152 - val_crf_33_acc_1: 0.8135 - val_crf_33_acc_2: 0.8148 - val_crf_33_acc_3: 0.9841 - val_f1: 0.8494 - val_crf_31_f1: 0.8539 - val_crf_32_f1: 0.7957 - val_crf_33_f1: 0.8986
Epoch 7/25
 - 1605s - loss: -7.5146e-02 - crf_31_loss: 0.0028 - crf_32_loss: -2.9439e-02 - crf_33_loss: -4.8516e-02 - crf_31_acc_1: 0.9540 - crf_31_acc_2: 0.7724 - crf_31_acc_3: 0.7756 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9454 - crf_32_acc_3: 0.7737 - crf_33_acc_1: 0.7752 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9777 - val_loss: -1.2655e-01 - val_crf_31_loss: -2.6668e-02 - val_crf_32_loss: -4.2398e-02 - val_crf_33_loss: -5.7484e-02 - val_crf_31_acc_1: 0.9718 - val_crf_31_acc_2: 0.8129 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9612 - val_crf_32_acc_3: 0.8152 - val_crf_33_acc_1: 0.8136 - val_crf_33_acc_2: 0.8151 - val_crf_33_acc_3: 0.9841 - val_f1: 0.8491 - val_crf_31_f1: 0.8536 - val_crf_32_f1: 0.7950 - val_crf_33_f1: 0.8987
Epoch 8/25
 - 1602s - loss: -1.0716e-01 - crf_31_loss: -8.5798e-03 - crf_32_loss: -3.9996e-02 - crf_33_loss: -5.8588e-02 - crf_31_acc_1: 0.9547 - crf_31_acc_2: 0.7724 - crf_31_acc_3: 0.7755 - crf_32_acc_1: 0.7723 - crf_32_acc_2: 0.9466 - crf_32_acc_3: 0.7737 - crf_33_acc_1: 0.7752 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9777 - val_loss: -1.5701e-01 - val_crf_31_loss: -3.6890e-02 - val_crf_32_loss: -5.2423e-02 - val_crf_33_loss: -6.7697e-02 - val_crf_31_acc_1: 0.9730 - val_crf_31_acc_2: 0.8129 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9588 - val_crf_32_acc_3: 0.8152 - val_crf_33_acc_1: 0.8135 - val_crf_33_acc_2: 0.8149 - val_crf_33_acc_3: 0.9849 - val_f1: 0.8452 - val_crf_31_f1: 0.8545 - val_crf_32_f1: 0.7796 - val_crf_33_f1: 0.9015
Epoch 9/25
 - 1602s - loss: -1.3842e-01 - crf_31_loss: -1.9533e-02 - crf_32_loss: -5.0283e-02 - crf_33_loss: -6.8599e-02 - crf_31_acc_1: 0.9553 - crf_31_acc_2: 0.7723 - crf_31_acc_3: 0.7755 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9472 - crf_32_acc_3: 0.7737 - crf_33_acc_1: 0.7752 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9779 - val_loss: -1.8633e-01 - val_crf_31_loss: -4.7083e-02 - val_crf_32_loss: -6.1982e-02 - val_crf_33_loss: -7.7265e-02 - val_crf_31_acc_1: 0.9732 - val_crf_31_acc_2: 0.8130 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9597 - val_crf_32_acc_3: 0.8153 - val_crf_33_acc_1: 0.8135 - val_crf_33_acc_2: 0.8150 - val_crf_33_acc_3: 0.9847 - val_f1: 0.8488 - val_crf_31_f1: 0.8580 - val_crf_32_f1: 0.7877 - val_crf_33_f1: 0.9006
Epoch 10/25
 - 1597s - loss: -1.6884e-01 - crf_31_loss: -2.9978e-02 - crf_32_loss: -6.0324e-02 - crf_33_loss: -7.8539e-02 - crf_31_acc_1: 0.9562 - crf_31_acc_2: 0.7723 - crf_31_acc_3: 0.7755 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9481 - crf_32_acc_3: 0.7737 - crf_33_acc_1: 0.7753 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9783 - val_loss: -2.1360e-01 - val_crf_31_loss: -5.6437e-02 - val_crf_32_loss: -7.0772e-02 - val_crf_33_loss: -8.6388e-02 - val_crf_31_acc_1: 0.9721 - val_crf_31_acc_2: 0.8129 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8134 - val_crf_32_acc_2: 0.9562 - val_crf_32_acc_3: 0.8153 - val_crf_33_acc_1: 0.8136 - val_crf_33_acc_2: 0.8155 - val_crf_33_acc_3: 0.9825 - val_f1: 0.8411 - val_crf_31_f1: 0.8562 - val_crf_32_f1: 0.7725 - val_crf_33_f1: 0.8945
Epoch 11/25
 - 1604s - loss: -1.9859e-01 - crf_31_loss: -4.0005e-02 - crf_32_loss: -7.0188e-02 - crf_33_loss: -8.8399e-02 - crf_31_acc_1: 0.9565 - crf_31_acc_2: 0.7723 - crf_31_acc_3: 0.7755 - crf_32_acc_1: 0.7722 - crf_32_acc_2: 0.9490 - crf_32_acc_3: 0.7737 - crf_33_acc_1: 0.7753 - crf_33_acc_2: 0.7730 - crf_33_acc_3: 0.9784 - val_loss: -2.4522e-01 - val_crf_31_loss: -6.6427e-02 - val_crf_32_loss: -8.1725e-02 - val_crf_33_loss: -9.7069e-02 - val_crf_31_acc_1: 0.9734 - val_crf_31_acc_2: 0.8130 - val_crf_31_acc_3: 0.8134 - val_crf_32_acc_1: 0.8133 - val_crf_32_acc_2: 0.9587 - val_crf_32_acc_3: 0.8152 - val_crf_33_acc_1: 0.8135 - val_crf_33_acc_2: 0.8148 - val_crf_33_acc_3: 0.9847 - val_f1: 0.8458 - val_crf_31_f1: 0.8626 - val_crf_32_f1: 0.7734 - val_crf_33_f1: 0.9015

-------------------------------------------
Best F1 score: 0.849397776529   (epoch number 6)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9524    0.5405    0.6897       148
        archivalreference     0.7076    0.7972    0.7497       853
              archive_lib     1.0000    0.8738    0.9326       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9245    0.9133    0.9189      4948
                      box     0.8113    0.3909    0.5276       110
              cartulation     0.1143    1.0000    0.2051         8
              conjunction     0.5206    0.7537    0.6159       134
                     date     0.4598    0.6897    0.5517        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3273    0.6429    0.4337        28
                foliation     0.7500    1.0000    0.8571        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.2000    0.1667    0.1818       120
                        o     0.1948    0.2580    0.2220       752
               pagination     0.9058    0.9543    0.9295      1139
   publicationnumber-year     0.6375    0.7678    0.6966       646
         publicationplace     0.9331    0.8938    0.9131      1592
publicationspecifications     0.2095    0.1183    0.1512       372
                publisher     0.8660    0.8198    0.8423      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.4862    0.5752    0.5269       153
                    title     0.9205    0.9253    0.9229     15560
                     tomo     1.0000    0.0714    0.1333       224
                   volume     0.4427    0.5162    0.4767       277
                     year     0.9261    0.7819    0.8479      2036

              avg / total     0.9753    0.9722    0.9726    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9524    0.5405    0.6897       148
        archivalreference     0.7076    0.7972    0.7497       853
              archive_lib     1.0000    0.8738    0.9326       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9245    0.9133    0.9189      4948
                      box     0.8113    0.3909    0.5276       110
              cartulation     0.1143    1.0000    0.2051         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5206    0.7537    0.6159       134
                     date     0.4598    0.6897    0.5517        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3273    0.6429    0.4337        28
                foliation     0.7500    1.0000    0.8571        12
             numbered_ref     0.2000    0.1667    0.1818       120
                        o     0.1948    0.2580    0.2220       752
               pagination     0.9058    0.9543    0.9295      1139
   publicationnumber-year     0.6375    0.7678    0.6966       646
         publicationplace     0.9331    0.8938    0.9131      1592
publicationspecifications     0.2095    0.1183    0.1512       372
                publisher     0.8660    0.8198    0.8423      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.4862    0.5752    0.5269       153
                    title     0.9205    0.9253    0.9229     15560
                     tomo     1.0000    0.0714    0.1333       224
                   volume     0.4427    0.5162    0.4767       277
                     year     0.9261    0.7819    0.8479      2036

              avg / total     0.8680    0.8516    0.8539     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7168    0.4655    0.5645       348
        b-primary     0.6765    0.2190    0.3309       105
      b-secondary     0.7107    0.6631    0.6861       852
e-meta-annotation     0.8863    0.7201    0.7946      1061
        e-primary     0.8523    0.6733    0.7523       300
      e-secondary     0.8143    0.8276    0.8209      1717
i-meta-annotation     0.7997    0.7431    0.7704      9981
        i-primary     0.8144    0.8814    0.8466      1728
      i-secondary     0.8197    0.8567    0.8378     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.1671    0.3232    0.2203       427

      avg / total     0.9628    0.9614    0.9617    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7168    0.4655    0.5645       348
        b-primary     0.6765    0.2190    0.3309       105
      b-secondary     0.7107    0.6631    0.6861       852
e-meta-annotation     0.8863    0.7201    0.7946      1061
        e-primary     0.8523    0.6733    0.7523       300
      e-secondary     0.8143    0.8276    0.8209      1717
i-meta-annotation     0.7997    0.7431    0.7704      9981
        i-primary     0.8144    0.8814    0.8466      1728
      i-secondary     0.8197    0.8567    0.8378     14357
                o     0.1671    0.3232    0.2203       427

      avg / total     0.8015    0.7940    0.7957     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8279    0.6674    0.7391      1305
        e-r     0.3111    0.0107    0.0207      1310
        i-r     0.9375    0.9769    0.9568     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2245    0.4075    0.2895       427

avg / total     0.9806    0.9841    0.9810    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8279    0.6674    0.7391      1305
        e-r     0.3111    0.0107    0.0207      1310
        i-r     0.9375    0.9769    0.9568     27834
          o     0.2245    0.4075    0.2895       427

avg / total     0.8964    0.9150    0.8986     30876




Confusion matrix, without normalization
[[    37      0    111      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    17      2    831      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    18      0     72     13      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   878      3   4057     10      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    128      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     58      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     28      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2    107     10      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     7      1    560    184      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      6   1128      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1    641      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1591      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    333     39      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1439      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    149      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    88      3  15166    303      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0     27   1815    194      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   7.50000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.99296600e-02   2.34466589e-03   9.74208675e-01   3.51699883e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.74757282e-01   0.00000000e+00   6.99029126e-01   1.26213592e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.77445432e-01   6.06305578e-04   8.19927243e-01   2.02101859e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.55223881e-01   4.47761194e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.33333333e-03   1.66666667e-02   8.91666667e-01   8.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.30851064e-03   1.32978723e-03   7.44680851e-01   2.44680851e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   5.26777875e-03   9.90342406e-01   3.51185250e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.54798762e-03   9.92260062e-01   6.19195046e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.99371859e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   8.95161290e-01   1.04838710e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.97227997e-01   2.77200277e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   9.67532468e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.65552699e-03   1.92802057e-04   9.74678663e-01   1.94730077e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.32612967e-02   8.91453831e-01   9.52848723e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   254      0     53     41      0      0      0      0      0      0
       0]
 [    32      0     71      2      0      0      0      0      0      0
       0]
 [   585      0    158    109      0      0      0      0      0      0
       0]
 [     1      3   1047     10      0      0      0      0      0      0
       0]
 [     0      0    297      3      0      0      0      0      0      0
       0]
 [     0     11   1690     16      0      0      0      0      0      0
       0]
 [    50     13   9742    176      0      0      0      0      0      0
       0]
 [     8      5   1689     26      0      0      0      0      0      0
       0]
 [   117     13  14009    218      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     5      0    248    174      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.29885057e-01   0.00000000e+00   1.52298851e-01   1.17816092e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.04761905e-01   0.00000000e+00   6.76190476e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.86619718e-01   0.00000000e+00   1.85446009e-01   1.27934272e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.42507069e-04   2.82752121e-03   9.86804901e-01   9.42507069e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.90000000e-01   1.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.40652301e-03   9.84274898e-01   9.31857892e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.00951808e-03   1.30247470e-03   9.76054504e-01   1.76335037e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.62962963e-03   2.89351852e-03   9.77430556e-01   1.50462963e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.14933482e-03   9.05481647e-04   9.75760953e-01   1.51842307e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.17096019e-02   0.00000000e+00   5.80796253e-01   4.07494145e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   871      0    282      0    152]
 [     0     14   1283      0     13]
 [   176     31  27191      0    436]
 [     0      0      0 133958      0]
 [     5      0    248      0    174]]
Normalized confusion matrix
[[ 0.66743295  0.          0.21609195  0.          0.1164751 ]
 [ 0.          0.01068702  0.97938931  0.          0.00992366]
 [ 0.0063232   0.00111375  0.97689876  0.          0.0156643 ]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.0117096   0.          0.58079625  0.          0.40749415]]
