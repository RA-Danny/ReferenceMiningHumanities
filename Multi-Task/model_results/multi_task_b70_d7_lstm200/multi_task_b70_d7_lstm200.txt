______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_20 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_20[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_28 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_19 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_19 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_28[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_19 (Embedding)                         (None, 73, 300)                  17130300          input_19[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_20 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_19[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_10 (Concatenate)                     (None, 73, 3000)                 0                 embedding_19[0][0]                                
                                                                                                    time_distributed_20[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_29 (Dropout)                             (None, 73, 3000)                 0                 concatenate_10[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_20 (Bidirectional)                 (None, 73, 400)                  5121600           dropout_29[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_30 (Dropout)                             (None, 73, 400)                  0                 bidirectional_20[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_28 (Dense)                                 (None, 73, 28)                   11228             dropout_30[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_29 (Dense)                                 (None, 73, 11)                   4411              dropout_30[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_30 (Dense)                                 (None, 73, 5)                    2005              dropout_30[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_28 (CRF)                                     (None, 73, 28)                   1652              dense_28[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_29 (CRF)                                     (None, 73, 11)                   275               dense_29[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_30 (CRF)                                     (None, 73, 5)                    65                dense_30[0][0]                                    
======================================================================================================================================================
Total params: 22,313,236
Trainable params: 22,313,236
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1636s - loss: 0.5894 - crf_28_loss: 0.2712 - crf_29_loss: 0.2124 - crf_30_loss: 0.1059 - crf_28_acc_1: 0.9116 - crf_28_acc_2: 0.7699 - crf_28_acc_3: 0.7732 - crf_29_acc_1: 0.7705 - crf_29_acc_2: 0.9033 - crf_29_acc_3: 0.7719 - crf_30_acc_1: 0.7723 - crf_30_acc_2: 0.7696 - crf_30_acc_3: 0.9585 - val_loss: 0.2057 - val_crf_28_loss: 0.0971 - val_crf_29_loss: 0.0841 - val_crf_30_loss: 0.0245 - val_crf_28_acc_1: 0.9537 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8132 - val_crf_29_acc_2: 0.9270 - val_crf_29_acc_3: 0.8152 - val_crf_30_acc_1: 0.8130 - val_crf_30_acc_2: 0.8158 - val_crf_30_acc_3: 0.9849 - val_f1: 0.7568 - val_crf_28_f1: 0.7375 - val_crf_29_f1: 0.6055 - val_crf_30_f1: 0.9273
Epoch 2/25
 - 1619s - loss: 0.1981 - crf_28_loss: 0.1088 - crf_29_loss: 0.0645 - crf_30_loss: 0.0248 - crf_28_acc_1: 0.9445 - crf_28_acc_2: 0.7725 - crf_28_acc_3: 0.7758 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9375 - crf_29_acc_3: 0.7740 - crf_30_acc_1: 0.7746 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9775 - val_loss: 0.0682 - val_crf_28_loss: 0.0440 - val_crf_29_loss: 0.0235 - val_crf_30_loss: 8.0159e-04 - val_crf_28_acc_1: 0.9704 - val_crf_28_acc_2: 0.8134 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9608 - val_crf_29_acc_3: 0.8152 - val_crf_30_acc_1: 0.8134 - val_crf_30_acc_2: 0.8152 - val_crf_30_acc_3: 0.9897 - val_f1: 0.8572 - val_crf_28_f1: 0.8338 - val_crf_29_f1: 0.7936 - val_crf_30_f1: 0.9443
Epoch 3/25
 - 1635s - loss: 0.0895 - crf_28_loss: 0.0623 - crf_29_loss: 0.0247 - crf_30_loss: 0.0025 - crf_28_acc_1: 0.9520 - crf_28_acc_2: 0.7725 - crf_28_acc_3: 0.7756 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9432 - crf_29_acc_3: 0.7738 - crf_30_acc_1: 0.7749 - crf_30_acc_2: 0.7731 - crf_30_acc_3: 0.9792 - val_loss: 0.0093 - val_crf_28_loss: 0.0202 - val_crf_29_loss: 0.0016 - val_crf_30_loss: -1.2463e-02 - val_crf_28_acc_1: 0.9706 - val_crf_28_acc_2: 0.8134 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9605 - val_crf_29_acc_3: 0.8152 - val_crf_30_acc_1: 0.8133 - val_crf_30_acc_2: 0.8150 - val_crf_30_acc_3: 0.9889 - val_f1: 0.8598 - val_crf_28_f1: 0.8453 - val_crf_29_f1: 0.7928 - val_crf_30_f1: 0.9413
Epoch 4/25
 - 1615s - loss: 0.0287 - crf_28_loss: 0.0373 - crf_29_loss: 0.0033 - crf_30_loss: -1.1945e-02 - crf_28_acc_1: 0.9548 - crf_28_acc_2: 0.7724 - crf_28_acc_3: 0.7756 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9455 - crf_29_acc_3: 0.7737 - crf_30_acc_1: 0.7751 - crf_30_acc_2: 0.7731 - crf_30_acc_3: 0.9795 - val_loss: -3.1901e-02 - val_crf_28_loss: 0.0031 - val_crf_29_loss: -1.1629e-02 - val_crf_30_loss: -2.3331e-02 - val_crf_28_acc_1: 0.9728 - val_crf_28_acc_2: 0.8132 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9551 - val_crf_29_acc_3: 0.8152 - val_crf_30_acc_1: 0.8134 - val_crf_30_acc_2: 0.8147 - val_crf_30_acc_3: 0.9884 - val_f1: 0.8468 - val_crf_28_f1: 0.8555 - val_crf_29_f1: 0.7527 - val_crf_30_f1: 0.9322
Epoch 5/25
 - 1616s - loss: -1.5922e-02 - crf_28_loss: 0.0199 - crf_29_loss: -1.1999e-02 - crf_30_loss: -2.3832e-02 - crf_28_acc_1: 0.9570 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7755 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9473 - crf_29_acc_3: 0.7737 - crf_30_acc_1: 0.7751 - crf_30_acc_2: 0.7731 - crf_30_acc_3: 0.9797 - val_loss: -6.7849e-02 - val_crf_28_loss: -9.6739e-03 - val_crf_29_loss: -2.4654e-02 - val_crf_30_loss: -3.3521e-02 - val_crf_28_acc_1: 0.9733 - val_crf_28_acc_2: 0.8130 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8133 - val_crf_29_acc_2: 0.9593 - val_crf_29_acc_3: 0.8152 - val_crf_30_acc_1: 0.8136 - val_crf_30_acc_2: 0.8149 - val_crf_30_acc_3: 0.9860 - val_f1: 0.8508 - val_crf_28_f1: 0.8599 - val_crf_29_f1: 0.7799 - val_crf_30_f1: 0.9127
Epoch 6/25
 - 1630s - loss: -5.2907e-02 - crf_28_loss: 0.0059 - crf_29_loss: -2.4219e-02 - crf_30_loss: -3.4624e-02 - crf_28_acc_1: 0.9584 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7755 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9484 - crf_29_acc_3: 0.7737 - crf_30_acc_1: 0.7752 - crf_30_acc_2: 0.7731 - crf_30_acc_3: 0.9794 - val_loss: -1.0078e-01 - val_crf_28_loss: -2.0880e-02 - val_crf_29_loss: -3.5929e-02 - val_crf_30_loss: -4.3967e-02 - val_crf_28_acc_1: 0.9740 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9633 - val_crf_29_acc_3: 0.8153 - val_crf_30_acc_1: 0.8138 - val_crf_30_acc_2: 0.8154 - val_crf_30_acc_3: 0.9855 - val_f1: 0.8581 - val_crf_28_f1: 0.8631 - val_crf_29_f1: 0.8060 - val_crf_30_f1: 0.9052
Epoch 7/25
 - 1630s - loss: -8.6801e-02 - crf_28_loss: -6.3731e-03 - crf_29_loss: -3.5480e-02 - crf_30_loss: -4.4948e-02 - crf_28_acc_1: 0.9593 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7755 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9500 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7752 - crf_30_acc_2: 0.7731 - crf_30_acc_3: 0.9794 - val_loss: -1.2968e-01 - val_crf_28_loss: -3.1676e-02 - val_crf_29_loss: -4.4796e-02 - val_crf_30_loss: -5.3211e-02 - val_crf_28_acc_1: 0.9753 - val_crf_28_acc_2: 0.8130 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9577 - val_crf_29_acc_3: 0.8153 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8156 - val_crf_30_acc_3: 0.9843 - val_f1: 0.8496 - val_crf_28_f1: 0.8714 - val_crf_29_f1: 0.7768 - val_crf_30_f1: 0.9007
Epoch 8/25
 - 1614s - loss: -1.1841e-01 - crf_28_loss: -1.7543e-02 - crf_29_loss: -4.5868e-02 - crf_30_loss: -5.5001e-02 - crf_28_acc_1: 0.9600 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7755 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9507 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7752 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9796 - val_loss: -1.6053e-01 - val_crf_28_loss: -4.1581e-02 - val_crf_29_loss: -5.5616e-02 - val_crf_30_loss: -6.3333e-02 - val_crf_28_acc_1: 0.9754 - val_crf_28_acc_2: 0.8132 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9628 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9849 - val_f1: 0.8600 - val_crf_28_f1: 0.8722 - val_crf_29_f1: 0.8050 - val_crf_30_f1: 0.9027
Epoch 9/25
 - 1635s - loss: -1.4911e-01 - crf_28_loss: -2.8174e-02 - crf_29_loss: -5.6016e-02 - crf_30_loss: -6.4924e-02 - crf_28_acc_1: 0.9604 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7755 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9515 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9796 - val_loss: -1.9111e-01 - val_crf_28_loss: -5.2798e-02 - val_crf_29_loss: -6.5379e-02 - val_crf_30_loss: -7.2929e-02 - val_crf_28_acc_1: 0.9766 - val_crf_28_acc_2: 0.8132 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9632 - val_crf_29_acc_3: 0.8152 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8152 - val_crf_30_acc_3: 0.9846 - val_f1: 0.8615 - val_crf_28_f1: 0.8764 - val_crf_29_f1: 0.8058 - val_crf_30_f1: 0.9024
Epoch 10/25
 - 1621s - loss: -1.7932e-01 - crf_28_loss: -3.8480e-02 - crf_29_loss: -6.5979e-02 - crf_30_loss: -7.4856e-02 - crf_28_acc_1: 0.9611 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9527 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9800 - val_loss: -2.1574e-01 - val_crf_28_loss: -6.0312e-02 - val_crf_29_loss: -7.3915e-02 - val_crf_30_loss: -8.1513e-02 - val_crf_28_acc_1: 0.9754 - val_crf_28_acc_2: 0.8130 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9627 - val_crf_29_acc_3: 0.8153 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8151 - val_crf_30_acc_3: 0.9848 - val_f1: 0.8588 - val_crf_28_f1: 0.8727 - val_crf_29_f1: 0.8013 - val_crf_30_f1: 0.9025
Epoch 11/25
 - 1608s - loss: -2.0920e-01 - crf_28_loss: -4.8691e-02 - crf_29_loss: -7.5836e-02 - crf_30_loss: -8.4674e-02 - crf_28_acc_1: 0.9619 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9533 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9803 - val_loss: -2.4956e-01 - val_crf_28_loss: -7.1696e-02 - val_crf_29_loss: -8.4774e-02 - val_crf_30_loss: -9.3087e-02 - val_crf_28_acc_1: 0.9770 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9602 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8155 - val_crf_30_acc_3: 0.9859 - val_f1: 0.8585 - val_crf_28_f1: 0.8793 - val_crf_29_f1: 0.7894 - val_crf_30_f1: 0.9066
Epoch 12/25
 - 1621s - loss: -2.3823e-01 - crf_28_loss: -5.8327e-02 - crf_29_loss: -8.5481e-02 - crf_30_loss: -9.4422e-02 - crf_28_acc_1: 0.9623 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7755 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9541 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9804 - val_loss: -2.7713e-01 - val_crf_28_loss: -8.0483e-02 - val_crf_29_loss: -9.4217e-02 - val_crf_30_loss: -1.0243e-01 - val_crf_28_acc_1: 0.9771 - val_crf_28_acc_2: 0.8132 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9644 - val_crf_29_acc_3: 0.8152 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9863 - val_f1: 0.8667 - val_crf_28_f1: 0.8798 - val_crf_29_f1: 0.8122 - val_crf_30_f1: 0.9081
Epoch 13/25
 - 1631s - loss: -2.6744e-01 - crf_28_loss: -6.8099e-02 - crf_29_loss: -9.5178e-02 - crf_30_loss: -1.0417e-01 - crf_28_acc_1: 0.9625 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9545 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9805 - val_loss: -3.0664e-01 - val_crf_28_loss: -9.0088e-02 - val_crf_29_loss: -1.0375e-01 - val_crf_30_loss: -1.1280e-01 - val_crf_28_acc_1: 0.9766 - val_crf_28_acc_2: 0.8130 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9582 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8148 - val_crf_30_acc_3: 0.9854 - val_f1: 0.8509 - val_crf_28_f1: 0.8780 - val_crf_29_f1: 0.7693 - val_crf_30_f1: 0.9053
Epoch 14/25
 - 1612s - loss: -2.9669e-01 - crf_28_loss: -7.7784e-02 - crf_29_loss: -1.0494e-01 - crf_30_loss: -1.1396e-01 - crf_28_acc_1: 0.9630 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9555 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9808 - val_loss: -3.3409e-01 - val_crf_28_loss: -9.8583e-02 - val_crf_29_loss: -1.1309e-01 - val_crf_30_loss: -1.2241e-01 - val_crf_28_acc_1: 0.9753 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9593 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8137 - val_crf_30_acc_2: 0.8157 - val_crf_30_acc_3: 0.9862 - val_f1: 0.8559 - val_crf_28_f1: 0.8748 - val_crf_29_f1: 0.7848 - val_crf_30_f1: 0.9081
Epoch 15/25
 - 1633s - loss: -3.2546e-01 - crf_28_loss: -8.7305e-02 - crf_29_loss: -1.1447e-01 - crf_30_loss: -1.2369e-01 - crf_28_acc_1: 0.9634 - crf_28_acc_2: 0.7723 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9553 - crf_29_acc_3: 0.7736 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9811 - val_loss: -3.6352e-01 - val_crf_28_loss: -1.0886e-01 - val_crf_29_loss: -1.2321e-01 - val_crf_30_loss: -1.3145e-01 - val_crf_28_acc_1: 0.9775 - val_crf_28_acc_2: 0.8129 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9647 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8152 - val_crf_30_acc_3: 0.9860 - val_f1: 0.8669 - val_crf_28_f1: 0.8810 - val_crf_29_f1: 0.8127 - val_crf_30_f1: 0.9071
Epoch 16/25
 - 1615s - loss: -3.5422e-01 - crf_28_loss: -9.6692e-02 - crf_29_loss: -1.2411e-01 - crf_30_loss: -1.3342e-01 - crf_28_acc_1: 0.9635 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9561 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9812 - val_loss: -3.9037e-01 - val_crf_28_loss: -1.1703e-01 - val_crf_29_loss: -1.3242e-01 - val_crf_30_loss: -1.4091e-01 - val_crf_28_acc_1: 0.9762 - val_crf_28_acc_2: 0.8130 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9652 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8136 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9855 - val_f1: 0.8662 - val_crf_28_f1: 0.8771 - val_crf_29_f1: 0.8156 - val_crf_30_f1: 0.9059
Epoch 17/25
 - 1610s - loss: -3.8316e-01 - crf_28_loss: -1.0630e-01 - crf_29_loss: -1.3375e-01 - crf_30_loss: -1.4310e-01 - crf_28_acc_1: 0.9640 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9568 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9814 - val_loss: -4.2051e-01 - val_crf_28_loss: -1.2646e-01 - val_crf_29_loss: -1.4268e-01 - val_crf_30_loss: -1.5137e-01 - val_crf_28_acc_1: 0.9770 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9659 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8136 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9866 - val_f1: 0.8704 - val_crf_28_f1: 0.8815 - val_crf_29_f1: 0.8194 - val_crf_30_f1: 0.9103
Epoch 18/25
 - 1613s - loss: -4.1179e-01 - crf_28_loss: -1.1558e-01 - crf_29_loss: -1.4338e-01 - crf_30_loss: -1.5282e-01 - crf_28_acc_1: 0.9642 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9570 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9814 - val_loss: -4.4896e-01 - val_crf_28_loss: -1.3619e-01 - val_crf_29_loss: -1.5176e-01 - val_crf_30_loss: -1.6101e-01 - val_crf_28_acc_1: 0.9782 - val_crf_28_acc_2: 0.8134 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9623 - val_crf_29_acc_3: 0.8150 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8151 - val_crf_30_acc_3: 0.9865 - val_f1: 0.8634 - val_crf_28_f1: 0.8845 - val_crf_29_f1: 0.7959 - val_crf_30_f1: 0.9097
Epoch 19/25
 - 1618s - loss: -4.4065e-01 - crf_28_loss: -1.2517e-01 - crf_29_loss: -1.5293e-01 - crf_30_loss: -1.6255e-01 - crf_28_acc_1: 0.9645 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9576 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9818 - val_loss: -4.7721e-01 - val_crf_28_loss: -1.4592e-01 - val_crf_29_loss: -1.6114e-01 - val_crf_30_loss: -1.7015e-01 - val_crf_28_acc_1: 0.9782 - val_crf_28_acc_2: 0.8131 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9654 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8136 - val_crf_30_acc_2: 0.8152 - val_crf_30_acc_3: 0.9862 - val_f1: 0.8691 - val_crf_28_f1: 0.8847 - val_crf_29_f1: 0.8148 - val_crf_30_f1: 0.9076
Epoch 20/25
 - 1616s - loss: -4.6902e-01 - crf_28_loss: -1.3427e-01 - crf_29_loss: -1.6251e-01 - crf_30_loss: -1.7224e-01 - crf_28_acc_1: 0.9648 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7721 - crf_29_acc_2: 0.9582 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9819 - val_loss: -5.0444e-01 - val_crf_28_loss: -1.5474e-01 - val_crf_29_loss: -1.7027e-01 - val_crf_30_loss: -1.7944e-01 - val_crf_28_acc_1: 0.9788 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9677 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9864 - val_f1: 0.8747 - val_crf_28_f1: 0.8867 - val_crf_29_f1: 0.8283 - val_crf_30_f1: 0.9091
Epoch 21/25
 - 1610s - loss: -4.9750e-01 - crf_28_loss: -1.4365e-01 - crf_29_loss: -1.7201e-01 - crf_30_loss: -1.8184e-01 - crf_28_acc_1: 0.9649 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9584 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7754 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9821 - val_loss: -5.3281e-01 - val_crf_28_loss: -1.6354e-01 - val_crf_29_loss: -1.7999e-01 - val_crf_30_loss: -1.8929e-01 - val_crf_28_acc_1: 0.9778 - val_crf_28_acc_2: 0.8132 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9651 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9860 - val_f1: 0.8692 - val_crf_28_f1: 0.8846 - val_crf_29_f1: 0.8155 - val_crf_30_f1: 0.9075
Epoch 22/25
 - 1616s - loss: -5.2598e-01 - crf_28_loss: -1.5290e-01 - crf_29_loss: -1.8158e-01 - crf_30_loss: -1.9149e-01 - crf_28_acc_1: 0.9654 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9587 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9820 - val_loss: -5.6216e-01 - val_crf_28_loss: -1.7296e-01 - val_crf_29_loss: -1.8994e-01 - val_crf_30_loss: -1.9926e-01 - val_crf_28_acc_1: 0.9781 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9673 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8154 - val_crf_30_acc_3: 0.9858 - val_f1: 0.8730 - val_crf_28_f1: 0.8854 - val_crf_29_f1: 0.8268 - val_crf_30_f1: 0.9067
Epoch 23/25
 - 1613s - loss: -5.5466e-01 - crf_28_loss: -1.6222e-01 - crf_29_loss: -1.9121e-01 - crf_30_loss: -2.0123e-01 - crf_28_acc_1: 0.9655 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9592 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9822 - val_loss: -5.8814e-01 - val_crf_28_loss: -1.8208e-01 - val_crf_29_loss: -1.9808e-01 - val_crf_30_loss: -2.0799e-01 - val_crf_28_acc_1: 0.9785 - val_crf_28_acc_2: 0.8131 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9643 - val_crf_29_acc_3: 0.8153 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9840 - val_f1: 0.8671 - val_crf_28_f1: 0.8869 - val_crf_29_f1: 0.8131 - val_crf_30_f1: 0.9012
Epoch 24/25
 - 1616s - loss: -5.8304e-01 - crf_28_loss: -1.7150e-01 - crf_29_loss: -2.0068e-01 - crf_30_loss: -2.1087e-01 - crf_28_acc_1: 0.9657 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7721 - crf_29_acc_2: 0.9593 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9823 - val_loss: -6.1626e-01 - val_crf_28_loss: -1.9076e-01 - val_crf_29_loss: -2.0771e-01 - val_crf_30_loss: -2.1779e-01 - val_crf_28_acc_1: 0.9782 - val_crf_28_acc_2: 0.8132 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9650 - val_crf_29_acc_3: 0.8151 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8153 - val_crf_30_acc_3: 0.9860 - val_f1: 0.8689 - val_crf_28_f1: 0.8847 - val_crf_29_f1: 0.8147 - val_crf_30_f1: 0.9072
Epoch 25/25
 - 1610s - loss: -6.1158e-01 - crf_28_loss: -1.8083e-01 - crf_29_loss: -2.1021e-01 - crf_30_loss: -2.2055e-01 - crf_28_acc_1: 0.9659 - crf_28_acc_2: 0.7722 - crf_28_acc_3: 0.7754 - crf_29_acc_1: 0.7722 - crf_29_acc_2: 0.9596 - crf_29_acc_3: 0.7735 - crf_30_acc_1: 0.7753 - crf_30_acc_2: 0.7730 - crf_30_acc_3: 0.9823 - val_loss: -6.4714e-01 - val_crf_28_loss: -2.0013e-01 - val_crf_29_loss: -2.1864e-01 - val_crf_30_loss: -2.2838e-01 - val_crf_28_acc_1: 0.9788 - val_crf_28_acc_2: 0.8133 - val_crf_28_acc_3: 0.8134 - val_crf_29_acc_1: 0.8134 - val_crf_29_acc_2: 0.9661 - val_crf_29_acc_3: 0.8153 - val_crf_30_acc_1: 0.8135 - val_crf_30_acc_2: 0.8152 - val_crf_30_acc_3: 0.9860 - val_f1: 0.8714 - val_crf_28_f1: 0.8872 - val_crf_29_f1: 0.8194 - val_crf_30_f1: 0.9077

-------------------------------------------
Best F1 score: 0.874676250933   (epoch number 20)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.8980    0.5946    0.7154       148
        archivalreference     0.7805    0.8710    0.8233       853
              archive_lib     0.9314    0.9223    0.9268       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9459    0.9363    0.9411      4948
                      box     0.8500    0.4636    0.6000       110
              cartulation     0.6667    1.0000    0.8000         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5161    0.8358    0.6382       134
                     date     0.5000    0.9310    0.6506        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3673    0.6429    0.4675        28
                foliation     0.4286    1.0000    0.6000        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.3014    0.1833    0.2280       120
                        o     0.3150    0.3431    0.3285       752
               pagination     0.9423    0.9614    0.9518      1139
   publicationnumber-year     0.6901    0.8065    0.7438       646
         publicationplace     0.9352    0.9152    0.9251      1592
publicationspecifications     0.3921    0.2930    0.3354       372
                publisher     0.9046    0.8607    0.8821      1443
                      ref     0.1818    0.6667    0.2857         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.8086    0.8562    0.8317       153
                    title     0.9364    0.9526    0.9444     15560
                     tomo     0.8197    0.4464    0.5780       224
                   volume     0.5885    0.5162    0.5500       277
                     year     0.9194    0.8124    0.8626      2036

              avg / total     0.9798    0.9788    0.9788    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.8980    0.5946    0.7154       148
        archivalreference     0.7805    0.8710    0.8233       853
              archive_lib     0.9314    0.9223    0.9268       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9459    0.9363    0.9411      4948
                      box     0.8500    0.4636    0.6000       110
              cartulation     0.6667    1.0000    0.8000         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5161    0.8358    0.6382       134
                     date     0.5000    0.9310    0.6506        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3673    0.6429    0.4675        28
                foliation     0.4286    1.0000    0.6000        12
             numbered_ref     0.3014    0.1833    0.2280       120
                        o     0.3150    0.3431    0.3285       752
               pagination     0.9423    0.9614    0.9518      1139
   publicationnumber-year     0.6901    0.8065    0.7438       646
         publicationplace     0.9352    0.9152    0.9251      1592
publicationspecifications     0.3921    0.2930    0.3354       372
                publisher     0.9046    0.8607    0.8821      1443
                      ref     0.1818    0.6667    0.2857         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.8086    0.8562    0.8317       153
                    title     0.9364    0.9526    0.9444     15560
                     tomo     0.8197    0.4464    0.5780       224
                   volume     0.5885    0.5162    0.5500       277
                     year     0.9194    0.8124    0.8626      2036

              avg / total     0.8922    0.8871    0.8867     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6997    0.6695    0.6843       348
        b-primary     0.8824    0.7143    0.7895       105
      b-secondary     0.7595    0.6819    0.7186       852
e-meta-annotation     0.8588    0.7795    0.8172      1061
        e-primary     0.7205    0.6100    0.6606       300
      e-secondary     0.8316    0.8713    0.8510      1717
i-meta-annotation     0.7957    0.8271    0.8111      9981
        i-primary     0.8754    0.8414    0.8581      1728
      i-secondary     0.8698    0.8523    0.8610     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.3565    0.4801    0.4092       427

      avg / total     0.9682    0.9677    0.9678    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6997    0.6695    0.6843       348
        b-primary     0.8824    0.7143    0.7895       105
      b-secondary     0.7595    0.6819    0.7186       852
e-meta-annotation     0.8588    0.7795    0.8172      1061
        e-primary     0.7205    0.6100    0.6606       300
      e-secondary     0.8316    0.8713    0.8510      1717
i-meta-annotation     0.7957    0.8271    0.8111      9981
        i-primary     0.8754    0.8414    0.8581      1728
      i-secondary     0.8698    0.8523    0.8610     14357
                o     0.3565    0.4801    0.4092       427

      avg / total     0.8302    0.8273    0.8283     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8348    0.7395    0.7842      1305
        e-r     0.4615    0.0137    0.0267      1310
        i-r     0.9427    0.9858    0.9638     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3757    0.5059    0.4311       427

avg / total     0.9831    0.9864    0.9830    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8348    0.7395    0.7842      1305
        e-r     0.4615    0.0137    0.0267      1310
        i-r     0.9427    0.9858    0.9638     27834
          o     0.3757    0.5059    0.4311       427

avg / total     0.9099    0.9275    0.9091     30876




Confusion matrix, without normalization
[[    36      0    112      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    45      3    802      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    17      0     75     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   905      1   4023     19      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    131      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2     25      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     11      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      2    110      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    14      0    512    226      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      8   1127      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     3      1    642      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1591      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0    348     23      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1   1440      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    149      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   126      0  15334    100      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0     19   1839    178      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.43243243e-01   0.00000000e+00   7.56756757e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.27549824e-02   3.51699883e-03   9.40211020e-01   3.51699883e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.65048544e-01   0.00000000e+00   7.28155340e-01   1.06796117e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.82902183e-01   2.02101859e-04   8.13055780e-01   3.83993533e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.77611940e-01   2.23880597e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   7.14285714e-02   8.92857143e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.33333333e-02   9.16666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   1.66666667e-02   9.16666667e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.86170213e-02   0.00000000e+00   6.80851064e-01   3.00531915e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   7.02370500e-03   9.89464442e-01   3.51185250e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.64396285e-03   1.54798762e-03   9.93808050e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.99371859e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   0.00000000e+00   9.35483871e-01   6.18279570e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   6.93000693e-04   9.97920998e-01   6.93000693e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   9.67532468e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.09768638e-03   0.00000000e+00   9.85475578e-01   6.42673522e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   9.33202358e-03   9.03241650e-01   8.74263261e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   278      0     29     41      0      0      0      0      0      0
       0]
 [    60      0     44      1      0      0      0      0      0      0
       0]
 [   627      0    112    113      0      0      0      0      0      0
       0]
 [     0      4   1053      4      0      0      0      0      0      0
       0]
 [     0      0    293      7      0      0      0      0      0      0
       0]
 [     0     14   1690     13      0      0      0      0      0      0
       0]
 [    52      3   9883     43      0      0      0      0      0      0
       0]
 [     9      9   1684     26      0      0      0      0      0      0
       0]
 [   120      9  14117    111      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [    10      0    201    216      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.98850575e-01   0.00000000e+00   8.33333333e-02   1.17816092e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.71428571e-01   0.00000000e+00   4.19047619e-01   9.52380952e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.35915493e-01   0.00000000e+00   1.31455399e-01   1.32629108e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.77002828e-03   9.92459943e-01   3.77002828e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.76666667e-01   2.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.15375655e-03   9.84274898e-01   7.57134537e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.20989881e-03   3.00571085e-04   9.90181345e-01   4.30818555e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.20833333e-03   5.20833333e-03   9.74537037e-01   1.50462963e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.35829212e-03   6.26871909e-04   9.83283416e-01   7.73142021e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  2.34192037e-02   0.00000000e+00   4.70725995e-01   5.05854801e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   965      0    185      0    155]
 [     0     18   1281      0     11]
 [   181     21  27439      0    193]
 [     0      0      0 133958      0]
 [    10      0    201      0    216]]
Normalized confusion matrix
[[  7.39463602e-01   0.00000000e+00   1.41762452e-01   0.00000000e+00
    1.18773946e-01]
 [  0.00000000e+00   1.37404580e-02   9.77862595e-01   0.00000000e+00
    8.39694656e-03]
 [  6.50283826e-03   7.54472947e-04   9.85808723e-01   0.00000000e+00
    6.93396565e-03]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  2.34192037e-02   0.00000000e+00   4.70725995e-01   0.00000000e+00
    5.05854801e-01]]
