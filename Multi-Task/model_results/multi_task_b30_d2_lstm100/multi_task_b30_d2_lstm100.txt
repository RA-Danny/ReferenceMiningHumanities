______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_52 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_52[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_76 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_51 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_51 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_76[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_51 (Embedding)                         (None, 73, 300)                  17130300          input_51[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_52 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_51[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_26 (Concatenate)                     (None, 73, 3000)                 0                 embedding_51[0][0]                                
                                                                                                    time_distributed_52[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_77 (Dropout)                             (None, 73, 3000)                 0                 concatenate_26[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_52 (Bidirectional)                 (None, 73, 200)                  2480800           dropout_77[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_78 (Dropout)                             (None, 73, 200)                  0                 bidirectional_52[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_76 (Dense)                                 (None, 73, 28)                   5628              dropout_78[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_77 (Dense)                                 (None, 73, 11)                   2211              dropout_78[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_78 (Dense)                                 (None, 73, 5)                    1005              dropout_78[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_76 (CRF)                                     (None, 73, 28)                   1652              dense_76[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_77 (CRF)                                     (None, 73, 11)                   275               dense_77[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_78 (CRF)                                     (None, 73, 5)                    65                dense_78[0][0]                                    
======================================================================================================================================================
Total params: 19,663,636
Trainable params: 19,663,636
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 2643s - loss: 0.2936 - crf_76_loss: 0.1439 - crf_77_loss: 0.1033 - crf_78_loss: 0.0464 - crf_76_acc_1: 0.9453 - crf_76_acc_2: 0.7718 - crf_76_acc_3: 0.7752 - crf_77_acc_1: 0.7717 - crf_77_acc_2: 0.9356 - crf_77_acc_3: 0.7736 - crf_78_acc_1: 0.7742 - crf_78_acc_2: 0.7721 - crf_78_acc_3: 0.9752 - val_loss: 0.0465 - val_crf_76_loss: 0.0346 - val_crf_77_loss: 0.0149 - val_crf_78_loss: -2.9973e-03 - val_crf_76_acc_1: 0.9729 - val_crf_76_acc_2: 0.8130 - val_crf_76_acc_3: 0.8134 - val_crf_77_acc_1: 0.8134 - val_crf_77_acc_2: 0.9595 - val_crf_77_acc_3: 0.8154 - val_crf_78_acc_1: 0.8135 - val_crf_78_acc_2: 0.8151 - val_crf_78_acc_3: 0.9897 - val_f1: 0.8609 - val_crf_76_f1: 0.8559 - val_crf_77_f1: 0.7824 - val_crf_78_f1: 0.9443
Epoch 2/25
 - 2581s - loss: 0.0168 - crf_76_loss: 0.0286 - crf_77_loss: 0.0017 - crf_78_loss: -1.3413e-02 - crf_76_acc_1: 0.9655 - crf_76_acc_2: 0.7723 - crf_76_acc_3: 0.7755 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9563 - crf_77_acc_3: 0.7736 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7731 - crf_78_acc_3: 0.9833 - val_loss: -4.8223e-02 - val_crf_76_loss: -1.6379e-03 - val_crf_77_loss: -1.9072e-02 - val_crf_78_loss: -2.7513e-02 - val_crf_76_acc_1: 0.9757 - val_crf_76_acc_2: 0.8130 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8134 - val_crf_77_acc_2: 0.9585 - val_crf_77_acc_3: 0.8152 - val_crf_78_acc_1: 0.8136 - val_crf_78_acc_2: 0.8148 - val_crf_78_acc_3: 0.9878 - val_f1: 0.8581 - val_crf_76_f1: 0.8744 - val_crf_77_f1: 0.7709 - val_crf_78_f1: 0.9289
Epoch 3/25
 - 2581s - loss: -7.5005e-02 - crf_76_loss: -6.2241e-03 - crf_77_loss: -2.9358e-02 - crf_78_loss: -3.9423e-02 - crf_76_acc_1: 0.9690 - crf_76_acc_2: 0.7722 - crf_76_acc_3: 0.7754 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9605 - crf_77_acc_3: 0.7735 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7730 - crf_78_acc_3: 0.9835 - val_loss: -1.2108e-01 - val_crf_76_loss: -2.7631e-02 - val_crf_77_loss: -4.3111e-02 - val_crf_78_loss: -5.0333e-02 - val_crf_76_acc_1: 0.9778 - val_crf_76_acc_2: 0.8130 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8134 - val_crf_77_acc_2: 0.9564 - val_crf_77_acc_3: 0.8152 - val_crf_78_acc_1: 0.8135 - val_crf_78_acc_2: 0.8150 - val_crf_78_acc_3: 0.9858 - val_f1: 0.8498 - val_crf_76_f1: 0.8817 - val_crf_77_f1: 0.7608 - val_crf_78_f1: 0.9068
Epoch 4/25
 - 2636s - loss: -1.4876e-01 - crf_76_loss: -3.2041e-02 - crf_77_loss: -5.3793e-02 - crf_78_loss: -6.2922e-02 - crf_76_acc_1: 0.9713 - crf_76_acc_2: 0.7722 - crf_76_acc_3: 0.7754 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9634 - crf_77_acc_3: 0.7734 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7730 - crf_78_acc_3: 0.9836 - val_loss: -1.8590e-01 - val_crf_76_loss: -4.7522e-02 - val_crf_77_loss: -6.6053e-02 - val_crf_78_loss: -7.2324e-02 - val_crf_76_acc_1: 0.9755 - val_crf_76_acc_2: 0.8130 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8133 - val_crf_77_acc_2: 0.9642 - val_crf_77_acc_3: 0.8153 - val_crf_78_acc_1: 0.8134 - val_crf_78_acc_2: 0.8150 - val_crf_78_acc_3: 0.9847 - val_f1: 0.8623 - val_crf_76_f1: 0.8752 - val_crf_77_f1: 0.8099 - val_crf_78_f1: 0.9019
Epoch 5/25
 - 2592s - loss: -2.1767e-01 - crf_76_loss: -5.5205e-02 - crf_77_loss: -7.6620e-02 - crf_78_loss: -8.5841e-02 - crf_76_acc_1: 0.9730 - crf_76_acc_2: 0.7722 - crf_76_acc_3: 0.7754 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9666 - crf_77_acc_3: 0.7734 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7730 - crf_78_acc_3: 0.9845 - val_loss: -2.5339e-01 - val_crf_76_loss: -7.0260e-02 - val_crf_77_loss: -8.7966e-02 - val_crf_78_loss: -9.5166e-02 - val_crf_76_acc_1: 0.9783 - val_crf_76_acc_2: 0.8129 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8134 - val_crf_77_acc_2: 0.9645 - val_crf_77_acc_3: 0.8154 - val_crf_78_acc_1: 0.8135 - val_crf_78_acc_2: 0.8153 - val_crf_78_acc_3: 0.9857 - val_f1: 0.8667 - val_crf_76_f1: 0.8850 - val_crf_77_f1: 0.8106 - val_crf_78_f1: 0.9047
Epoch 6/25
 - 2633s - loss: -2.8443e-01 - crf_76_loss: -7.7087e-02 - crf_77_loss: -9.8859e-02 - crf_78_loss: -1.0848e-01 - crf_76_acc_1: 0.9747 - crf_76_acc_2: 0.7721 - crf_76_acc_3: 0.7754 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9691 - crf_77_acc_3: 0.7733 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7731 - crf_78_acc_3: 0.9853 - val_loss: -3.1680e-01 - val_crf_76_loss: -8.8871e-02 - val_crf_77_loss: -1.0990e-01 - val_crf_78_loss: -1.1803e-01 - val_crf_76_acc_1: 0.9753 - val_crf_76_acc_2: 0.8130 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8133 - val_crf_77_acc_2: 0.9647 - val_crf_77_acc_3: 0.8153 - val_crf_78_acc_1: 0.8134 - val_crf_78_acc_2: 0.8153 - val_crf_78_acc_3: 0.9854 - val_f1: 0.8642 - val_crf_76_f1: 0.8747 - val_crf_77_f1: 0.8138 - val_crf_78_f1: 0.9042
Epoch 7/25
 - 2578s - loss: -3.5004e-01 - crf_76_loss: -9.8137e-02 - crf_77_loss: -1.2086e-01 - crf_78_loss: -1.3105e-01 - crf_76_acc_1: 0.9756 - crf_76_acc_2: 0.7721 - crf_76_acc_3: 0.7753 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9707 - crf_77_acc_3: 0.7733 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7730 - crf_78_acc_3: 0.9860 - val_loss: -3.7495e-01 - val_crf_76_loss: -1.0744e-01 - val_crf_77_loss: -1.2924e-01 - val_crf_78_loss: -1.3826e-01 - val_crf_76_acc_1: 0.9766 - val_crf_76_acc_2: 0.8129 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8133 - val_crf_77_acc_2: 0.9655 - val_crf_77_acc_3: 0.8152 - val_crf_78_acc_1: 0.8134 - val_crf_78_acc_2: 0.8152 - val_crf_78_acc_3: 0.9845 - val_f1: 0.8653 - val_crf_76_f1: 0.8770 - val_crf_77_f1: 0.8177 - val_crf_78_f1: 0.9013
Epoch 8/25
 - 2587s - loss: -4.1552e-01 - crf_76_loss: -1.1922e-01 - crf_77_loss: -1.4276e-01 - crf_78_loss: -1.5354e-01 - crf_76_acc_1: 0.9770 - crf_76_acc_2: 0.7721 - crf_76_acc_3: 0.7753 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9727 - crf_77_acc_3: 0.7733 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7730 - crf_78_acc_3: 0.9866 - val_loss: -4.3416e-01 - val_crf_76_loss: -1.2537e-01 - val_crf_77_loss: -1.4919e-01 - val_crf_78_loss: -1.5959e-01 - val_crf_76_acc_1: 0.9734 - val_crf_76_acc_2: 0.8129 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8133 - val_crf_77_acc_2: 0.9637 - val_crf_77_acc_3: 0.8152 - val_crf_78_acc_1: 0.8137 - val_crf_78_acc_2: 0.8153 - val_crf_78_acc_3: 0.9851 - val_f1: 0.8594 - val_crf_76_f1: 0.8670 - val_crf_77_f1: 0.8079 - val_crf_78_f1: 0.9032
Epoch 9/25
 - 2589s - loss: -4.8021e-01 - crf_76_loss: -1.3966e-01 - crf_77_loss: -1.6459e-01 - crf_78_loss: -1.7596e-01 - crf_76_acc_1: 0.9779 - crf_76_acc_2: 0.7721 - crf_76_acc_3: 0.7753 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9748 - crf_77_acc_3: 0.7733 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7730 - crf_78_acc_3: 0.9873 - val_loss: -4.9185e-01 - val_crf_76_loss: -1.4392e-01 - val_crf_77_loss: -1.6805e-01 - val_crf_78_loss: -1.7988e-01 - val_crf_76_acc_1: 0.9752 - val_crf_76_acc_2: 0.8130 - val_crf_76_acc_3: 0.8136 - val_crf_77_acc_1: 0.8133 - val_crf_77_acc_2: 0.9633 - val_crf_77_acc_3: 0.8152 - val_crf_78_acc_1: 0.8136 - val_crf_78_acc_2: 0.8155 - val_crf_78_acc_3: 0.9842 - val_f1: 0.8594 - val_crf_76_f1: 0.8716 - val_crf_77_f1: 0.8069 - val_crf_78_f1: 0.8998
Epoch 10/25
 - 2577s - loss: -5.4478e-01 - crf_76_loss: -1.6011e-01 - crf_77_loss: -1.8631e-01 - crf_78_loss: -1.9836e-01 - crf_76_acc_1: 0.9788 - crf_76_acc_2: 0.7721 - crf_76_acc_3: 0.7753 - crf_77_acc_1: 0.7721 - crf_77_acc_2: 0.9765 - crf_77_acc_3: 0.7732 - crf_78_acc_1: 0.7753 - crf_78_acc_2: 0.7730 - crf_78_acc_3: 0.9877 - val_loss: -5.5084e-01 - val_crf_76_loss: -1.6131e-01 - val_crf_77_loss: -1.8816e-01 - val_crf_78_loss: -2.0137e-01 - val_crf_76_acc_1: 0.9713 - val_crf_76_acc_2: 0.8130 - val_crf_76_acc_3: 0.8135 - val_crf_77_acc_1: 0.8133 - val_crf_77_acc_2: 0.9620 - val_crf_77_acc_3: 0.8152 - val_crf_78_acc_1: 0.8136 - val_crf_78_acc_2: 0.8152 - val_crf_78_acc_3: 0.9822 - val_f1: 0.8519 - val_crf_76_f1: 0.8606 - val_crf_77_f1: 0.8016 - val_crf_78_f1: 0.8936

-------------------------------------------
Best F1 score: 0.866730877874   (epoch number 5)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9565    0.5946    0.7333       148
        archivalreference     0.8383    0.8265    0.8323       853
              archive_lib     0.8512    1.0000    0.9196       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9415    0.9276    0.9345      4948
                      box     0.8393    0.4273    0.5663       110
              cartulation     0.1290    1.0000    0.2286         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5351    0.7388    0.6207       134
                     date     0.3309    0.7759    0.4639        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3833    0.8214    0.5227        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.3125    0.1667    0.2174       120
                        o     0.3266    0.3218    0.3242       752
               pagination     0.9365    0.9579    0.9470      1139
   publicationnumber-year     0.7019    0.8529    0.7701       646
         publicationplace     0.9272    0.9121    0.9196      1592
publicationspecifications     0.3041    0.4194    0.3525       372
                publisher     0.9253    0.8330    0.8767      1443
                      ref     0.1818    0.6667    0.2857         3
                 registry     0.6154    0.1039    0.1778       154
                   series     0.8699    0.8301    0.8495       153
                    title     0.9331    0.9552    0.9440     15560
                     tomo     0.7143    0.3571    0.4762       224
                   volume     0.7239    0.4260    0.5364       277
                     year     0.9461    0.8104    0.8730      2036

              avg / total     0.9799    0.9783    0.9785    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9565    0.5946    0.7333       148
        archivalreference     0.8383    0.8265    0.8323       853
              archive_lib     0.8512    1.0000    0.9196       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9415    0.9276    0.9345      4948
                      box     0.8393    0.4273    0.5663       110
              cartulation     0.1290    1.0000    0.2286         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5351    0.7388    0.6207       134
                     date     0.3309    0.7759    0.4639        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.3833    0.8214    0.5227        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.3125    0.1667    0.2174       120
                        o     0.3266    0.3218    0.3242       752
               pagination     0.9365    0.9579    0.9470      1139
   publicationnumber-year     0.7019    0.8529    0.7701       646
         publicationplace     0.9272    0.9121    0.9196      1592
publicationspecifications     0.3041    0.4194    0.3525       372
                publisher     0.9253    0.8330    0.8767      1443
                      ref     0.1818    0.6667    0.2857         3
                 registry     0.6154    0.1039    0.1778       154
                   series     0.8699    0.8301    0.8495       153
                    title     0.9331    0.9552    0.9440     15560
                     tomo     0.7143    0.3571    0.4762       224
                   volume     0.7239    0.4260    0.5364       277
                     year     0.9461    0.8104    0.8730      2036

              avg / total     0.8929    0.8840    0.8850     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6914    0.6437    0.6667       348
        b-primary     0.5455    0.2286    0.3221       105
      b-secondary     0.7577    0.6315    0.6889       852
e-meta-annotation     0.8715    0.6522    0.7461      1061
        e-primary     0.6854    0.7333    0.7085       300
      e-secondary     0.7872    0.8725    0.8276      1717
i-meta-annotation     0.8065    0.8047    0.8056      9981
        i-primary     0.6740    0.9178    0.7773      1728
      i-secondary     0.8633    0.8392    0.8511     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.3145    0.3770    0.3429       427

      avg / total     0.9654    0.9645    0.9645    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6914    0.6437    0.6667       348
        b-primary     0.5455    0.2286    0.3221       105
      b-secondary     0.7577    0.6315    0.6889       852
e-meta-annotation     0.8715    0.6522    0.7461      1061
        e-primary     0.6854    0.7333    0.7085       300
      e-secondary     0.7872    0.8725    0.8276      1717
i-meta-annotation     0.8065    0.8047    0.8056      9981
        i-primary     0.6740    0.9178    0.7773      1728
      i-secondary     0.8633    0.8392    0.8511     14357
                o     0.3145    0.3770    0.3429       427

      avg / total     0.8151    0.8104    0.8106     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8305    0.6797    0.7476      1305
        e-r     0.2889    0.0099    0.0192      1310
        i-r     0.9386    0.9859    0.9617     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.3472    0.4286    0.3836       427

avg / total     0.9810    0.9857    0.9821    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8305    0.6797    0.7476      1305
        e-r     0.2889    0.0099    0.0192      1310
        i-r     0.9386    0.9859    0.9617     27834
          o     0.3472    0.4286    0.3836       427

avg / total     0.8983    0.9239    0.9047     30876




Confusion matrix, without normalization
[[    37      0     95     16      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     9      7    828      9      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    17      0     86      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   854      3   4077     14      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    130      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     28      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3    112      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    12      1    540    199      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      6   1102     30      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      1    639      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1591      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0    341     30      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1442      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     4      0    150      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   124      4  15381     51      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5     19   1847    165      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   6.41891892e-01   1.08108108e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.05509965e-02   8.20633060e-03   9.70691676e-01   1.05509965e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.65048544e-01   0.00000000e+00   8.34951456e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.72594988e-01   6.06305578e-04   8.23969281e-01   2.82942603e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.70149254e-01   2.98507463e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.33333333e-03   2.50000000e-02   9.33333333e-01   3.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.59574468e-02   1.32978723e-03   7.18085106e-01   2.64627660e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   5.26777875e-03   9.67515364e-01   2.63388938e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.09597523e-03   1.54798762e-03   9.89164087e-01   6.19195046e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.99371859e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   0.00000000e+00   9.16666667e-01   8.06451613e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   0.00000000e+00   9.99306999e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.59740260e-02   0.00000000e+00   9.74025974e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.96915167e-03   2.57069409e-04   9.88496144e-01   3.27763496e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.45579568e-03   9.33202358e-03   9.07170923e-01   8.10412574e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   267      0     46     35      0      0      0      0      0      0
       0]
 [    25      0     80      0      0      0      0      0      0      0
       0]
 [   595      0    149    108      0      0      0      0      0      0
       0]
 [     1      2   1032     26      0      0      0      0      0      0
       0]
 [     0      0    293      7      0      0      0      0      0      0
       0]
 [     0     11   1699      7      0      0      0      0      0      0
       0]
 [    46      8   9839     88      0      0      0      0      0      0
       0]
 [     6     11   1691     20      0      0      0      0      0      0
       0]
 [   119     13  14172     53      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     9      0    235    183      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.67241379e-01   0.00000000e+00   1.32183908e-01   1.00574713e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.38095238e-01   0.00000000e+00   7.61904762e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.98356808e-01   0.00000000e+00   1.74882629e-01   1.26760563e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.42507069e-04   1.88501414e-03   9.72667295e-01   2.45051838e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.76666667e-01   2.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.40652301e-03   9.89516599e-01   4.07687828e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.60875664e-03   8.01522893e-04   9.85772969e-01   8.81675183e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.47222222e-03   6.36574074e-03   9.78587963e-01   1.15740741e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.28863969e-03   9.05481647e-04   9.87114300e-01   3.69157902e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  2.10772834e-02   0.00000000e+00   5.50351288e-01   4.28571429e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   887      0    275      0    143]
 [     0     13   1284      0     13]
 [   172     32  27442      0    188]
 [     0      0      0 133958      0]
 [     9      0    235      0    183]]
Normalized confusion matrix
[[ 0.67969349  0.          0.21072797  0.          0.10957854]
 [ 0.          0.00992366  0.98015267  0.          0.00992366]
 [ 0.00617949  0.00114967  0.9859165   0.          0.00675433]
 [ 0.          0.          0.          1.          0.        ]
 [ 0.02107728  0.          0.55035129  0.          0.42857143]]
