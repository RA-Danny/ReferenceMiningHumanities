______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_42 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_42[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_61 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_41 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_41 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_61[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_41 (Embedding)                         (None, 73, 300)                  17130300          input_41[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_42 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_41[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_21 (Concatenate)                     (None, 73, 3000)                 0                 embedding_41[0][0]                                
                                                                                                    time_distributed_42[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_62 (Dropout)                             (None, 73, 3000)                 0                 concatenate_21[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_42 (Bidirectional)                 (None, 73, 80)                   973120            dropout_62[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_63 (Dropout)                             (None, 73, 80)                   0                 bidirectional_42[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_61 (Dense)                                 (None, 73, 28)                   2268              dropout_63[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_62 (Dense)                                 (None, 73, 11)                   891               dropout_63[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_63 (Dense)                                 (None, 73, 5)                    405               dropout_63[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_61 (CRF)                                     (None, 73, 28)                   1652              dense_61[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_62 (CRF)                                     (None, 73, 11)                   275               dense_62[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_63 (CRF)                                     (None, 73, 5)                    65                dense_63[0][0]                                    
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 2616s - loss: 0.4681 - crf_61_loss: 0.2485 - crf_62_loss: 0.1574 - crf_63_loss: 0.0622 - crf_61_acc_1: 0.9045 - crf_61_acc_2: 0.7723 - crf_61_acc_3: 0.7752 - crf_62_acc_1: 0.7709 - crf_62_acc_2: 0.8993 - crf_62_acc_3: 0.7742 - crf_63_acc_1: 0.7720 - crf_63_acc_2: 0.7720 - crf_63_acc_3: 0.9598 - val_loss: 0.0905 - val_crf_61_loss: 0.0696 - val_crf_62_loss: 0.0255 - val_crf_63_loss: -4.6215e-03 - val_crf_61_acc_1: 0.9517 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8133 - val_crf_62_acc_2: 0.9393 - val_crf_62_acc_3: 0.8154 - val_crf_63_acc_1: 0.8129 - val_crf_63_acc_2: 0.8146 - val_crf_63_acc_3: 0.9880 - val_f1: 0.7635 - val_crf_61_f1: 0.7010 - val_crf_62_f1: 0.6566 - val_crf_63_f1: 0.9328
Epoch 2/25
 - 2548s - loss: 0.0928 - crf_61_loss: 0.0795 - crf_62_loss: 0.0192 - crf_63_loss: -5.8832e-03 - crf_61_acc_1: 0.9298 - crf_61_acc_2: 0.7727 - crf_61_acc_3: 0.7760 - crf_62_acc_1: 0.7722 - crf_62_acc_2: 0.9269 - crf_62_acc_3: 0.7742 - crf_63_acc_1: 0.7743 - crf_63_acc_2: 0.7729 - crf_63_acc_3: 0.9715 - val_loss: -2.5077e-02 - val_crf_61_loss: 0.0197 - val_crf_62_loss: -1.3730e-02 - val_crf_63_loss: -3.1023e-02 - val_crf_61_acc_1: 0.9556 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8133 - val_crf_62_acc_2: 0.9481 - val_crf_62_acc_3: 0.8152 - val_crf_63_acc_1: 0.8130 - val_crf_63_acc_2: 0.8145 - val_crf_63_acc_3: 0.9844 - val_f1: 0.7862 - val_crf_61_f1: 0.7372 - val_crf_62_f1: 0.7133 - val_crf_63_f1: 0.9081
Epoch 3/25
 - 2546s - loss: -1.1670e-02 - crf_61_loss: 0.0354 - crf_62_loss: -1.4850e-02 - crf_63_loss: -3.2176e-02 - crf_61_acc_1: 0.9350 - crf_61_acc_2: 0.7726 - crf_61_acc_3: 0.7757 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9299 - crf_62_acc_3: 0.7741 - crf_63_acc_1: 0.7748 - crf_63_acc_2: 0.7730 - crf_63_acc_3: 0.9717 - val_loss: -1.0531e-01 - val_crf_61_loss: -1.2406e-02 - val_crf_62_loss: -3.8906e-02 - val_crf_63_loss: -5.4000e-02 - val_crf_61_acc_1: 0.9624 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8134 - val_crf_62_acc_2: 0.9537 - val_crf_62_acc_3: 0.8153 - val_crf_63_acc_1: 0.8132 - val_crf_63_acc_2: 0.8149 - val_crf_63_acc_3: 0.9828 - val_f1: 0.8159 - val_crf_61_f1: 0.7976 - val_crf_62_f1: 0.7568 - val_crf_63_f1: 0.8933
Epoch 4/25
 - 2552s - loss: -8.9000e-02 - crf_61_loss: 0.0066 - crf_62_loss: -3.9879e-02 - crf_63_loss: -5.5750e-02 - crf_61_acc_1: 0.9379 - crf_61_acc_2: 0.7726 - crf_61_acc_3: 0.7757 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9319 - crf_62_acc_3: 0.7740 - crf_63_acc_1: 0.7751 - crf_63_acc_2: 0.7729 - crf_63_acc_3: 0.9722 - val_loss: -1.7528e-01 - val_crf_61_loss: -3.6487e-02 - val_crf_62_loss: -6.1912e-02 - val_crf_63_loss: -7.6886e-02 - val_crf_61_acc_1: 0.9638 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8133 - val_crf_62_acc_2: 0.9520 - val_crf_62_acc_3: 0.8154 - val_crf_63_acc_1: 0.8132 - val_crf_63_acc_2: 0.8147 - val_crf_63_acc_3: 0.9839 - val_f1: 0.8124 - val_crf_61_f1: 0.7982 - val_crf_62_f1: 0.7437 - val_crf_63_f1: 0.8953
Epoch 5/25
 - 2548s - loss: -1.5948e-01 - crf_61_loss: -1.7994e-02 - crf_62_loss: -6.2855e-02 - crf_63_loss: -7.8627e-02 - crf_61_acc_1: 0.9398 - crf_61_acc_2: 0.7726 - crf_61_acc_3: 0.7756 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9331 - crf_62_acc_3: 0.7740 - crf_63_acc_1: 0.7752 - crf_63_acc_2: 0.7730 - crf_63_acc_3: 0.9727 - val_loss: -2.4385e-01 - val_crf_61_loss: -6.0459e-02 - val_crf_62_loss: -8.4025e-02 - val_crf_63_loss: -9.9363e-02 - val_crf_61_acc_1: 0.9661 - val_crf_61_acc_2: 0.8132 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8133 - val_crf_62_acc_2: 0.9538 - val_crf_62_acc_3: 0.8151 - val_crf_63_acc_1: 0.8134 - val_crf_63_acc_2: 0.8150 - val_crf_63_acc_3: 0.9838 - val_f1: 0.8238 - val_crf_61_f1: 0.8202 - val_crf_62_f1: 0.7531 - val_crf_63_f1: 0.8982
Epoch 6/25
 - 2541s - loss: -2.2723e-01 - crf_61_loss: -4.0747e-02 - crf_62_loss: -8.5257e-02 - crf_63_loss: -1.0122e-01 - crf_61_acc_1: 0.9413 - crf_61_acc_2: 0.7726 - crf_61_acc_3: 0.7756 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9348 - crf_62_acc_3: 0.7740 - crf_63_acc_1: 0.7754 - crf_63_acc_2: 0.7729 - crf_63_acc_3: 0.9731 - val_loss: -3.0783e-01 - val_crf_61_loss: -8.1507e-02 - val_crf_62_loss: -1.0498e-01 - val_crf_63_loss: -1.2135e-01 - val_crf_61_acc_1: 0.9677 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8134 - val_crf_62_acc_2: 0.9469 - val_crf_62_acc_3: 0.8153 - val_crf_63_acc_1: 0.8133 - val_crf_63_acc_2: 0.8144 - val_crf_63_acc_3: 0.9827 - val_f1: 0.8089 - val_crf_61_f1: 0.8253 - val_crf_62_f1: 0.7086 - val_crf_63_f1: 0.8927
Epoch 7/25
 - 2547s - loss: -2.9337e-01 - crf_61_loss: -6.2379e-02 - crf_62_loss: -1.0728e-01 - crf_63_loss: -1.2372e-01 - crf_61_acc_1: 0.9424 - crf_61_acc_2: 0.7726 - crf_61_acc_3: 0.7756 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9355 - crf_62_acc_3: 0.7739 - crf_63_acc_1: 0.7753 - crf_63_acc_2: 0.7729 - crf_63_acc_3: 0.9737 - val_loss: -3.7773e-01 - val_crf_61_loss: -1.0414e-01 - val_crf_62_loss: -1.2871e-01 - val_crf_63_loss: -1.4488e-01 - val_crf_61_acc_1: 0.9682 - val_crf_61_acc_2: 0.8132 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8134 - val_crf_62_acc_2: 0.9581 - val_crf_62_acc_3: 0.8152 - val_crf_63_acc_1: 0.8135 - val_crf_63_acc_2: 0.8150 - val_crf_63_acc_3: 0.9851 - val_f1: 0.8364 - val_crf_61_f1: 0.8304 - val_crf_62_f1: 0.7762 - val_crf_63_f1: 0.9024
Epoch 8/25
 - 2551s - loss: -3.5920e-01 - crf_61_loss: -8.3882e-02 - crf_62_loss: -1.2921e-01 - crf_63_loss: -1.4611e-01 - crf_61_acc_1: 0.9430 - crf_61_acc_2: 0.7725 - crf_61_acc_3: 0.7756 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9368 - crf_62_acc_3: 0.7739 - crf_63_acc_1: 0.7755 - crf_63_acc_2: 0.7730 - crf_63_acc_3: 0.9741 - val_loss: -4.4209e-01 - val_crf_61_loss: -1.2507e-01 - val_crf_62_loss: -1.5021e-01 - val_crf_63_loss: -1.6681e-01 - val_crf_61_acc_1: 0.9698 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8134 - val_crf_62_acc_2: 0.9557 - val_crf_62_acc_3: 0.8153 - val_crf_63_acc_1: 0.8134 - val_crf_63_acc_2: 0.8148 - val_crf_63_acc_3: 0.9847 - val_f1: 0.8322 - val_crf_61_f1: 0.8339 - val_crf_62_f1: 0.7627 - val_crf_63_f1: 0.9000
Epoch 9/25
 - 2555s - loss: -4.2425e-01 - crf_61_loss: -1.0469e-01 - crf_62_loss: -1.5106e-01 - crf_63_loss: -1.6850e-01 - crf_61_acc_1: 0.9438 - crf_61_acc_2: 0.7725 - crf_61_acc_3: 0.7755 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9364 - crf_62_acc_3: 0.7739 - crf_63_acc_1: 0.7755 - crf_63_acc_2: 0.7729 - crf_63_acc_3: 0.9742 - val_loss: -5.0506e-01 - val_crf_61_loss: -1.4498e-01 - val_crf_62_loss: -1.7113e-01 - val_crf_63_loss: -1.8895e-01 - val_crf_61_acc_1: 0.9684 - val_crf_61_acc_2: 0.8131 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8133 - val_crf_62_acc_2: 0.9485 - val_crf_62_acc_3: 0.8152 - val_crf_63_acc_1: 0.8134 - val_crf_63_acc_2: 0.8147 - val_crf_63_acc_3: 0.9838 - val_f1: 0.8164 - val_crf_61_f1: 0.8313 - val_crf_62_f1: 0.7192 - val_crf_63_f1: 0.8986
Epoch 10/25
 - 2550s - loss: -4.8892e-01 - crf_61_loss: -1.2542e-01 - crf_62_loss: -1.7279e-01 - crf_63_loss: -1.9071e-01 - crf_61_acc_1: 0.9443 - crf_61_acc_2: 0.7725 - crf_61_acc_3: 0.7755 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9382 - crf_62_acc_3: 0.7739 - crf_63_acc_1: 0.7754 - crf_63_acc_2: 0.7729 - crf_63_acc_3: 0.9744 - val_loss: -5.7159e-01 - val_crf_61_loss: -1.6664e-01 - val_crf_62_loss: -1.9344e-01 - val_crf_63_loss: -2.1150e-01 - val_crf_61_acc_1: 0.9703 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8134 - val_crf_62_acc_2: 0.9529 - val_crf_62_acc_3: 0.8152 - val_crf_63_acc_1: 0.8134 - val_crf_63_acc_2: 0.8147 - val_crf_63_acc_3: 0.9833 - val_f1: 0.8286 - val_crf_61_f1: 0.8404 - val_crf_62_f1: 0.7490 - val_crf_63_f1: 0.8964
Epoch 11/25
 - 2547s - loss: -5.5360e-01 - crf_61_loss: -1.4602e-01 - crf_62_loss: -1.9455e-01 - crf_63_loss: -2.1303e-01 - crf_61_acc_1: 0.9447 - crf_61_acc_2: 0.7725 - crf_61_acc_3: 0.7755 - crf_62_acc_1: 0.7724 - crf_62_acc_2: 0.9382 - crf_62_acc_3: 0.7739 - crf_63_acc_1: 0.7755 - crf_63_acc_2: 0.7730 - crf_63_acc_3: 0.9746 - val_loss: -6.3572e-01 - val_crf_61_loss: -1.8695e-01 - val_crf_62_loss: -2.1511e-01 - val_crf_63_loss: -2.3366e-01 - val_crf_61_acc_1: 0.9702 - val_crf_61_acc_2: 0.8130 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8133 - val_crf_62_acc_2: 0.9530 - val_crf_62_acc_3: 0.8153 - val_crf_63_acc_1: 0.8134 - val_crf_63_acc_2: 0.8145 - val_crf_63_acc_3: 0.9849 - val_f1: 0.8280 - val_crf_61_f1: 0.8395 - val_crf_62_f1: 0.7435 - val_crf_63_f1: 0.9010
Epoch 12/25
 - 2551s - loss: -6.1820e-01 - crf_61_loss: -1.6668e-01 - crf_62_loss: -2.1620e-01 - crf_63_loss: -2.3532e-01 - crf_61_acc_1: 0.9454 - crf_61_acc_2: 0.7724 - crf_61_acc_3: 0.7756 - crf_62_acc_1: 0.7723 - crf_62_acc_2: 0.9388 - crf_62_acc_3: 0.7738 - crf_63_acc_1: 0.7755 - crf_63_acc_2: 0.7729 - crf_63_acc_3: 0.9750 - val_loss: -7.0167e-01 - val_crf_61_loss: -2.0819e-01 - val_crf_62_loss: -2.3711e-01 - val_crf_63_loss: -2.5637e-01 - val_crf_61_acc_1: 0.9710 - val_crf_61_acc_2: 0.8131 - val_crf_61_acc_3: 0.8134 - val_crf_62_acc_1: 0.8133 - val_crf_62_acc_2: 0.9535 - val_crf_62_acc_3: 0.8152 - val_crf_63_acc_1: 0.8134 - val_crf_63_acc_2: 0.8146 - val_crf_63_acc_3: 0.9849 - val_f1: 0.8321 - val_crf_61_f1: 0.8474 - val_crf_62_f1: 0.7467 - val_crf_63_f1: 0.9023

-------------------------------------------
Best F1 score: 0.836369943046   (epoch number 7)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9000    0.4865    0.6316       148
        archivalreference     0.6085    0.8218    0.6993       853
              archive_lib     0.9610    0.7184    0.8222       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9071    0.8905    0.8987      4948
                      box     0.7273    0.3636    0.4848       110
              cartulation     0.1356    1.0000    0.2388         8
              conjunction     0.5077    0.7388    0.6018       134
                     date     0.4252    0.9310    0.5838        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2456    0.5000    0.3294        28
                foliation     0.7500    1.0000    0.8571        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1538    0.2500    0.1905       120
                        o     0.1944    0.2301    0.2107       752
               pagination     0.9025    0.9508    0.9260      1139
   publicationnumber-year     0.6555    0.6656    0.6605       646
         publicationplace     0.8844    0.8361    0.8595      1592
publicationspecifications     0.1089    0.0753    0.0890       372
                publisher     0.8611    0.7387    0.7952      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.6400    0.1039    0.1788       154
                   series     0.7368    0.3660    0.4891       153
                    title     0.8959    0.9192    0.9074     15560
                     tomo     0.2353    0.0179    0.0332       224
                   volume     0.4355    0.4874    0.4600       277
                     year     0.9191    0.7313    0.8146      2036

              avg / total     0.9700    0.9682    0.9682    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9000    0.4865    0.6316       148
        archivalreference     0.6085    0.8218    0.6993       853
              archive_lib     0.9610    0.7184    0.8222       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9071    0.8905    0.8987      4948
                      box     0.7273    0.3636    0.4848       110
              cartulation     0.1356    1.0000    0.2388         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5077    0.7388    0.6018       134
                     date     0.4252    0.9310    0.5838        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2456    0.5000    0.3294        28
                foliation     0.7500    1.0000    0.8571        12
             numbered_ref     0.1538    0.2500    0.1905       120
                        o     0.1944    0.2301    0.2107       752
               pagination     0.9025    0.9508    0.9260      1139
   publicationnumber-year     0.6555    0.6656    0.6605       646
         publicationplace     0.8844    0.8361    0.8595      1592
publicationspecifications     0.1089    0.0753    0.0890       372
                publisher     0.8611    0.7387    0.7952      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.6400    0.1039    0.1788       154
                   series     0.7368    0.3660    0.4891       153
                    title     0.8959    0.9192    0.9074     15560
                     tomo     0.2353    0.0179    0.0332       224
                   volume     0.4355    0.4874    0.4600       277
                     year     0.9191    0.7313    0.8146      2036

              avg / total     0.8400    0.8300    0.8304     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6743    0.4224    0.5194       348
        b-primary     0.8310    0.5619    0.6705       105
      b-secondary     0.6750    0.6655    0.6702       852
e-meta-annotation     0.8947    0.6645    0.7626      1061
        e-primary     0.7572    0.6967    0.7257       300
      e-secondary     0.7896    0.7758    0.7826      1717
i-meta-annotation     0.7830    0.6937    0.7357      9981
        i-primary     0.8773    0.9062    0.8915      1728
      i-secondary     0.7877    0.8587    0.8216     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.1771    0.2974    0.2220       427

      avg / total     0.9592    0.9581    0.9581    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6743    0.4224    0.5194       348
        b-primary     0.8310    0.5619    0.6705       105
      b-secondary     0.6750    0.6655    0.6702       852
e-meta-annotation     0.8947    0.6645    0.7626      1061
        e-primary     0.7572    0.6967    0.7257       300
      e-secondary     0.7896    0.7758    0.7826      1717
i-meta-annotation     0.7830    0.6937    0.7357      9981
        i-primary     0.8773    0.9062    0.8915      1728
      i-secondary     0.7877    0.8587    0.8216     14357
                o     0.1771    0.2974    0.2220       427

      avg / total     0.7820    0.7761    0.7762     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8229    0.7050    0.7594      1305
        e-r     0.4545    0.0115    0.0223      1310
        i-r     0.9387    0.9818    0.9598     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2577    0.3700    0.3038       427

avg / total     0.9820    0.9851    0.9817    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8229    0.7050    0.7594      1305
        e-r     0.4545    0.0115    0.0223      1310
        i-r     0.9387    0.9818    0.9598     27834
          o     0.2577    0.3700    0.3038       427

avg / total     0.9038    0.9205    0.9024     30876




Confusion matrix, without normalization
[[    36      0    112      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    48      3    793      9      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    18      0     74     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   900      0   4034     14      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    129      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     58      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3     24      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      2    116      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     9      0    585    158      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      6   1133      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1    644      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1590      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    353     19      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      0   1441      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     6      0    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    94      4  15246    216      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0     14   1842    180      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.43243243e-01   0.00000000e+00   7.56756757e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.62719812e-02   3.51699883e-03   9.29660023e-01   1.05509965e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.74757282e-01   0.00000000e+00   7.18446602e-01   1.06796117e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.81891673e-01   0.00000000e+00   8.15278901e-01   2.82942603e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.62686567e-01   3.73134328e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   1.07142857e-01   8.57142857e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   1.66666667e-02   9.66666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.19680851e-02   0.00000000e+00   7.77925532e-01   2.10106383e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   5.26777875e-03   9.94732221e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   1.54798762e-03   9.96904025e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   0.00000000e+00   9.98743719e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.48924731e-01   5.10752688e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.38600139e-03   0.00000000e+00   9.98613999e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.89610390e-02   0.00000000e+00   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.04113111e-03   2.57069409e-04   9.79820051e-01   1.38817481e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.87622790e-03   9.04715128e-01   8.84086444e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   261      0     49     38      0      0      0      0      0      0
       0]
 [    64      0     40      1      0      0      0      0      0      0
       0]
 [   595      0    149    108      0      0      0      0      0      0
       0]
 [     0      3   1056      2      0      0      0      0      0      0
       0]
 [     0      2    295      3      0      0      0      0      0      0
       0]
 [     0     10   1691     16      0      0      0      0      0      0
       0]
 [    59      4   9835     83      0      0      0      0      0      0
       0]
 [    10      8   1689     21      0      0      0      0      0      0
       0]
 [   123      6  14045    183      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     6      0    263    158      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.50000000e-01   0.00000000e+00   1.40804598e-01   1.09195402e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.09523810e-01   0.00000000e+00   3.80952381e-01   9.52380952e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.98356808e-01   0.00000000e+00   1.74882629e-01   1.26760563e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.82752121e-03   9.95287465e-01   1.88501414e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.66666667e-03   9.83333333e-01   1.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   5.82411182e-03   9.84857309e-01   9.31857892e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.91123134e-03   4.00761447e-04   9.85372207e-01   8.31580002e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.78703704e-03   4.62962963e-03   9.77430556e-01   1.21527778e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.56724943e-03   4.17914606e-04   9.78268440e-01   1.27463955e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.40515222e-02   0.00000000e+00   6.15925059e-01   3.70023419e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   920      0    238      0    147]
 [     0     15   1284      0     11]
 [   192     18  27327      0    297]
 [     0      0      0 133958      0]
 [     6      0    263      0    158]]
Normalized confusion matrix
[[  7.04980843e-01   0.00000000e+00   1.82375479e-01   0.00000000e+00
    1.12643678e-01]
 [  0.00000000e+00   1.14503817e-02   9.80152672e-01   0.00000000e+00
    8.39694656e-03]
 [  6.89803837e-03   6.46691097e-04   9.81784867e-01   0.00000000e+00
    1.06704031e-02]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  1.40515222e-02   0.00000000e+00   6.15925059e-01   0.00000000e+00
    3.70023419e-01]]
