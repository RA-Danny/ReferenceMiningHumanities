______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_4 (InputLayer)                             (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_4[0][0]                                     
______________________________________________________________________________________________________________________________________________________
dropout_4 (Dropout)                              (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_3 (InputLayer)                             (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_3 (TimeDistributed)             (None, 73, 54, 50)               25200             dropout_4[0][0]                                   
______________________________________________________________________________________________________________________________________________________
embedding_3 (Embedding)                          (None, 73, 300)                  17130300          input_3[0][0]                                     
______________________________________________________________________________________________________________________________________________________
time_distributed_4 (TimeDistributed)             (None, 73, 2700)                 0                 time_distributed_3[0][0]                          
______________________________________________________________________________________________________________________________________________________
concatenate_2 (Concatenate)                      (None, 73, 3000)                 0                 embedding_3[0][0]                                 
                                                                                                    time_distributed_4[0][0]                          
______________________________________________________________________________________________________________________________________________________
dropout_5 (Dropout)                              (None, 73, 3000)                 0                 concatenate_2[0][0]                               
______________________________________________________________________________________________________________________________________________________
bidirectional_4 (Bidirectional)                  (None, 73, 200)                  2480800           dropout_5[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dropout_6 (Dropout)                              (None, 73, 200)                  0                 bidirectional_4[0][0]                             
______________________________________________________________________________________________________________________________________________________
dense_4 (Dense)                                  (None, 73, 28)                   5628              dropout_6[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dense_5 (Dense)                                  (None, 73, 11)                   2211              dropout_6[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dense_6 (Dense)                                  (None, 73, 5)                    1005              dropout_6[0][0]                                   
______________________________________________________________________________________________________________________________________________________
crf_4 (CRF)                                      (None, 73, 28)                   1652              dense_4[0][0]                                     
______________________________________________________________________________________________________________________________________________________
crf_5 (CRF)                                      (None, 73, 11)                   275               dense_5[0][0]                                     
______________________________________________________________________________________________________________________________________________________
crf_6 (CRF)                                      (None, 73, 5)                    65                dense_6[0][0]                                     
======================================================================================================================================================
Total params: 19,663,636
Trainable params: 19,663,636
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1465s - loss: 0.7225 - crf_4_loss: 0.3348 - crf_5_loss: 0.2528 - crf_6_loss: 0.1349 - crf_4_acc_1: 0.8983 - crf_4_acc_2: 0.7710 - crf_4_acc_3: 0.7721 - crf_5_acc_1: 0.7701 - crf_5_acc_2: 0.8936 - crf_5_acc_3: 0.7712 - crf_6_acc_1: 0.7711 - crf_6_acc_2: 0.7702 - crf_6_acc_3: 0.9515 - val_loss: 0.2366 - val_crf_4_loss: 0.1201 - val_crf_5_loss: 0.0902 - val_crf_6_loss: 0.0262 - val_crf_4_acc_1: 0.9545 - val_crf_4_acc_2: 0.8131 - val_crf_4_acc_3: 0.8133 - val_crf_5_acc_1: 0.8132 - val_crf_5_acc_2: 0.9354 - val_crf_5_acc_3: 0.8156 - val_crf_6_acc_1: 0.8130 - val_crf_6_acc_2: 0.8136 - val_crf_6_acc_3: 0.9893 - val_f1: 0.7569 - val_crf_4_f1: 0.7183 - val_crf_5_f1: 0.6145 - val_crf_6_f1: 0.9380
Epoch 2/25
 - 1459s - loss: 0.2960 - crf_4_loss: 0.1559 - crf_5_loss: 0.0976 - crf_6_loss: 0.0425 - crf_4_acc_1: 0.9350 - crf_4_acc_2: 0.7726 - crf_4_acc_3: 0.7759 - crf_5_acc_1: 0.7721 - crf_5_acc_2: 0.9316 - crf_5_acc_3: 0.7742 - crf_6_acc_1: 0.7740 - crf_6_acc_2: 0.7726 - crf_6_acc_3: 0.9751 - val_loss: 0.1273 - val_crf_4_loss: 0.0729 - val_crf_5_loss: 0.0438 - val_crf_6_loss: 0.0106 - val_crf_4_acc_1: 0.9616 - val_crf_4_acc_2: 0.8132 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8133 - val_crf_5_acc_2: 0.9501 - val_crf_5_acc_3: 0.8155 - val_crf_6_acc_1: 0.8131 - val_crf_6_acc_2: 0.8151 - val_crf_6_acc_3: 0.9892 - val_f1: 0.8180 - val_crf_4_f1: 0.7764 - val_crf_5_f1: 0.7357 - val_crf_6_f1: 0.9418
Epoch 3/25
 - 1449s - loss: 0.1709 - crf_4_loss: 0.1014 - crf_5_loss: 0.0505 - crf_6_loss: 0.0190 - crf_4_acc_1: 0.9433 - crf_4_acc_2: 0.7725 - crf_4_acc_3: 0.7758 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9393 - crf_5_acc_3: 0.7740 - crf_6_acc_1: 0.7743 - crf_6_acc_2: 0.7729 - crf_6_acc_3: 0.9778 - val_loss: 0.0659 - val_crf_4_loss: 0.0475 - val_crf_5_loss: 0.0184 - val_crf_6_loss: -3.2661e-05 - val_crf_4_acc_1: 0.9643 - val_crf_4_acc_2: 0.8133 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9578 - val_crf_5_acc_3: 0.8153 - val_crf_6_acc_1: 0.8134 - val_crf_6_acc_2: 0.8147 - val_crf_6_acc_3: 0.9896 - val_f1: 0.8397 - val_crf_4_f1: 0.8018 - val_crf_5_f1: 0.7742 - val_crf_6_f1: 0.9430
Epoch 4/25
 - 1444s - loss: 0.1005 - crf_4_loss: 0.0704 - crf_5_loss: 0.0252 - crf_6_loss: 0.0049 - crf_4_acc_1: 0.9480 - crf_4_acc_2: 0.7725 - crf_4_acc_3: 0.7757 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9429 - crf_5_acc_3: 0.7739 - crf_6_acc_1: 0.7746 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9788 - val_loss: 0.0313 - val_crf_4_loss: 0.0334 - val_crf_5_loss: 0.0054 - val_crf_6_loss: -7.5305e-03 - val_crf_4_acc_1: 0.9616 - val_crf_4_acc_2: 0.8134 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9550 - val_crf_5_acc_3: 0.8154 - val_crf_6_acc_1: 0.8136 - val_crf_6_acc_2: 0.8148 - val_crf_6_acc_3: 0.9871 - val_f1: 0.8352 - val_crf_4_f1: 0.8063 - val_crf_5_f1: 0.7618 - val_crf_6_f1: 0.9375
Epoch 5/25
 - 1443s - loss: 0.0540 - crf_4_loss: 0.0503 - crf_5_loss: 0.0090 - crf_6_loss: -5.3351e-03 - crf_4_acc_1: 0.9507 - crf_4_acc_2: 0.7724 - crf_4_acc_3: 0.7756 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9444 - crf_5_acc_3: 0.7739 - crf_6_acc_1: 0.7748 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9789 - val_loss: -3.3426e-03 - val_crf_4_loss: 0.0169 - val_crf_5_loss: -4.2709e-03 - val_crf_6_loss: -1.6020e-02 - val_crf_4_acc_1: 0.9690 - val_crf_4_acc_2: 0.8133 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9445 - val_crf_5_acc_3: 0.8153 - val_crf_6_acc_1: 0.8134 - val_crf_6_acc_2: 0.8145 - val_crf_6_acc_3: 0.9869 - val_f1: 0.8178 - val_crf_4_f1: 0.8334 - val_crf_5_f1: 0.6861 - val_crf_6_f1: 0.9338
Epoch 6/25
 - 1444s - loss: 0.0187 - crf_4_loss: 0.0360 - crf_5_loss: -3.0895e-03 - crf_6_loss: -1.4185e-02 - crf_4_acc_1: 0.9525 - crf_4_acc_2: 0.7724 - crf_4_acc_3: 0.7756 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9450 - crf_5_acc_3: 0.7738 - crf_6_acc_1: 0.7750 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9790 - val_loss: -3.8561e-02 - val_crf_4_loss: 0.0041 - val_crf_5_loss: -1.7833e-02 - val_crf_6_loss: -2.4852e-02 - val_crf_4_acc_1: 0.9717 - val_crf_4_acc_2: 0.8133 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9587 - val_crf_5_acc_3: 0.8153 - val_crf_6_acc_1: 0.8135 - val_crf_6_acc_2: 0.8149 - val_crf_6_acc_3: 0.9879 - val_f1: 0.8529 - val_crf_4_f1: 0.8462 - val_crf_5_f1: 0.7777 - val_crf_6_f1: 0.9349
Epoch 7/25
 - 1460s - loss: -1.1088e-02 - crf_4_loss: 0.0242 - crf_5_loss: -1.3025e-02 - crf_6_loss: -2.2264e-02 - crf_4_acc_1: 0.9540 - crf_4_acc_2: 0.7724 - crf_4_acc_3: 0.7756 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9465 - crf_5_acc_3: 0.7738 - crf_6_acc_1: 0.7751 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9790 - val_loss: -5.1670e-02 - val_crf_4_loss: -9.4036e-04 - val_crf_5_loss: -2.2003e-02 - val_crf_6_loss: -2.8726e-02 - val_crf_4_acc_1: 0.9652 - val_crf_4_acc_2: 0.8133 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9467 - val_crf_5_acc_3: 0.8152 - val_crf_6_acc_1: 0.8132 - val_crf_6_acc_2: 0.8149 - val_crf_6_acc_3: 0.9805 - val_f1: 0.8170 - val_crf_4_f1: 0.8319 - val_crf_5_f1: 0.7097 - val_crf_6_f1: 0.9095
Epoch 8/25
 - 1444s - loss: -3.7119e-02 - crf_4_loss: 0.0142 - crf_5_loss: -2.1668e-02 - crf_6_loss: -2.9700e-02 - crf_4_acc_1: 0.9548 - crf_4_acc_2: 0.7724 - crf_4_acc_3: 0.7755 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9473 - crf_5_acc_3: 0.7737 - crf_6_acc_1: 0.7751 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9788 - val_loss: -8.5970e-02 - val_crf_4_loss: -1.3411e-02 - val_crf_5_loss: -3.3608e-02 - val_crf_6_loss: -3.8951e-02 - val_crf_4_acc_1: 0.9743 - val_crf_4_acc_2: 0.8133 - val_crf_4_acc_3: 0.8133 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9562 - val_crf_5_acc_3: 0.8152 - val_crf_6_acc_1: 0.8135 - val_crf_6_acc_2: 0.8149 - val_crf_6_acc_3: 0.9860 - val_f1: 0.8449 - val_crf_4_f1: 0.8591 - val_crf_5_f1: 0.7618 - val_crf_6_f1: 0.9140
Epoch 9/25
 - 1446s - loss: -6.1654e-02 - crf_4_loss: 0.0054 - crf_5_loss: -2.9845e-02 - crf_6_loss: -3.7166e-02 - crf_4_acc_1: 0.9557 - crf_4_acc_2: 0.7723 - crf_4_acc_3: 0.7755 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9475 - crf_5_acc_3: 0.7737 - crf_6_acc_1: 0.7751 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9788 - val_loss: -1.0660e-01 - val_crf_4_loss: -2.1486e-02 - val_crf_5_loss: -3.9859e-02 - val_crf_6_loss: -4.5256e-02 - val_crf_4_acc_1: 0.9745 - val_crf_4_acc_2: 0.8131 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9538 - val_crf_5_acc_3: 0.8151 - val_crf_6_acc_1: 0.8135 - val_crf_6_acc_2: 0.8148 - val_crf_6_acc_3: 0.9856 - val_f1: 0.8380 - val_crf_4_f1: 0.8612 - val_crf_5_f1: 0.7436 - val_crf_6_f1: 0.9092
Epoch 10/25
 - 1445s - loss: -8.4787e-02 - crf_4_loss: -3.0070e-03 - crf_5_loss: -3.7409e-02 - crf_6_loss: -4.4371e-02 - crf_4_acc_1: 0.9563 - crf_4_acc_2: 0.7724 - crf_4_acc_3: 0.7755 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9486 - crf_5_acc_3: 0.7737 - crf_6_acc_1: 0.7753 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9788 - val_loss: -1.2591e-01 - val_crf_4_loss: -2.6774e-02 - val_crf_5_loss: -4.7333e-02 - val_crf_6_loss: -5.1802e-02 - val_crf_4_acc_1: 0.9706 - val_crf_4_acc_2: 0.8130 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9583 - val_crf_5_acc_3: 0.8155 - val_crf_6_acc_1: 0.8135 - val_crf_6_acc_2: 0.8154 - val_crf_6_acc_3: 0.9847 - val_f1: 0.8428 - val_crf_4_f1: 0.8490 - val_crf_5_f1: 0.7794 - val_crf_6_f1: 0.9000
Epoch 11/25
 - 1442s - loss: -1.0719e-01 - crf_4_loss: -1.0974e-02 - crf_5_loss: -4.4800e-02 - crf_6_loss: -5.1420e-02 - crf_4_acc_1: 0.9569 - crf_4_acc_2: 0.7724 - crf_4_acc_3: 0.7755 - crf_5_acc_1: 0.7722 - crf_5_acc_2: 0.9493 - crf_5_acc_3: 0.7737 - crf_6_acc_1: 0.7752 - crf_6_acc_2: 0.7730 - crf_6_acc_3: 0.9788 - val_loss: -1.4880e-01 - val_crf_4_loss: -3.5814e-02 - val_crf_5_loss: -5.3791e-02 - val_crf_6_loss: -5.9200e-02 - val_crf_4_acc_1: 0.9743 - val_crf_4_acc_2: 0.8133 - val_crf_4_acc_3: 0.8134 - val_crf_5_acc_1: 0.8134 - val_crf_5_acc_2: 0.9541 - val_crf_5_acc_3: 0.8152 - val_crf_6_acc_1: 0.8136 - val_crf_6_acc_2: 0.8146 - val_crf_6_acc_3: 0.9865 - val_f1: 0.8381 - val_crf_4_f1: 0.8643 - val_crf_5_f1: 0.7412 - val_crf_6_f1: 0.9087

-------------------------------------------
Best F1 score: 0.852930370012   (epoch number 6)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9367    0.5000    0.6520       148
        archivalreference     0.6464    0.8593    0.7378       853
              archive_lib     0.9659    0.8252    0.8901       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9155    0.9125    0.9140      4948
                      box     0.8438    0.4909    0.6207       110
              cartulation     0.2759    1.0000    0.4324         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5344    0.7537    0.6254       134
                     date     0.4602    0.8966    0.6082        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4359    0.6071    0.5075        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.2469    0.1667    0.1990       120
                        o     0.1954    0.2739    0.2281       752
               pagination     0.9232    0.9605    0.9415      1139
   publicationnumber-year     0.5832    0.7214    0.6450       646
         publicationplace     0.9048    0.8832    0.8938      1592
publicationspecifications     0.1573    0.0376    0.0607       372
                publisher     0.8317    0.8184    0.8250      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7826    0.2353    0.3618       153
                    title     0.9157    0.9247    0.9202     15560
                     tomo     0.8333    0.0446    0.0847       224
                   volume     0.4069    0.5523    0.4686       277
                     year     0.9156    0.7677    0.8352      2036

              avg / total     0.9733    0.9717    0.9712    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9367    0.5000    0.6520       148
        archivalreference     0.6464    0.8593    0.7378       853
              archive_lib     0.9659    0.8252    0.8901       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9155    0.9125    0.9140      4948
                      box     0.8438    0.4909    0.6207       110
              cartulation     0.2759    1.0000    0.4324         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5344    0.7537    0.6254       134
                     date     0.4602    0.8966    0.6082        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.4359    0.6071    0.5075        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.2469    0.1667    0.1990       120
                        o     0.1954    0.2739    0.2281       752
               pagination     0.9232    0.9605    0.9415      1139
   publicationnumber-year     0.5832    0.7214    0.6450       646
         publicationplace     0.9048    0.8832    0.8938      1592
publicationspecifications     0.1573    0.0376    0.0607       372
                publisher     0.8317    0.8184    0.8250      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7826    0.2353    0.3618       153
                    title     0.9157    0.9247    0.9202     15560
                     tomo     0.8333    0.0446    0.0847       224
                   volume     0.4069    0.5523    0.4686       277
                     year     0.9156    0.7677    0.8352      2036

              avg / total     0.8577    0.8488    0.8462     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7772    0.4310    0.5545       348
        b-primary     0.8690    0.6952    0.7725       105
      b-secondary     0.6728    0.6878    0.6802       852
e-meta-annotation     0.9090    0.6117    0.7313      1061
        e-primary     0.7269    0.6300    0.6750       300
      e-secondary     0.7553    0.8375    0.7943      1717
i-meta-annotation     0.8654    0.6244    0.7254      9981
        i-primary     0.8644    0.8374    0.8507      1728
      i-secondary     0.7693    0.9153    0.8360     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.1781    0.3724    0.2409       427

      avg / total     0.9623    0.9587    0.9584    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7772    0.4310    0.5545       348
        b-primary     0.8690    0.6952    0.7725       105
      b-secondary     0.6728    0.6878    0.6802       852
e-meta-annotation     0.9090    0.6117    0.7313      1061
        e-primary     0.7269    0.6300    0.6750       300
      e-secondary     0.7553    0.8375    0.7943      1717
i-meta-annotation     0.8654    0.6244    0.7254      9981
        i-primary     0.8644    0.8374    0.8507      1728
      i-secondary     0.7693    0.9153    0.8360     14357
                o     0.1781    0.3724    0.2409       427

      avg / total     0.7989    0.7794    0.7777     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8242    0.6897    0.7509      1305
        e-r     0.9547    0.4664    0.6267      1310
        i-r     0.9589    0.9768    0.9677     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2336    0.4333    0.3035       427

avg / total     0.9893    0.9879    0.9878    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8242    0.6897    0.7509      1305
        e-r     0.9547    0.4664    0.6267      1310
        i-r     0.9589    0.9768    0.9677     27834
          o     0.2336    0.4333    0.3035       427

avg / total     0.9430    0.9355    0.9349     30876




Confusion matrix, without normalization
[[    37      0    111      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    43      2    799      9      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    18      0     72     13      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   874      1   4052     21      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    129      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2     56      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1     26      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     11      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      3    115      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     6      6    534    206      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     3    175    957      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3    635      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1   1587      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2    347     22      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1441      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      1    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   100      5  15152    303      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    437   1402    197      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   7.50000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.04103165e-02   2.34466589e-03   9.36694021e-01   1.05509965e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.74757282e-01   0.00000000e+00   6.99029126e-01   1.26213592e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.76637025e-01   2.02101859e-04   8.18916734e-01   4.24413905e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.62686567e-01   3.73134328e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.44827586e-02   9.65517241e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   3.57142857e-02   9.28571429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.33333333e-02   9.16666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   2.50000000e-02   9.58333333e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.97872340e-03   7.97872340e-03   7.10106383e-01   2.73936170e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.63388938e-03   1.53643547e-01   8.40210711e-01   3.51185250e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   4.64396285e-03   9.82972136e-01   1.08359133e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.28140704e-04   6.28140704e-04   9.96859296e-01   1.88442211e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   5.37634409e-03   9.32795699e-01   5.91397849e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.98613999e-01   1.38600139e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   6.49350649e-03   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.42673522e-03   3.21336761e-04   9.73778920e-01   1.94730077e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.14636542e-01   6.88605108e-01   9.67583497e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   260      0     46     42      0      0      0      0      0      0
       0]
 [    58      0     45      2      0      0      0      0      0      0
       0]
 [   582      0    156    114      0      0      0      0      0      0
       0]
 [     2    193    858      8      0      0      0      0      0      0
       0]
 [     0      3    288      9      0      0      0      0      0      0
       0]
 [     0    415   1282     20      0      0      0      0      0      0
       0]
 [    53      9   9753    166      0      0      0      0      0      0
       0]
 [    11      8   1680     29      0      0      0      0      0      0
       0]
 [   122      9  14009    217      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     4      3    235    185      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.47126437e-01   0.00000000e+00   1.32183908e-01   1.20689655e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.52380952e-01   0.00000000e+00   4.28571429e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.83098592e-01   0.00000000e+00   1.83098592e-01   1.33802817e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.88501414e-03   1.81903864e-01   8.08671065e-01   7.54005655e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.00000000e-02   9.60000000e-01   3.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.41700641e-01   7.46651136e-01   1.16482236e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.31008917e-03   9.01713255e-04   9.77156598e-01   1.66316000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.36574074e-03   4.62962963e-03   9.72222222e-01   1.67824074e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.49759699e-03   6.26871909e-04   9.75760953e-01   1.51145783e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  9.36768150e-03   7.02576112e-03   5.50351288e-01   4.33255269e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   900      0    247      0    158]
 [     0    611    683      0     16]
 [   188     26  27187      0    433]
 [     0      0      0 133958      0]
 [     4      3    235      0    185]]
Normalized confusion matrix
[[  6.89655172e-01   0.00000000e+00   1.89272031e-01   0.00000000e+00
    1.21072797e-01]
 [  0.00000000e+00   4.66412214e-01   5.21374046e-01   0.00000000e+00
    1.22137405e-02]
 [  6.75432924e-03   9.34109363e-04   9.76755048e-01   0.00000000e+00
    1.55565136e-02]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  9.36768150e-03   7.02576112e-03   5.50351288e-01   0.00000000e+00
    4.33255269e-01]]
