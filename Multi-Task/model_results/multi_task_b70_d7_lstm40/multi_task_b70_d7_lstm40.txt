______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_24 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_24[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_34 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_23 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_23 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_34[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_23 (Embedding)                         (None, 73, 300)                  17130300          input_23[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_24 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_23[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_12 (Concatenate)                     (None, 73, 3000)                 0                 embedding_23[0][0]                                
                                                                                                    time_distributed_24[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_35 (Dropout)                             (None, 73, 3000)                 0                 concatenate_12[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_24 (Bidirectional)                 (None, 73, 80)                   973120            dropout_35[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_36 (Dropout)                             (None, 73, 80)                   0                 bidirectional_24[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_34 (Dense)                                 (None, 73, 28)                   2268              dropout_36[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_35 (Dense)                                 (None, 73, 11)                   891               dropout_36[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_36 (Dense)                                 (None, 73, 5)                    405               dropout_36[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_34 (CRF)                                     (None, 73, 28)                   1652              dense_34[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_35 (CRF)                                     (None, 73, 11)                   275               dense_35[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_36 (CRF)                                     (None, 73, 5)                    65                dense_36[0][0]                                    
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1750s - loss: 0.6825 - crf_34_loss: 0.3513 - crf_35_loss: 0.2379 - crf_36_loss: 0.0933 - crf_34_acc_1: 0.8922 - crf_34_acc_2: 0.7700 - crf_34_acc_3: 0.7757 - crf_35_acc_1: 0.7690 - crf_35_acc_2: 0.8863 - crf_35_acc_3: 0.7750 - crf_36_acc_1: 0.7697 - crf_36_acc_2: 0.7692 - crf_36_acc_3: 0.9533 - val_loss: 0.2230 - val_crf_34_loss: 0.1244 - val_crf_35_loss: 0.0799 - val_crf_36_loss: 0.0188 - val_crf_34_acc_1: 0.9499 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8133 - val_crf_35_acc_1: 0.8132 - val_crf_35_acc_2: 0.9350 - val_crf_35_acc_3: 0.8157 - val_crf_36_acc_1: 0.8129 - val_crf_36_acc_2: 0.8139 - val_crf_36_acc_3: 0.9875 - val_f1: 0.7528 - val_crf_34_f1: 0.6912 - val_crf_35_f1: 0.6390 - val_crf_36_f1: 0.9282
Epoch 2/25
 - 1728s - loss: 0.2541 - crf_34_loss: 0.1517 - crf_35_loss: 0.0788 - crf_36_loss: 0.0237 - crf_34_acc_1: 0.9282 - crf_34_acc_2: 0.7728 - crf_34_acc_3: 0.7760 - crf_35_acc_1: 0.7722 - crf_35_acc_2: 0.9233 - crf_35_acc_3: 0.7744 - crf_36_acc_1: 0.7737 - crf_36_acc_2: 0.7727 - crf_36_acc_3: 0.9714 - val_loss: 0.1022 - val_crf_34_loss: 0.0686 - val_crf_35_loss: 0.0326 - val_crf_36_loss: 0.0011 - val_crf_34_acc_1: 0.9550 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9429 - val_crf_35_acc_3: 0.8157 - val_crf_36_acc_1: 0.8131 - val_crf_36_acc_2: 0.8140 - val_crf_36_acc_3: 0.9886 - val_f1: 0.7768 - val_crf_34_f1: 0.7224 - val_crf_35_f1: 0.6743 - val_crf_36_f1: 0.9338
Epoch 3/25
 - 1706s - loss: 0.1368 - crf_34_loss: 0.0942 - crf_35_loss: 0.0373 - crf_36_loss: 0.0053 - crf_34_acc_1: 0.9346 - crf_34_acc_2: 0.7727 - crf_34_acc_3: 0.7759 - crf_35_acc_1: 0.7722 - crf_35_acc_2: 0.9288 - crf_35_acc_3: 0.7742 - crf_36_acc_1: 0.7741 - crf_36_acc_2: 0.7728 - crf_36_acc_3: 0.9729 - val_loss: 0.0399 - val_crf_34_loss: 0.0401 - val_crf_35_loss: 0.0106 - val_crf_36_loss: -1.0829e-02 - val_crf_34_acc_1: 0.9589 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8132 - val_crf_35_acc_2: 0.9527 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8130 - val_crf_36_acc_2: 0.8149 - val_crf_36_acc_3: 0.9877 - val_f1: 0.8129 - val_crf_34_f1: 0.7581 - val_crf_35_f1: 0.7489 - val_crf_36_f1: 0.9318
Epoch 4/25
 - 1699s - loss: 0.0721 - crf_34_loss: 0.0643 - crf_35_loss: 0.0157 - crf_36_loss: -7.8312e-03 - crf_34_acc_1: 0.9380 - crf_34_acc_2: 0.7726 - crf_34_acc_3: 0.7758 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9321 - crf_35_acc_3: 0.7741 - crf_36_acc_1: 0.7744 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9731 - val_loss: -3.4930e-03 - val_crf_34_loss: 0.0214 - val_crf_35_loss: -3.4721e-03 - val_crf_36_loss: -2.1412e-02 - val_crf_34_acc_1: 0.9620 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9472 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8132 - val_crf_36_acc_2: 0.8144 - val_crf_36_acc_3: 0.9843 - val_f1: 0.7996 - val_crf_34_f1: 0.7833 - val_crf_35_f1: 0.7091 - val_crf_36_f1: 0.9065
Epoch 5/25
 - 1705s - loss: 0.0265 - crf_34_loss: 0.0448 - crf_35_loss: 7.5359e-04 - crf_36_loss: -1.9081e-02 - crf_34_acc_1: 0.9407 - crf_34_acc_2: 0.7726 - crf_34_acc_3: 0.7757 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9342 - crf_35_acc_3: 0.7740 - crf_36_acc_1: 0.7748 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9730 - val_loss: -4.2240e-02 - val_crf_34_loss: 0.0061 - val_crf_35_loss: -1.6257e-02 - val_crf_36_loss: -3.2097e-02 - val_crf_34_acc_1: 0.9644 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9521 - val_crf_35_acc_3: 0.8155 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8144 - val_crf_36_acc_3: 0.9837 - val_f1: 0.8110 - val_crf_34_f1: 0.8007 - val_crf_35_f1: 0.7380 - val_crf_36_f1: 0.8944
Epoch 6/25
 - 1709s - loss: -1.2143e-02 - crf_34_loss: 0.0296 - crf_35_loss: -1.1887e-02 - crf_36_loss: -2.9871e-02 - crf_34_acc_1: 0.9422 - crf_34_acc_2: 0.7726 - crf_34_acc_3: 0.7756 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9346 - crf_35_acc_3: 0.7740 - crf_36_acc_1: 0.7748 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9734 - val_loss: -7.5195e-02 - val_crf_34_loss: -6.2986e-03 - val_crf_35_loss: -2.6871e-02 - val_crf_36_loss: -4.2026e-02 - val_crf_34_acc_1: 0.9660 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9528 - val_crf_35_acc_3: 0.8154 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8151 - val_crf_36_acc_3: 0.9835 - val_f1: 0.8203 - val_crf_34_f1: 0.8145 - val_crf_35_f1: 0.7506 - val_crf_36_f1: 0.8958
Epoch 7/25
 - 1706s - loss: -4.6458e-02 - crf_34_loss: 0.0169 - crf_35_loss: -2.3146e-02 - crf_36_loss: -4.0164e-02 - crf_34_acc_1: 0.9434 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7756 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9363 - crf_35_acc_3: 0.7740 - crf_36_acc_1: 0.7751 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9737 - val_loss: -1.0637e-01 - val_crf_34_loss: -1.8078e-02 - val_crf_35_loss: -3.6424e-02 - val_crf_36_loss: -5.1871e-02 - val_crf_34_acc_1: 0.9674 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9452 - val_crf_35_acc_3: 0.8152 - val_crf_36_acc_1: 0.8135 - val_crf_36_acc_2: 0.8145 - val_crf_36_acc_3: 0.9839 - val_f1: 0.8055 - val_crf_34_f1: 0.8258 - val_crf_35_f1: 0.6926 - val_crf_36_f1: 0.8981
Epoch 8/25
 - 1705s - loss: -7.8771e-02 - crf_34_loss: 0.0050 - crf_35_loss: -3.3581e-02 - crf_36_loss: -5.0218e-02 - crf_34_acc_1: 0.9449 - crf_34_acc_2: 0.7726 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9369 - crf_35_acc_3: 0.7740 - crf_36_acc_1: 0.7752 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9738 - val_loss: -1.3895e-01 - val_crf_34_loss: -2.8981e-02 - val_crf_35_loss: -4.7992e-02 - val_crf_36_loss: -6.1975e-02 - val_crf_34_acc_1: 0.9688 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9550 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8148 - val_crf_36_acc_3: 0.9854 - val_f1: 0.8291 - val_crf_34_f1: 0.8289 - val_crf_35_f1: 0.7572 - val_crf_36_f1: 0.9013
Epoch 9/25
 - 1701s - loss: -1.1021e-01 - crf_34_loss: -5.9623e-03 - crf_35_loss: -4.3962e-02 - crf_36_loss: -6.0281e-02 - crf_34_acc_1: 0.9453 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7756 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9379 - crf_35_acc_3: 0.7739 - crf_36_acc_1: 0.7752 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9742 - val_loss: -1.6821e-01 - val_crf_34_loss: -3.9268e-02 - val_crf_35_loss: -5.7383e-02 - val_crf_36_loss: -7.1560e-02 - val_crf_34_acc_1: 0.9686 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9516 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8147 - val_crf_36_acc_3: 0.9845 - val_f1: 0.8217 - val_crf_34_f1: 0.8291 - val_crf_35_f1: 0.7370 - val_crf_36_f1: 0.8990
Epoch 10/25
 - 1711s - loss: -1.4075e-01 - crf_34_loss: -1.6487e-02 - crf_35_loss: -5.4061e-02 - crf_36_loss: -7.0207e-02 - crf_34_acc_1: 0.9462 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9384 - crf_35_acc_3: 0.7739 - crf_36_acc_1: 0.7752 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9745 - val_loss: -1.9614e-01 - val_crf_34_loss: -4.8389e-02 - val_crf_35_loss: -6.6782e-02 - val_crf_36_loss: -8.0972e-02 - val_crf_34_acc_1: 0.9680 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9508 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8147 - val_crf_36_acc_3: 0.9835 - val_f1: 0.8207 - val_crf_34_f1: 0.8318 - val_crf_35_f1: 0.7342 - val_crf_36_f1: 0.8961
Epoch 11/25
 - 1702s - loss: -1.7058e-01 - crf_34_loss: -2.6653e-02 - crf_35_loss: -6.3889e-02 - crf_36_loss: -8.0034e-02 - crf_34_acc_1: 0.9465 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9395 - crf_35_acc_3: 0.7739 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9748 - val_loss: -2.2706e-01 - val_crf_34_loss: -5.9135e-02 - val_crf_35_loss: -7.6971e-02 - val_crf_36_loss: -9.0950e-02 - val_crf_34_acc_1: 0.9701 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9557 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8135 - val_crf_36_acc_2: 0.8150 - val_crf_36_acc_3: 0.9853 - val_f1: 0.8342 - val_crf_34_f1: 0.8376 - val_crf_35_f1: 0.7630 - val_crf_36_f1: 0.9020
Epoch 12/25
 - 1706s - loss: -2.0055e-01 - crf_34_loss: -3.6954e-02 - crf_35_loss: -7.3759e-02 - crf_36_loss: -8.9833e-02 - crf_34_acc_1: 0.9474 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9397 - crf_35_acc_3: 0.7739 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9749 - val_loss: -2.5674e-01 - val_crf_34_loss: -6.9438e-02 - val_crf_35_loss: -8.6483e-02 - val_crf_36_loss: -1.0082e-01 - val_crf_34_acc_1: 0.9701 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9553 - val_crf_35_acc_3: 0.8152 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8150 - val_crf_36_acc_3: 0.9844 - val_f1: 0.8340 - val_crf_34_f1: 0.8406 - val_crf_35_f1: 0.7629 - val_crf_36_f1: 0.8985
Epoch 13/25
 - 1724s - loss: -2.2971e-01 - crf_34_loss: -4.6803e-02 - crf_35_loss: -8.3391e-02 - crf_36_loss: -9.9519e-02 - crf_34_acc_1: 0.9479 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9403 - crf_35_acc_3: 0.7739 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9751 - val_loss: -2.8352e-01 - val_crf_34_loss: -7.7601e-02 - val_crf_35_loss: -9.5897e-02 - val_crf_36_loss: -1.1002e-01 - val_crf_34_acc_1: 0.9679 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8132 - val_crf_35_acc_2: 0.9521 - val_crf_35_acc_3: 0.8154 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8150 - val_crf_36_acc_3: 0.9838 - val_f1: 0.8263 - val_crf_34_f1: 0.8347 - val_crf_35_f1: 0.7469 - val_crf_36_f1: 0.8973
Epoch 14/25
 - 1702s - loss: -2.5924e-01 - crf_34_loss: -5.6476e-02 - crf_35_loss: -9.3286e-02 - crf_36_loss: -1.0947e-01 - crf_34_acc_1: 0.9483 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9413 - crf_35_acc_3: 0.7739 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9753 - val_loss: -3.1435e-01 - val_crf_34_loss: -8.8125e-02 - val_crf_35_loss: -1.0598e-01 - val_crf_36_loss: -1.2025e-01 - val_crf_34_acc_1: 0.9705 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9550 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8135 - val_crf_36_acc_2: 0.8152 - val_crf_36_acc_3: 0.9853 - val_f1: 0.8360 - val_crf_34_f1: 0.8452 - val_crf_35_f1: 0.7610 - val_crf_36_f1: 0.9019
Epoch 15/25
 - 1727s - loss: -2.8836e-01 - crf_34_loss: -6.6377e-02 - crf_35_loss: -1.0291e-01 - crf_36_loss: -1.1907e-01 - crf_34_acc_1: 0.9488 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7754 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9416 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7754 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9758 - val_loss: -3.4329e-01 - val_crf_34_loss: -9.7820e-02 - val_crf_35_loss: -1.1551e-01 - val_crf_36_loss: -1.2996e-01 - val_crf_34_acc_1: 0.9709 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9541 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8146 - val_crf_36_acc_3: 0.9851 - val_f1: 0.8306 - val_crf_34_f1: 0.8435 - val_crf_35_f1: 0.7474 - val_crf_36_f1: 0.9009
Epoch 16/25
 - 1701s - loss: -3.1729e-01 - crf_34_loss: -7.5927e-02 - crf_35_loss: -1.1252e-01 - crf_36_loss: -1.2884e-01 - crf_34_acc_1: 0.9487 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7754 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9421 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9757 - val_loss: -3.7081e-01 - val_crf_34_loss: -1.0677e-01 - val_crf_35_loss: -1.2498e-01 - val_crf_36_loss: -1.3905e-01 - val_crf_34_acc_1: 0.9698 - val_crf_34_acc_2: 0.8129 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9553 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8136 - val_crf_36_acc_2: 0.8148 - val_crf_36_acc_3: 0.9837 - val_f1: 0.8343 - val_crf_34_f1: 0.8429 - val_crf_35_f1: 0.7632 - val_crf_36_f1: 0.8967
Epoch 17/25
 - 1711s - loss: -3.4629e-01 - crf_34_loss: -8.5582e-02 - crf_35_loss: -1.2215e-01 - crf_36_loss: -1.3856e-01 - crf_34_acc_1: 0.9495 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9417 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7754 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9759 - val_loss: -4.0003e-01 - val_crf_34_loss: -1.1648e-01 - val_crf_35_loss: -1.3466e-01 - val_crf_36_loss: -1.4889e-01 - val_crf_34_acc_1: 0.9712 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9573 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8148 - val_crf_36_acc_3: 0.9841 - val_f1: 0.8394 - val_crf_34_f1: 0.8483 - val_crf_35_f1: 0.7718 - val_crf_36_f1: 0.8979
Epoch 18/25
 - 1706s - loss: -3.7526e-01 - crf_34_loss: -9.5020e-02 - crf_35_loss: -1.3192e-01 - crf_36_loss: -1.4832e-01 - crf_34_acc_1: 0.9498 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9423 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9761 - val_loss: -4.2956e-01 - val_crf_34_loss: -1.2647e-01 - val_crf_35_loss: -1.4434e-01 - val_crf_36_loss: -1.5875e-01 - val_crf_34_acc_1: 0.9723 - val_crf_34_acc_2: 0.8131 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9576 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8135 - val_crf_36_acc_2: 0.8149 - val_crf_36_acc_3: 0.9851 - val_f1: 0.8416 - val_crf_34_f1: 0.8509 - val_crf_35_f1: 0.7729 - val_crf_36_f1: 0.9009
Epoch 19/25
 - 1698s - loss: -4.0399e-01 - crf_34_loss: -1.0452e-01 - crf_35_loss: -1.4144e-01 - crf_36_loss: -1.5803e-01 - crf_34_acc_1: 0.9498 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9424 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9763 - val_loss: -4.5804e-01 - val_crf_34_loss: -1.3602e-01 - val_crf_35_loss: -1.5373e-01 - val_crf_36_loss: -1.6829e-01 - val_crf_34_acc_1: 0.9735 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9565 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8149 - val_crf_36_acc_3: 0.9852 - val_f1: 0.8409 - val_crf_34_f1: 0.8554 - val_crf_35_f1: 0.7658 - val_crf_36_f1: 0.9014
Epoch 20/25
 - 1703s - loss: -4.3284e-01 - crf_34_loss: -1.1394e-01 - crf_35_loss: -1.5113e-01 - crf_36_loss: -1.6777e-01 - crf_34_acc_1: 0.9503 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9435 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7754 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9765 - val_loss: -4.8677e-01 - val_crf_34_loss: -1.4532e-01 - val_crf_35_loss: -1.6347e-01 - val_crf_36_loss: -1.7799e-01 - val_crf_34_acc_1: 0.9718 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9561 - val_crf_35_acc_3: 0.8153 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8150 - val_crf_36_acc_3: 0.9854 - val_f1: 0.8393 - val_crf_34_f1: 0.8498 - val_crf_35_f1: 0.7664 - val_crf_36_f1: 0.9017
Epoch 21/25
 - 1707s - loss: -4.6146e-01 - crf_34_loss: -1.2346e-01 - crf_35_loss: -1.6059e-01 - crf_36_loss: -1.7741e-01 - crf_34_acc_1: 0.9505 - crf_34_acc_2: 0.7725 - crf_34_acc_3: 0.7754 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9434 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9766 - val_loss: -5.1515e-01 - val_crf_34_loss: -1.5449e-01 - val_crf_35_loss: -1.7308e-01 - val_crf_36_loss: -1.8758e-01 - val_crf_34_acc_1: 0.9724 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9575 - val_crf_35_acc_3: 0.8152 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8148 - val_crf_36_acc_3: 0.9849 - val_f1: 0.8411 - val_crf_34_f1: 0.8522 - val_crf_35_f1: 0.7703 - val_crf_36_f1: 0.9007
Epoch 22/25
 - 1706s - loss: -4.9033e-01 - crf_34_loss: -1.3292e-01 - crf_35_loss: -1.7026e-01 - crf_36_loss: -1.8714e-01 - crf_34_acc_1: 0.9507 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9436 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7753 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9766 - val_loss: -5.4447e-01 - val_crf_34_loss: -1.6398e-01 - val_crf_35_loss: -1.8287e-01 - val_crf_36_loss: -1.9762e-01 - val_crf_34_acc_1: 0.9720 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9572 - val_crf_35_acc_3: 0.8152 - val_crf_36_acc_1: 0.8136 - val_crf_36_acc_2: 0.8151 - val_crf_36_acc_3: 0.9847 - val_f1: 0.8417 - val_crf_34_f1: 0.8521 - val_crf_35_f1: 0.7728 - val_crf_36_f1: 0.9002
Epoch 23/25
 - 1706s - loss: -5.1965e-01 - crf_34_loss: -1.4274e-01 - crf_35_loss: -1.7998e-01 - crf_36_loss: -1.9693e-01 - crf_34_acc_1: 0.9514 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7754 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9448 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7754 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9769 - val_loss: -5.7275e-01 - val_crf_34_loss: -1.7339e-01 - val_crf_35_loss: -1.9227e-01 - val_crf_36_loss: -2.0709e-01 - val_crf_34_acc_1: 0.9726 - val_crf_34_acc_2: 0.8132 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9582 - val_crf_35_acc_3: 0.8152 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8149 - val_crf_36_acc_3: 0.9851 - val_f1: 0.8438 - val_crf_34_f1: 0.8550 - val_crf_35_f1: 0.7748 - val_crf_36_f1: 0.9015
Epoch 24/25
 - 1724s - loss: -5.4784e-01 - crf_34_loss: -1.5191e-01 - crf_35_loss: -1.8944e-01 - crf_36_loss: -2.0648e-01 - crf_34_acc_1: 0.9513 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9446 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7754 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9769 - val_loss: -5.9914e-01 - val_crf_34_loss: -1.8199e-01 - val_crf_35_loss: -2.0117e-01 - val_crf_36_loss: -2.1599e-01 - val_crf_34_acc_1: 0.9722 - val_crf_34_acc_2: 0.8129 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8134 - val_crf_35_acc_2: 0.9580 - val_crf_35_acc_3: 0.8154 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8148 - val_crf_36_acc_3: 0.9843 - val_f1: 0.8410 - val_crf_34_f1: 0.8502 - val_crf_35_f1: 0.7752 - val_crf_36_f1: 0.8975
Epoch 25/25
 - 1704s - loss: -5.7637e-01 - crf_34_loss: -1.6121e-01 - crf_35_loss: -1.9890e-01 - crf_36_loss: -2.1626e-01 - crf_34_acc_1: 0.9515 - crf_34_acc_2: 0.7724 - crf_34_acc_3: 0.7755 - crf_35_acc_1: 0.7723 - crf_35_acc_2: 0.9439 - crf_35_acc_3: 0.7738 - crf_36_acc_1: 0.7754 - crf_36_acc_2: 0.7729 - crf_36_acc_3: 0.9771 - val_loss: -6.2833e-01 - val_crf_34_loss: -1.9140e-01 - val_crf_35_loss: -2.1084e-01 - val_crf_36_loss: -2.2609e-01 - val_crf_34_acc_1: 0.9713 - val_crf_34_acc_2: 0.8130 - val_crf_34_acc_3: 0.8134 - val_crf_35_acc_1: 0.8133 - val_crf_35_acc_2: 0.9559 - val_crf_35_acc_3: 0.8154 - val_crf_36_acc_1: 0.8134 - val_crf_36_acc_2: 0.8150 - val_crf_36_acc_3: 0.9836 - val_f1: 0.8390 - val_crf_34_f1: 0.8534 - val_crf_35_f1: 0.7680 - val_crf_36_f1: 0.8954

-------------------------------------------
Best F1 score: 0.843767973954   (epoch number 23)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9756    0.5405    0.6957       148
        archivalreference     0.6992    0.7386    0.7184       853
              archive_lib     0.8776    0.8350    0.8557       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9302    0.9048    0.9173      4948
                      box     0.7959    0.3545    0.4906       110
              cartulation     0.4706    1.0000    0.6400         8
              conjunction     0.5155    0.7463    0.6098       134
                     date     0.2808    0.7069    0.4020        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2308    0.6429    0.3396        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1579    0.2000    0.1765       120
                        o     0.2270    0.2527    0.2391       752
               pagination     0.9156    0.9614    0.9379      1139
   publicationnumber-year     0.5888    0.8111    0.6823       646
         publicationplace     0.9198    0.8932    0.9063      1592
publicationspecifications     0.1595    0.1290    0.1426       372
                publisher     0.9024    0.8198    0.8591      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7368    0.5490    0.6292       153
                    title     0.9195    0.9366    0.9280     15560
                     tomo     0.6061    0.0893    0.1556       224
                   volume     0.4704    0.4874    0.4787       277
                     year     0.9223    0.7583    0.8323      2036

              avg / total     0.9749    0.9726    0.9728    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9756    0.5405    0.6957       148
        archivalreference     0.6992    0.7386    0.7184       853
              archive_lib     0.8776    0.8350    0.8557       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9302    0.9048    0.9173      4948
                      box     0.7959    0.3545    0.4906       110
              cartulation     0.4706    1.0000    0.6400         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5155    0.7463    0.6098       134
                     date     0.2808    0.7069    0.4020        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2308    0.6429    0.3396        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1579    0.2000    0.1765       120
                        o     0.2270    0.2527    0.2391       752
               pagination     0.9156    0.9614    0.9379      1139
   publicationnumber-year     0.5888    0.8111    0.6823       646
         publicationplace     0.9198    0.8932    0.9063      1592
publicationspecifications     0.1595    0.1290    0.1426       372
                publisher     0.9024    0.8198    0.8591      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.7368    0.5490    0.6292       153
                    title     0.9195    0.9366    0.9280     15560
                     tomo     0.6061    0.0893    0.1556       224
                   volume     0.4704    0.4874    0.4787       277
                     year     0.9223    0.7583    0.8323      2036

              avg / total     0.8661    0.8535    0.8550     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7402    0.4339    0.5471       348
        b-primary     0.8000    0.6095    0.6919       105
      b-secondary     0.6802    0.6866    0.6834       852
e-meta-annotation     0.9057    0.6334    0.7454      1061
        e-primary     0.6254    0.6233    0.6244       300
      e-secondary     0.7763    0.8288    0.8017      1717
i-meta-annotation     0.8256    0.6575    0.7321      9981
        i-primary     0.8038    0.8061    0.8050      1728
      i-secondary     0.7765    0.8925    0.8305     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.1953    0.3091    0.2393       427

      avg / total     0.9599    0.9582    0.9578    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7402    0.4339    0.5471       348
        b-primary     0.8000    0.6095    0.6919       105
      b-secondary     0.6802    0.6866    0.6834       852
e-meta-annotation     0.9057    0.6334    0.7454      1061
        e-primary     0.6254    0.6233    0.6244       300
      e-secondary     0.7763    0.8288    0.8017      1717
i-meta-annotation     0.8256    0.6575    0.7321      9981
        i-primary     0.8038    0.8061    0.8050      1728
      i-secondary     0.7765    0.8925    0.8305     14357
                o     0.1953    0.3091    0.2393       427

      avg / total     0.7859    0.7768    0.7748     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8103    0.6874    0.7438      1305
        e-r     0.2973    0.0084    0.0163      1310
        i-r     0.9376    0.9830    0.9598     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2641    0.3396    0.2971       427

avg / total     0.9805    0.9851    0.9815    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8103    0.6874    0.7438      1305
        e-r     0.2973    0.0084    0.0163      1310
        i-r     0.9376    0.9830    0.9598     27834
          o     0.2641    0.3396    0.2971       427

avg / total     0.8957    0.9203    0.9015     30876




Confusion matrix, without normalization
[[    37      0    103      8      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    16      6    828      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    18      0     78      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   897      1   4029     21      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    129      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2     25      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     11      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      2    110      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     7      0    597    148      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     4      8   1127      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      1    639      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1587      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    359     13      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      0   1441      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    149      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   116      2  15294    148      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0     13   1842    181      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   6.95945946e-01   5.40540541e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.87573271e-02   7.03399766e-03   9.70691676e-01   3.51699883e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.74757282e-01   0.00000000e+00   7.57281553e-01   6.79611650e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.81285368e-01   2.02101859e-04   8.14268391e-01   4.24413905e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.62686567e-01   3.73134328e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   7.14285714e-02   8.92857143e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.33333333e-02   9.16666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   1.66666667e-02   9.16666667e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  9.30851064e-03   0.00000000e+00   7.93882979e-01   1.96808511e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.51185250e-03   7.02370500e-03   9.89464442e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.09597523e-03   1.54798762e-03   9.89164087e-01   6.19195046e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.96859296e-01   3.14070352e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.65053763e-01   3.49462366e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.38600139e-03   0.00000000e+00   9.98613999e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   9.67532468e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.45501285e-03   1.28534704e-04   9.82904884e-01   9.51156812e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.38506876e-03   9.04715128e-01   8.88998035e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   267      0     41     40      0      0      0      0      0      0
       0]
 [    30      0     74      1      0      0      0      0      0      0
       0]
 [   600      0    141    111      0      0      0      0      0      0
       0]
 [     2      3   1056      0      0      0      0      0      0      0
       0]
 [     0      0    293      7      0      0      0      0      0      0
       0]
 [     1      8   1694     14      0      0      0      0      0      0
       0]
 [    63      7   9819     92      0      0      0      0      0      0
       0]
 [    14     13   1673     28      0      0      0      0      0      0
       0]
 [   125      6  14115    111      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     5      0    277    145      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.67241379e-01   0.00000000e+00   1.17816092e-01   1.14942529e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.85714286e-01   0.00000000e+00   7.04761905e-01   9.52380952e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.04225352e-01   0.00000000e+00   1.65492958e-01   1.30281690e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.88501414e-03   2.82752121e-03   9.95287465e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.76666667e-01   2.33333333e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.82411182e-04   4.65928946e-03   9.86604543e-01   8.15375655e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.31199279e-03   7.01332532e-04   9.83769161e-01   9.21751328e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.10185185e-03   7.52314815e-03   9.68171296e-01   1.62037037e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.70655429e-03   4.17914606e-04   9.83144111e-01   7.73142021e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.17096019e-02   0.00000000e+00   6.48711944e-01   3.39578454e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   897      0    256      0    152]
 [     0     11   1288      0     11]
 [   205     26  27362      0    241]
 [     0      0      0 133958      0]
 [     5      0    277      0    145]]
Normalized confusion matrix
[[  6.87356322e-01   0.00000000e+00   1.96168582e-01   0.00000000e+00
    1.16475096e-01]
 [  0.00000000e+00   8.39694656e-03   9.83206107e-01   0.00000000e+00
    8.39694656e-03]
 [  7.36509305e-03   9.34109363e-04   9.83042322e-01   0.00000000e+00
    8.65847525e-03]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  1.17096019e-02   0.00000000e+00   6.48711944e-01   0.00000000e+00
    3.39578454e-01]]
