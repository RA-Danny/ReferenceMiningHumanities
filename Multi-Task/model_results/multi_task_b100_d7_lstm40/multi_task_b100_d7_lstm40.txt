______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_6 (InputLayer)                             (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_6[0][0]                                     
______________________________________________________________________________________________________________________________________________________
dropout_7 (Dropout)                              (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_5 (InputLayer)                             (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_5 (TimeDistributed)             (None, 73, 54, 50)               25200             dropout_7[0][0]                                   
______________________________________________________________________________________________________________________________________________________
embedding_5 (Embedding)                          (None, 73, 300)                  17130300          input_5[0][0]                                     
______________________________________________________________________________________________________________________________________________________
time_distributed_6 (TimeDistributed)             (None, 73, 2700)                 0                 time_distributed_5[0][0]                          
______________________________________________________________________________________________________________________________________________________
concatenate_3 (Concatenate)                      (None, 73, 3000)                 0                 embedding_5[0][0]                                 
                                                                                                    time_distributed_6[0][0]                          
______________________________________________________________________________________________________________________________________________________
dropout_8 (Dropout)                              (None, 73, 3000)                 0                 concatenate_3[0][0]                               
______________________________________________________________________________________________________________________________________________________
bidirectional_6 (Bidirectional)                  (None, 73, 80)                   973120            dropout_8[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dropout_9 (Dropout)                              (None, 73, 80)                   0                 bidirectional_6[0][0]                             
______________________________________________________________________________________________________________________________________________________
dense_7 (Dense)                                  (None, 73, 28)                   2268              dropout_9[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dense_8 (Dense)                                  (None, 73, 11)                   891               dropout_9[0][0]                                   
______________________________________________________________________________________________________________________________________________________
dense_9 (Dense)                                  (None, 73, 5)                    405               dropout_9[0][0]                                   
______________________________________________________________________________________________________________________________________________________
crf_7 (CRF)                                      (None, 73, 28)                   1652              dense_7[0][0]                                     
______________________________________________________________________________________________________________________________________________________
crf_8 (CRF)                                      (None, 73, 11)                   275               dense_8[0][0]                                     
______________________________________________________________________________________________________________________________________________________
crf_9 (CRF)                                      (None, 73, 5)                    65                dense_9[0][0]                                     
======================================================================================================================================================
Total params: 18,150,676
Trainable params: 18,150,676
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 1520s - loss: 0.8861 - crf_7_loss: 0.3985 - crf_8_loss: 0.3009 - crf_9_loss: 0.1866 - crf_7_acc_1: 0.8821 - crf_7_acc_2: 0.7672 - crf_7_acc_3: 0.7708 - crf_8_acc_1: 0.7686 - crf_8_acc_2: 0.8770 - crf_8_acc_3: 0.7702 - crf_9_acc_1: 0.7690 - crf_9_acc_2: 0.7671 - crf_9_acc_3: 0.9374 - val_loss: 0.2991 - val_crf_7_loss: 0.1544 - val_crf_8_loss: 0.1134 - val_crf_9_loss: 0.0313 - val_crf_7_acc_1: 0.9441 - val_crf_7_acc_2: 0.8128 - val_crf_7_acc_3: 0.8133 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9336 - val_crf_8_acc_3: 0.8155 - val_crf_9_acc_1: 0.8128 - val_crf_9_acc_2: 0.8138 - val_crf_9_acc_3: 0.9876 - val_f1: 0.7396 - val_crf_7_f1: 0.6560 - val_crf_8_f1: 0.6315 - val_crf_9_f1: 0.9315
Epoch 2/25
 - 1514s - loss: 0.3657 - crf_7_loss: 0.1917 - crf_8_loss: 0.1151 - crf_9_loss: 0.0590 - crf_7_acc_1: 0.9227 - crf_7_acc_2: 0.7726 - crf_7_acc_3: 0.7758 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9226 - crf_8_acc_3: 0.7744 - crf_9_acc_1: 0.7736 - crf_9_acc_2: 0.7727 - crf_9_acc_3: 0.9708 - val_loss: 0.1694 - val_crf_7_loss: 0.0983 - val_crf_8_loss: 0.0590 - val_crf_9_loss: 0.0121 - val_crf_7_acc_1: 0.9500 - val_crf_7_acc_2: 0.8129 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8132 - val_crf_8_acc_2: 0.9433 - val_crf_8_acc_3: 0.8157 - val_crf_9_acc_1: 0.8130 - val_crf_9_acc_2: 0.8142 - val_crf_9_acc_3: 0.9882 - val_f1: 0.7724 - val_crf_7_f1: 0.6926 - val_crf_8_f1: 0.6892 - val_crf_9_f1: 0.9354
Epoch 3/25
 - 1516s - loss: 0.2168 - crf_7_loss: 0.1276 - crf_8_loss: 0.0626 - crf_9_loss: 0.0266 - crf_7_acc_1: 0.9303 - crf_7_acc_2: 0.7726 - crf_7_acc_3: 0.7758 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9307 - crf_8_acc_3: 0.7742 - crf_9_acc_1: 0.7739 - crf_9_acc_2: 0.7728 - crf_9_acc_3: 0.9746 - val_loss: 0.0927 - val_crf_7_loss: 0.0633 - val_crf_8_loss: 0.0303 - val_crf_9_loss: -8.6059e-04 - val_crf_7_acc_1: 0.9546 - val_crf_7_acc_2: 0.8132 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9477 - val_crf_8_acc_3: 0.8156 - val_crf_9_acc_1: 0.8129 - val_crf_9_acc_2: 0.8144 - val_crf_9_acc_3: 0.9893 - val_f1: 0.7896 - val_crf_7_f1: 0.7179 - val_crf_8_f1: 0.7111 - val_crf_9_f1: 0.9399
Epoch 4/25
 - 1514s - loss: 0.1363 - crf_7_loss: 0.0916 - crf_8_loss: 0.0358 - crf_9_loss: 0.0090 - crf_7_acc_1: 0.9344 - crf_7_acc_2: 0.7726 - crf_7_acc_3: 0.7758 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9341 - crf_8_acc_3: 0.7741 - crf_9_acc_1: 0.7741 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9752 - val_loss: 0.0452 - val_crf_7_loss: 0.0416 - val_crf_8_loss: 0.0144 - val_crf_9_loss: -1.0850e-02 - val_crf_7_acc_1: 0.9588 - val_crf_7_acc_2: 0.8133 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9474 - val_crf_8_acc_3: 0.8155 - val_crf_9_acc_1: 0.8130 - val_crf_9_acc_2: 0.8153 - val_crf_9_acc_3: 0.9884 - val_f1: 0.8036 - val_crf_7_f1: 0.7522 - val_crf_8_f1: 0.7222 - val_crf_9_f1: 0.9364
Epoch 5/25
 - 1535s - loss: 0.0853 - crf_7_loss: 0.0689 - crf_8_loss: 0.0194 - crf_9_loss: -2.9260e-03 - crf_7_acc_1: 0.9374 - crf_7_acc_2: 0.7726 - crf_7_acc_3: 0.7757 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9349 - crf_8_acc_3: 0.7740 - crf_9_acc_1: 0.7745 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9752 - val_loss: 0.0116 - val_crf_7_loss: 0.0269 - val_crf_8_loss: 0.0030 - val_crf_9_loss: -1.8324e-02 - val_crf_7_acc_1: 0.9614 - val_crf_7_acc_2: 0.8132 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9489 - val_crf_8_acc_3: 0.8155 - val_crf_9_acc_1: 0.8132 - val_crf_9_acc_2: 0.8143 - val_crf_9_acc_3: 0.9872 - val_f1: 0.8118 - val_crf_7_f1: 0.7872 - val_crf_8_f1: 0.7190 - val_crf_9_f1: 0.9291
Epoch 6/25
 - 1514s - loss: 0.0478 - crf_7_loss: 0.0532 - crf_8_loss: 0.0070 - crf_9_loss: -1.2314e-02 - crf_7_acc_1: 0.9393 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7757 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9368 - crf_8_acc_3: 0.7740 - crf_9_acc_1: 0.7746 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9749 - val_loss: -1.7451e-02 - val_crf_7_loss: 0.0164 - val_crf_8_loss: -7.0397e-03 - val_crf_9_loss: -2.6801e-02 - val_crf_7_acc_1: 0.9627 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9479 - val_crf_8_acc_3: 0.8154 - val_crf_9_acc_1: 0.8131 - val_crf_9_acc_2: 0.8145 - val_crf_9_acc_3: 0.9853 - val_f1: 0.8015 - val_crf_7_f1: 0.7855 - val_crf_8_f1: 0.7099 - val_crf_9_f1: 0.9090
Epoch 7/25
 - 1524s - loss: 0.0169 - crf_7_loss: 0.0407 - crf_8_loss: -3.0722e-03 - crf_9_loss: -2.0733e-02 - crf_7_acc_1: 0.9416 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7757 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9370 - crf_8_acc_3: 0.7740 - crf_9_acc_1: 0.7749 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9750 - val_loss: -4.1773e-02 - val_crf_7_loss: 0.0068 - val_crf_8_loss: -1.5171e-02 - val_crf_9_loss: -3.3367e-02 - val_crf_7_acc_1: 0.9615 - val_crf_7_acc_2: 0.8132 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9519 - val_crf_8_acc_3: 0.8155 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8144 - val_crf_9_acc_3: 0.9826 - val_f1: 0.8079 - val_crf_7_f1: 0.7922 - val_crf_8_f1: 0.7391 - val_crf_9_f1: 0.8922
Epoch 8/25
 - 1525s - loss: -1.0501e-02 - crf_7_loss: 0.0298 - crf_8_loss: -1.1884e-02 - crf_9_loss: -2.8458e-02 - crf_7_acc_1: 0.9430 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7756 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9385 - crf_8_acc_3: 0.7740 - crf_9_acc_1: 0.7750 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9748 - val_loss: -6.6089e-02 - val_crf_7_loss: -3.7597e-03 - val_crf_8_loss: -2.2732e-02 - val_crf_9_loss: -3.9597e-02 - val_crf_7_acc_1: 0.9662 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9542 - val_crf_8_acc_3: 0.8155 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8146 - val_crf_9_acc_3: 0.9825 - val_f1: 0.8200 - val_crf_7_f1: 0.8107 - val_crf_8_f1: 0.7581 - val_crf_9_f1: 0.8911
Epoch 9/25
 - 1524s - loss: -3.5580e-02 - crf_7_loss: 0.0205 - crf_8_loss: -2.0093e-02 - crf_9_loss: -3.5939e-02 - crf_7_acc_1: 0.9440 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7757 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9386 - crf_8_acc_3: 0.7740 - crf_9_acc_1: 0.7751 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9747 - val_loss: -9.1575e-02 - val_crf_7_loss: -1.2117e-02 - val_crf_8_loss: -3.1317e-02 - val_crf_9_loss: -4.8142e-02 - val_crf_7_acc_1: 0.9675 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9509 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8148 - val_crf_9_acc_3: 0.9836 - val_f1: 0.8169 - val_crf_7_f1: 0.8183 - val_crf_8_f1: 0.7346 - val_crf_9_f1: 0.8977
Epoch 10/25
 - 1525s - loss: -5.9117e-02 - crf_7_loss: 0.0120 - crf_8_loss: -2.7835e-02 - crf_9_loss: -4.3259e-02 - crf_7_acc_1: 0.9450 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7756 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9396 - crf_8_acc_3: 0.7739 - crf_9_acc_1: 0.7752 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9748 - val_loss: -1.1366e-01 - val_crf_7_loss: -1.9786e-02 - val_crf_8_loss: -3.8813e-02 - val_crf_9_loss: -5.5056e-02 - val_crf_7_acc_1: 0.9672 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9556 - val_crf_8_acc_3: 0.8153 - val_crf_9_acc_1: 0.8135 - val_crf_9_acc_2: 0.8146 - val_crf_9_acc_3: 0.9834 - val_f1: 0.8273 - val_crf_7_f1: 0.8249 - val_crf_8_f1: 0.7613 - val_crf_9_f1: 0.8957
Epoch 11/25
 - 1518s - loss: -8.2212e-02 - crf_7_loss: 0.0034 - crf_8_loss: -3.5217e-02 - crf_9_loss: -5.0355e-02 - crf_7_acc_1: 0.9459 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9398 - crf_8_acc_3: 0.7739 - crf_9_acc_1: 0.7752 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9750 - val_loss: -1.3464e-01 - val_crf_7_loss: -2.7311e-02 - val_crf_8_loss: -4.5557e-02 - val_crf_9_loss: -6.1769e-02 - val_crf_7_acc_1: 0.9683 - val_crf_7_acc_2: 0.8131 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9525 - val_crf_8_acc_3: 0.8153 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8147 - val_crf_9_acc_3: 0.9837 - val_f1: 0.8236 - val_crf_7_f1: 0.8301 - val_crf_8_f1: 0.7437 - val_crf_9_f1: 0.8971
Epoch 12/25
 - 1511s - loss: -1.0453e-01 - crf_7_loss: -4.4818e-03 - crf_8_loss: -4.2609e-02 - crf_9_loss: -5.7436e-02 - crf_7_acc_1: 0.9468 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9409 - crf_8_acc_3: 0.7739 - crf_9_acc_1: 0.7752 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9753 - val_loss: -1.5746e-01 - val_crf_7_loss: -3.5760e-02 - val_crf_8_loss: -5.2972e-02 - val_crf_9_loss: -6.8731e-02 - val_crf_7_acc_1: 0.9706 - val_crf_7_acc_2: 0.8129 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9562 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8150 - val_crf_9_acc_3: 0.9839 - val_f1: 0.8355 - val_crf_7_f1: 0.8400 - val_crf_8_f1: 0.7685 - val_crf_9_f1: 0.8981
Epoch 13/25
 - 1509s - loss: -1.2613e-01 - crf_7_loss: -1.2163e-02 - crf_8_loss: -4.9590e-02 - crf_9_loss: -6.4377e-02 - crf_7_acc_1: 0.9473 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7756 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9408 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7753 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9753 - val_loss: -1.7694e-01 - val_crf_7_loss: -4.2961e-02 - val_crf_8_loss: -5.8365e-02 - val_crf_9_loss: -7.5617e-02 - val_crf_7_acc_1: 0.9707 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9467 - val_crf_8_acc_3: 0.8153 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8156 - val_crf_9_acc_3: 0.9839 - val_f1: 0.8180 - val_crf_7_f1: 0.8401 - val_crf_8_f1: 0.7168 - val_crf_9_f1: 0.8971
Epoch 14/25
 - 1509s - loss: -1.4780e-01 - crf_7_loss: -1.9583e-02 - crf_8_loss: -5.6784e-02 - crf_9_loss: -7.1435e-02 - crf_7_acc_1: 0.9478 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7756 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9411 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7752 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9755 - val_loss: -1.9873e-01 - val_crf_7_loss: -5.1036e-02 - val_crf_8_loss: -6.5248e-02 - val_crf_9_loss: -8.2451e-02 - val_crf_7_acc_1: 0.9724 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9465 - val_crf_8_acc_3: 0.8153 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8157 - val_crf_9_acc_3: 0.9854 - val_f1: 0.8210 - val_crf_7_f1: 0.8477 - val_crf_8_f1: 0.7135 - val_crf_9_f1: 0.9018
Epoch 15/25
 - 1512s - loss: -1.6937e-01 - crf_7_loss: -2.7077e-02 - crf_8_loss: -6.3851e-02 - crf_9_loss: -7.8445e-02 - crf_7_acc_1: 0.9485 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9421 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7753 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9759 - val_loss: -2.2199e-01 - val_crf_7_loss: -5.8183e-02 - val_crf_8_loss: -7.3974e-02 - val_crf_9_loss: -8.9833e-02 - val_crf_7_acc_1: 0.9722 - val_crf_7_acc_2: 0.8129 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9545 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8150 - val_crf_9_acc_3: 0.9852 - val_f1: 0.8344 - val_crf_7_f1: 0.8466 - val_crf_8_f1: 0.7549 - val_crf_9_f1: 0.9018
Epoch 16/25
 - 1515s - loss: -1.9022e-01 - crf_7_loss: -3.4305e-02 - crf_8_loss: -7.0633e-02 - crf_9_loss: -8.5283e-02 - crf_7_acc_1: 0.9489 - crf_7_acc_2: 0.7725 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9425 - crf_8_acc_3: 0.7739 - crf_9_acc_1: 0.7753 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9759 - val_loss: -2.4139e-01 - val_crf_7_loss: -6.4899e-02 - val_crf_8_loss: -8.0434e-02 - val_crf_9_loss: -9.6053e-02 - val_crf_7_acc_1: 0.9723 - val_crf_7_acc_2: 0.8129 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9579 - val_crf_8_acc_3: 0.8153 - val_crf_9_acc_1: 0.8134 - val_crf_9_acc_2: 0.8148 - val_crf_9_acc_3: 0.9846 - val_f1: 0.8402 - val_crf_7_f1: 0.8482 - val_crf_8_f1: 0.7733 - val_crf_9_f1: 0.8992
Epoch 17/25
 - 1513s - loss: -2.1159e-01 - crf_7_loss: -4.1574e-02 - crf_8_loss: -7.7687e-02 - crf_9_loss: -9.2327e-02 - crf_7_acc_1: 0.9495 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9429 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7753 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9764 - val_loss: -2.6167e-01 - val_crf_7_loss: -7.1498e-02 - val_crf_8_loss: -8.7365e-02 - val_crf_9_loss: -1.0281e-01 - val_crf_7_acc_1: 0.9708 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9596 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8135 - val_crf_9_acc_2: 0.8148 - val_crf_9_acc_3: 0.9841 - val_f1: 0.8424 - val_crf_7_f1: 0.8442 - val_crf_8_f1: 0.7845 - val_crf_9_f1: 0.8984
Epoch 18/25
 - 1516s - loss: -2.3192e-01 - crf_7_loss: -4.8408e-02 - crf_8_loss: -8.4464e-02 - crf_9_loss: -9.9044e-02 - crf_7_acc_1: 0.9495 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9431 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7754 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9762 - val_loss: -2.7910e-01 - val_crf_7_loss: -7.7384e-02 - val_crf_8_loss: -9.2987e-02 - val_crf_9_loss: -1.0873e-01 - val_crf_7_acc_1: 0.9691 - val_crf_7_acc_2: 0.8129 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9536 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8135 - val_crf_9_acc_2: 0.8150 - val_crf_9_acc_3: 0.9821 - val_f1: 0.8305 - val_crf_7_f1: 0.8414 - val_crf_8_f1: 0.7580 - val_crf_9_f1: 0.8921
Epoch 19/25
 - 1512s - loss: -2.5264e-01 - crf_7_loss: -5.5513e-02 - crf_8_loss: -9.1246e-02 - crf_9_loss: -1.0588e-01 - crf_7_acc_1: 0.9502 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9433 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7753 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9763 - val_loss: -3.0095e-01 - val_crf_7_loss: -8.5587e-02 - val_crf_8_loss: -9.9255e-02 - val_crf_9_loss: -1.1610e-01 - val_crf_7_acc_1: 0.9714 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9490 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8135 - val_crf_9_acc_2: 0.8146 - val_crf_9_acc_3: 0.9829 - val_f1: 0.8207 - val_crf_7_f1: 0.8514 - val_crf_8_f1: 0.7164 - val_crf_9_f1: 0.8944
Epoch 20/25
 - 1511s - loss: -2.7333e-01 - crf_7_loss: -6.2395e-02 - crf_8_loss: -9.8126e-02 - crf_9_loss: -1.1281e-01 - crf_7_acc_1: 0.9505 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9436 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7754 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9766 - val_loss: -3.2269e-01 - val_crf_7_loss: -9.1447e-02 - val_crf_8_loss: -1.0763e-01 - val_crf_9_loss: -1.2362e-01 - val_crf_7_acc_1: 0.9717 - val_crf_7_acc_2: 0.8130 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8133 - val_crf_8_acc_2: 0.9574 - val_crf_8_acc_3: 0.8151 - val_crf_9_acc_1: 0.8135 - val_crf_9_acc_2: 0.8150 - val_crf_9_acc_3: 0.9847 - val_f1: 0.8394 - val_crf_7_f1: 0.8458 - val_crf_8_f1: 0.7715 - val_crf_9_f1: 0.9008
Epoch 21/25
 - 1512s - loss: -2.9397e-01 - crf_7_loss: -6.9243e-02 - crf_8_loss: -1.0502e-01 - crf_9_loss: -1.1971e-01 - crf_7_acc_1: 0.9505 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7722 - crf_8_acc_2: 0.9435 - crf_8_acc_3: 0.7737 - crf_9_acc_1: 0.7754 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9767 - val_loss: -3.4184e-01 - val_crf_7_loss: -9.8734e-02 - val_crf_8_loss: -1.1369e-01 - val_crf_9_loss: -1.2942e-01 - val_crf_7_acc_1: 0.9722 - val_crf_7_acc_2: 0.8131 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9562 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8135 - val_crf_9_acc_2: 0.8153 - val_crf_9_acc_3: 0.9830 - val_f1: 0.8389 - val_crf_7_f1: 0.8504 - val_crf_8_f1: 0.7710 - val_crf_9_f1: 0.8953
Epoch 22/25
 - 1512s - loss: -3.1432e-01 - crf_7_loss: -7.6231e-02 - crf_8_loss: -1.1167e-01 - crf_9_loss: -1.2641e-01 - crf_7_acc_1: 0.9505 - crf_7_acc_2: 0.7724 - crf_7_acc_3: 0.7755 - crf_8_acc_1: 0.7723 - crf_8_acc_2: 0.9440 - crf_8_acc_3: 0.7738 - crf_9_acc_1: 0.7753 - crf_9_acc_2: 0.7729 - crf_9_acc_3: 0.9767 - val_loss: -3.6152e-01 - val_crf_7_loss: -1.0460e-01 - val_crf_8_loss: -1.2044e-01 - val_crf_9_loss: -1.3648e-01 - val_crf_7_acc_1: 0.9706 - val_crf_7_acc_2: 0.8129 - val_crf_7_acc_3: 0.8134 - val_crf_8_acc_1: 0.8134 - val_crf_8_acc_2: 0.9548 - val_crf_8_acc_3: 0.8152 - val_crf_9_acc_1: 0.8133 - val_crf_9_acc_2: 0.8154 - val_crf_9_acc_3: 0.9821 - val_f1: 0.8354 - val_crf_7_f1: 0.8484 - val_crf_8_f1: 0.7653 - val_crf_9_f1: 0.8923

-------------------------------------------
Best F1 score: 0.842372179517   (epoch number 17)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9213    0.5541    0.6920       148
        archivalreference     0.6832    0.8066    0.7398       853
              archive_lib     0.7789    0.7184    0.7475       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9222    0.8985    0.9102      4948
                      box     0.8372    0.3273    0.4706       110
              cartulation     0.1702    1.0000    0.2909         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5189    0.7164    0.6019       134
                     date     0.3750    0.6724    0.4815        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2535    0.6429    0.3636        28
                foliation     0.4800    1.0000    0.6486        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.0588    0.0333    0.0426       120
                        o     0.2259    0.3497    0.2745       752
               pagination     0.9196    0.9543    0.9367      1139
   publicationnumber-year     0.6584    0.7430    0.6982       646
         publicationplace     0.9252    0.8235    0.8714      1592
publicationspecifications     0.2421    0.0618    0.0985       372
                publisher     0.8623    0.7942    0.8268      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.5736    0.4837    0.5248       153
                    title     0.9064    0.9269    0.9166     15560
                     tomo     0.3333    0.0357    0.0645       224
                   volume     0.3675    0.5560    0.4425       277
                     year     0.9258    0.7716    0.8417      2036

              avg / total     0.9730    0.9708    0.9708    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9213    0.5541    0.6920       148
        archivalreference     0.6832    0.8066    0.7398       853
              archive_lib     0.7789    0.7184    0.7475       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9222    0.8985    0.9102      4948
                      box     0.8372    0.3273    0.4706       110
              cartulation     0.1702    1.0000    0.2909         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5189    0.7164    0.6019       134
                     date     0.3750    0.6724    0.4815        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2535    0.6429    0.3636        28
                foliation     0.4800    1.0000    0.6486        12
             numbered_ref     0.0588    0.0333    0.0426       120
                        o     0.2259    0.3497    0.2745       752
               pagination     0.9196    0.9543    0.9367      1139
   publicationnumber-year     0.6584    0.7430    0.6982       646
         publicationplace     0.9252    0.8235    0.8714      1592
publicationspecifications     0.2421    0.0618    0.0985       372
                publisher     0.8623    0.7942    0.8268      1443
                      ref     0.0000    0.0000    0.0000         3
                 registry     1.0000    0.1039    0.1882       154
                   series     0.5736    0.4837    0.5248       153
                    title     0.9064    0.9269    0.9166     15560
                     tomo     0.3333    0.0357    0.0645       224
                   volume     0.3675    0.5560    0.4425       277
                     year     0.9258    0.7716    0.8417      2036

              avg / total     0.8559    0.8441    0.8442     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.7286    0.4167    0.5302       348
        b-primary     0.6744    0.2762    0.3919       105
      b-secondary     0.6793    0.6737    0.6765       852
e-meta-annotation     0.9015    0.7163    0.7983      1061
        e-primary     0.7017    0.5567    0.6208       300
      e-secondary     0.8000    0.7944    0.7972      1717
i-meta-annotation     0.8294    0.6967    0.7573      9981
        i-primary     0.8396    0.7812    0.8094      1728
      i-secondary     0.7854    0.8871    0.8332     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.1786    0.3326    0.2324       427

      avg / total     0.9615    0.9596    0.9596    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.7286    0.4167    0.5302       348
        b-primary     0.6744    0.2762    0.3919       105
      b-secondary     0.6793    0.6737    0.6765       852
e-meta-annotation     0.9015    0.7163    0.7983      1061
        e-primary     0.7017    0.5567    0.6208       300
      e-secondary     0.8000    0.7944    0.7972      1717
i-meta-annotation     0.8294    0.6967    0.7573      9981
        i-primary     0.8396    0.7812    0.8094      1728
      i-secondary     0.7854    0.8871    0.8332     14357
                o     0.1786    0.3326    0.2324       427

      avg / total     0.7943    0.7845    0.7845     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8195    0.6682    0.7362      1305
        e-r     0.3636    0.0092    0.0179      1310
        i-r     0.9374    0.9775    0.9570     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.2162    0.3817    0.2760       427

avg / total     0.9809    0.9841    0.9810    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8195    0.6682    0.7362      1305
        e-r     0.3636    0.0092    0.0179      1310
        i-r     0.9374    0.9775    0.9570     27834
          o     0.2162    0.3817    0.2760       427

avg / total     0.8981    0.9151    0.8984     30876




Confusion matrix, without normalization
[[    38      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    21      4    814     14      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    16      0     76     11      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   866      0   4055     27      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      8      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    127      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1     57      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      3     24      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      2    116      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     6      0    573    173      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     3      7   1129      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      1    637      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0   1585      7      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0    343     28      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      0   1439      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      0    149      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   102      1  15171    286      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    224      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    277      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0     14   1830    192      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.56756757e-01   0.00000000e+00   7.43243243e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.46189918e-02   4.68933177e-03   9.54279015e-01   1.64126612e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.55339806e-01   0.00000000e+00   7.37864078e-01   1.06796117e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.75020210e-01   0.00000000e+00   8.19523040e-01   5.45675020e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.47761194e-01   5.22388060e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.72413793e-02   9.82758621e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.57142857e-02   1.07142857e-01   8.57142857e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   1.66666667e-02   9.66666667e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.97872340e-03   0.00000000e+00   7.61968085e-01   2.30053191e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.63388938e-03   6.14574188e-03   9.91220369e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   1.54798762e-03   9.86068111e-01   1.08359133e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.95603015e-01   4.39698492e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   0.00000000e+00   9.22043011e-01   7.52688172e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.38600139e-03   0.00000000e+00   9.97227997e-01   1.38600139e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   0.00000000e+00   9.67532468e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.55526992e-03   6.42673522e-05   9.75000000e-01   1.83804627e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.87622790e-03   8.98821218e-01   9.43025540e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   254      0     53     41      0      0      0      0      0      0
       0]
 [    36      0     67      2      0      0      0      0      0      0
       0]
 [   582      0    156    114      0      0      0      0      0      0
       0]
 [     2      3   1054      2      0      0      0      0      0      0
       0]
 [     0      1    290      9      0      0      0      0      0      0
       0]
 [     0      8   1689     20      0      0      0      0      0      0
       0]
 [    61      6   9797    117      0      0      0      0      0      0
       0]
 [     8     10   1671     39      0      0      0      0      0      0
       0]
 [   117      5  13988    247      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     4      0    260    163      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.29885057e-01   0.00000000e+00   1.52298851e-01   1.17816092e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.42857143e-01   0.00000000e+00   6.38095238e-01   1.90476190e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.83098592e-01   0.00000000e+00   1.83098592e-01   1.33802817e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.88501414e-03   2.82752121e-03   9.93402451e-01   1.88501414e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.33333333e-03   9.66666667e-01   3.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   4.65928946e-03   9.83692487e-01   1.16482236e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.11161206e-03   6.01142170e-04   9.81564973e-01   1.17222723e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.62962963e-03   5.78703704e-03   9.67013889e-01   2.25694444e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.14933482e-03   3.48262172e-04   9.74298252e-01   1.72041513e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  9.36768150e-03   0.00000000e+00   6.08899297e-01   3.81733021e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   872      0    276      0    157]
 [     0     12   1282      0     16]
 [   188     21  27207      0    418]
 [     0      0      0 133958      0]
 [     4      0    260      0    163]]
Normalized confusion matrix
[[  6.68199234e-01   0.00000000e+00   2.11494253e-01   0.00000000e+00
    1.20306513e-01]
 [  0.00000000e+00   9.16030534e-03   9.78625954e-01   0.00000000e+00
    1.22137405e-02]
 [  6.75432924e-03   7.54472947e-04   9.77473593e-01   0.00000000e+00
    1.50176044e-02]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  9.36768150e-03   0.00000000e+00   6.08899297e-01   0.00000000e+00
    3.81733021e-01]]
