______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_44 (InputLayer)                            (None, 73, 54)                   0                                                                   
______________________________________________________________________________________________________________________________________________________
char_embedding (TimeDistributed)                 (None, 73, 54, 100)              16500             input_44[0][0]                                    
______________________________________________________________________________________________________________________________________________________
dropout_64 (Dropout)                             (None, 73, 54, 100)              0                 char_embedding[0][0]                              
______________________________________________________________________________________________________________________________________________________
input_43 (InputLayer)                            (None, 73)                       0                                                                   
______________________________________________________________________________________________________________________________________________________
time_distributed_43 (TimeDistributed)            (None, 73, 54, 50)               25200             dropout_64[0][0]                                  
______________________________________________________________________________________________________________________________________________________
embedding_43 (Embedding)                         (None, 73, 300)                  17130300          input_43[0][0]                                    
______________________________________________________________________________________________________________________________________________________
time_distributed_44 (TimeDistributed)            (None, 73, 2700)                 0                 time_distributed_43[0][0]                         
______________________________________________________________________________________________________________________________________________________
concatenate_22 (Concatenate)                     (None, 73, 3000)                 0                 embedding_43[0][0]                                
                                                                                                    time_distributed_44[0][0]                         
______________________________________________________________________________________________________________________________________________________
dropout_65 (Dropout)                             (None, 73, 3000)                 0                 concatenate_22[0][0]                              
______________________________________________________________________________________________________________________________________________________
bidirectional_44 (Bidirectional)                 (None, 73, 400)                  5121600           dropout_65[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dropout_66 (Dropout)                             (None, 73, 400)                  0                 bidirectional_44[0][0]                            
______________________________________________________________________________________________________________________________________________________
dense_64 (Dense)                                 (None, 73, 28)                   11228             dropout_66[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_65 (Dense)                                 (None, 73, 11)                   4411              dropout_66[0][0]                                  
______________________________________________________________________________________________________________________________________________________
dense_66 (Dense)                                 (None, 73, 5)                    2005              dropout_66[0][0]                                  
______________________________________________________________________________________________________________________________________________________
crf_64 (CRF)                                     (None, 73, 28)                   1652              dense_64[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_65 (CRF)                                     (None, 73, 11)                   275               dense_65[0][0]                                    
______________________________________________________________________________________________________________________________________________________
crf_66 (CRF)                                     (None, 73, 5)                    65                dense_66[0][0]                                    
======================================================================================================================================================
Total params: 22,313,236
Trainable params: 22,313,236
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
None 




Train on 49616 samples, validate on 2258 samples
Epoch 1/25
 - 2689s - loss: 0.3486 - crf_64_loss: 0.1631 - crf_65_loss: 0.1204 - crf_66_loss: 0.0651 - crf_64_acc_1: 0.9380 - crf_64_acc_2: 0.7721 - crf_64_acc_3: 0.7752 - crf_65_acc_1: 0.7717 - crf_65_acc_2: 0.9286 - crf_65_acc_3: 0.7736 - crf_66_acc_1: 0.7741 - crf_66_acc_2: 0.7722 - crf_66_acc_3: 0.9721 - val_loss: 0.0459 - val_crf_64_loss: 0.0347 - val_crf_65_loss: 0.0140 - val_crf_66_loss: -2.8686e-03 - val_crf_64_acc_1: 0.9742 - val_crf_64_acc_2: 0.8130 - val_crf_64_acc_3: 0.8134 - val_crf_65_acc_1: 0.8134 - val_crf_65_acc_2: 0.9569 - val_crf_65_acc_3: 0.8154 - val_crf_66_acc_1: 0.8136 - val_crf_66_acc_2: 0.8153 - val_crf_66_acc_3: 0.9913 - val_f1: 0.8585 - val_crf_64_f1: 0.8569 - val_crf_65_f1: 0.7680 - val_crf_66_f1: 0.9505
Epoch 2/25
 - 2644s - loss: 0.0307 - crf_64_loss: 0.0361 - crf_65_loss: 0.0035 - crf_66_loss: -8.9576e-03 - crf_64_acc_1: 0.9604 - crf_64_acc_2: 0.7723 - crf_64_acc_3: 0.7755 - crf_65_acc_1: 0.7722 - crf_65_acc_2: 0.9497 - crf_65_acc_3: 0.7737 - crf_66_acc_1: 0.7752 - crf_66_acc_2: 0.7731 - crf_66_acc_3: 0.9824 - val_loss: -5.6382e-02 - val_crf_64_loss: -4.1910e-03 - val_crf_65_loss: -2.2900e-02 - val_crf_66_loss: -2.9292e-02 - val_crf_64_acc_1: 0.9767 - val_crf_64_acc_2: 0.8130 - val_crf_64_acc_3: 0.8135 - val_crf_65_acc_1: 0.8134 - val_crf_65_acc_2: 0.9603 - val_crf_65_acc_3: 0.8151 - val_crf_66_acc_1: 0.8135 - val_crf_66_acc_2: 0.8155 - val_crf_66_acc_3: 0.9906 - val_f1: 0.8694 - val_crf_64_f1: 0.8732 - val_crf_65_f1: 0.7882 - val_crf_66_f1: 0.9467
Epoch 3/25
 - 2643s - loss: -6.5553e-02 - crf_64_loss: -2.4886e-04 - crf_65_loss: -2.9291e-02 - crf_66_loss: -3.6013e-02 - crf_64_acc_1: 0.9639 - crf_64_acc_2: 0.7722 - crf_64_acc_3: 0.7755 - crf_65_acc_1: 0.7722 - crf_65_acc_2: 0.9534 - crf_65_acc_3: 0.7736 - crf_66_acc_1: 0.7752 - crf_66_acc_2: 0.7731 - crf_66_acc_3: 0.9827 - val_loss: -1.2611e-01 - val_crf_64_loss: -2.8786e-02 - val_crf_65_loss: -4.6023e-02 - val_crf_66_loss: -5.1298e-02 - val_crf_64_acc_1: 0.9752 - val_crf_64_acc_2: 0.8130 - val_crf_64_acc_3: 0.8135 - val_crf_65_acc_1: 0.8134 - val_crf_65_acc_2: 0.9606 - val_crf_65_acc_3: 0.8152 - val_crf_66_acc_1: 0.8136 - val_crf_66_acc_2: 0.8153 - val_crf_66_acc_3: 0.9865 - val_f1: 0.8635 - val_crf_64_f1: 0.8727 - val_crf_65_f1: 0.7924 - val_crf_66_f1: 0.9255
Epoch 4/25
 - 2642s - loss: -1.3938e-01 - crf_64_loss: -2.6265e-02 - crf_65_loss: -5.3684e-02 - crf_66_loss: -5.9432e-02 - crf_64_acc_1: 0.9658 - crf_64_acc_2: 0.7722 - crf_64_acc_3: 0.7755 - crf_65_acc_1: 0.7722 - crf_65_acc_2: 0.9554 - crf_65_acc_3: 0.7735 - crf_66_acc_1: 0.7753 - crf_66_acc_2: 0.7730 - crf_66_acc_3: 0.9820 - val_loss: -1.9376e-01 - val_crf_64_loss: -5.1647e-02 - val_crf_65_loss: -6.8406e-02 - val_crf_66_loss: -7.3707e-02 - val_crf_64_acc_1: 0.9770 - val_crf_64_acc_2: 0.8133 - val_crf_64_acc_3: 0.8134 - val_crf_65_acc_1: 0.8134 - val_crf_65_acc_2: 0.9645 - val_crf_65_acc_3: 0.8150 - val_crf_66_acc_1: 0.8135 - val_crf_66_acc_2: 0.8152 - val_crf_66_acc_3: 0.9860 - val_f1: 0.8658 - val_crf_64_f1: 0.8812 - val_crf_65_f1: 0.8092 - val_crf_66_f1: 0.9071
Epoch 5/25
 - 2667s - loss: -2.0765e-01 - crf_64_loss: -4.9241e-02 - crf_65_loss: -7.6247e-02 - crf_66_loss: -8.2164e-02 - crf_64_acc_1: 0.9672 - crf_64_acc_2: 0.7722 - crf_64_acc_3: 0.7754 - crf_65_acc_1: 0.7722 - crf_65_acc_2: 0.9573 - crf_65_acc_3: 0.7735 - crf_66_acc_1: 0.7753 - crf_66_acc_2: 0.7730 - crf_66_acc_3: 0.9821 - val_loss: -2.5909e-01 - val_crf_64_loss: -7.3017e-02 - val_crf_65_loss: -9.0257e-02 - val_crf_66_loss: -9.5818e-02 - val_crf_64_acc_1: 0.9783 - val_crf_64_acc_2: 0.8130 - val_crf_64_acc_3: 0.8134 - val_crf_65_acc_1: 0.8134 - val_crf_65_acc_2: 0.9636 - val_crf_65_acc_3: 0.8152 - val_crf_66_acc_1: 0.8133 - val_crf_66_acc_2: 0.8152 - val_crf_66_acc_3: 0.9851 - val_f1: 0.8659 - val_crf_64_f1: 0.8870 - val_crf_65_f1: 0.8069 - val_crf_66_f1: 0.9037
Epoch 6/25
 - 2633s - loss: -2.7373e-01 - crf_64_loss: -7.0824e-02 - crf_65_loss: -9.8237e-02 - crf_66_loss: -1.0467e-01 - crf_64_acc_1: 0.9681 - crf_64_acc_2: 0.7722 - crf_64_acc_3: 0.7754 - crf_65_acc_1: 0.7722 - crf_65_acc_2: 0.9590 - crf_65_acc_3: 0.7735 - crf_66_acc_1: 0.7753 - crf_66_acc_2: 0.7730 - crf_66_acc_3: 0.9825 - val_loss: -3.2252e-01 - val_crf_64_loss: -9.2538e-02 - val_crf_65_loss: -1.1182e-01 - val_crf_66_loss: -1.1816e-01 - val_crf_64_acc_1: 0.9782 - val_crf_64_acc_2: 0.8129 - val_crf_64_acc_3: 0.8135 - val_crf_65_acc_1: 0.8134 - val_crf_65_acc_2: 0.9652 - val_crf_65_acc_3: 0.8151 - val_crf_66_acc_1: 0.8135 - val_crf_66_acc_2: 0.8152 - val_crf_66_acc_3: 0.9858 - val_f1: 0.8688 - val_crf_64_f1: 0.8857 - val_crf_65_f1: 0.8149 - val_crf_66_f1: 0.9057
Epoch 7/25
 - 2669s - loss: -3.3861e-01 - crf_64_loss: -9.1625e-02 - crf_65_loss: -1.2001e-01 - crf_66_loss: -1.2698e-01 - crf_64_acc_1: 0.9686 - crf_64_acc_2: 0.7722 - crf_64_acc_3: 0.7754 - crf_65_acc_1: 0.7722 - crf_65_acc_2: 0.9605 - crf_65_acc_3: 0.7735 - crf_66_acc_1: 0.7753 - crf_66_acc_2: 0.7730 - crf_66_acc_3: 0.9828 - val_loss: -3.8690e-01 - val_crf_64_loss: -1.1264e-01 - val_crf_65_loss: -1.3355e-01 - val_crf_66_loss: -1.4071e-01 - val_crf_64_acc_1: 0.9784 - val_crf_64_acc_2: 0.8129 - val_crf_64_acc_3: 0.8135 - val_crf_65_acc_1: 0.8134 - val_crf_65_acc_2: 0.9652 - val_crf_65_acc_3: 0.8151 - val_crf_66_acc_1: 0.8134 - val_crf_66_acc_2: 0.8153 - val_crf_66_acc_3: 0.9865 - val_f1: 0.8690 - val_crf_64_f1: 0.8847 - val_crf_65_f1: 0.8141 - val_crf_66_f1: 0.9083

-------------------------------------------
Best F1 score: 0.869383668174   (epoch number 2)
For task 1
====================================================================================
With padding into account
                           precision    recall  f1-score   support

             abbreviation     0.9762    0.5541    0.7069       148
        archivalreference     0.8000    0.8253    0.8125       853
              archive_lib     0.8000    0.8155    0.8077       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9535    0.8996    0.9257      4948
                      box     0.8704    0.4273    0.5732       110
              cartulation     0.6667    1.0000    0.8000         8
              conjunction     0.5319    0.7463    0.6211       134
                     date     0.5614    0.5517    0.5565        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2979    0.5000    0.3733        28
                foliation     0.6000    1.0000    0.7500        12
                     null     1.0000    1.0000    1.0000    133958
             numbered_ref     0.1739    0.1667    0.1702       120
                        o     0.3185    0.2952    0.3064       752
               pagination     0.9338    0.9543    0.9440      1139
   publicationnumber-year     0.5835    0.8545    0.6935       646
         publicationplace     0.9512    0.8574    0.9019      1592
publicationspecifications     0.4059    0.4059    0.4059       372
                publisher     0.9165    0.8593    0.8870      1443
                      ref     1.0000    0.6667    0.8000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.8776    0.2810    0.4257       153
                    title     0.9116    0.9674    0.9387     15560
                     tomo     0.8261    0.2545    0.3891       224
                   volume     0.5794    0.4874    0.5294       277
                     year     0.9457    0.7608    0.8432      2036

              avg / total     0.9780    0.9767    0.9763    164834


----------------------------------------------

Without the padding:
                           precision    recall  f1-score   support

             abbreviation     0.9762    0.5541    0.7069       148
        archivalreference     0.8000    0.8253    0.8125       853
              archive_lib     0.8000    0.8155    0.8077       103
               attachment     0.0000    0.0000    0.0000         0
                   author     0.9535    0.8996    0.9257      4948
                      box     0.8704    0.4273    0.5732       110
              cartulation     0.6667    1.0000    0.8000         8
                   column     0.0000    0.0000    0.0000         0
              conjunction     0.5319    0.7463    0.6211       134
                     date     0.5614    0.5517    0.5565        58
                    filza     1.0000    1.0000    1.0000         3
                   folder     0.2979    0.5000    0.3733        28
                foliation     0.6000    1.0000    0.7500        12
             numbered_ref     0.1739    0.1667    0.1702       120
                        o     0.3185    0.2952    0.3064       752
               pagination     0.9338    0.9543    0.9440      1139
   publicationnumber-year     0.5835    0.8545    0.6935       646
         publicationplace     0.9512    0.8574    0.9019      1592
publicationspecifications     0.4059    0.4059    0.4059       372
                publisher     0.9165    0.8593    0.8870      1443
                      ref     1.0000    0.6667    0.8000         3
                 registry     0.7273    0.1039    0.1818       154
                   series     0.8776    0.2810    0.4257       153
                    title     0.9116    0.9674    0.9387     15560
                     tomo     0.8261    0.2545    0.3891       224
                   volume     0.5794    0.4874    0.5294       277
                     year     0.9457    0.7608    0.8432      2036

              avg / total     0.8824    0.8754    0.8732     30876



For task 2
====================================================================================
With padding into account
                   precision    recall  f1-score   support

b-meta-annotation     0.6162    0.6782    0.6457       348
        b-primary     0.7188    0.2190    0.3358       105
      b-secondary     0.7521    0.6338    0.6879       852
e-meta-annotation     0.8916    0.6975    0.7827      1061
        e-primary     0.6965    0.5967    0.6427       300
      e-secondary     0.7854    0.8526    0.8176      1717
i-meta-annotation     0.7201    0.8536    0.7812      9981
        i-primary     0.8373    0.7894    0.8126      1728
      i-secondary     0.8633    0.7740    0.8162     14357
             null     1.0000    1.0000    1.0000    133958
                o     0.3275    0.3513    0.3390       427

      avg / total     0.9619    0.9603    0.9603    164834


----------------------------------------------

Without the padding:
                   precision    recall  f1-score   support

b-meta-annotation     0.6162    0.6782    0.6457       348
        b-primary     0.7188    0.2190    0.3358       105
      b-secondary     0.7521    0.6338    0.6879       852
e-meta-annotation     0.8916    0.6975    0.7827      1061
        e-primary     0.6965    0.5967    0.6427       300
      e-secondary     0.7854    0.8526    0.8176      1717
i-meta-annotation     0.7201    0.8536    0.7812      9981
        i-primary     0.8373    0.7894    0.8126      1728
      i-secondary     0.8633    0.7740    0.8162     14357
                o     0.3275    0.3513    0.3390       427

      avg / total     0.7968    0.7880    0.7882     30876



For task 3
====================================================================================
With padding into account
             precision    recall  f1-score   support

        b-r     0.8301    0.7149    0.7682      1305
        e-r     0.9645    0.5191    0.6749      1310
        i-r     0.9633    0.9881    0.9755     27834
       null     1.0000    1.0000    1.0000    133958
          o     0.4150    0.4801    0.4452       427

avg / total     0.9907    0.9906    0.9900    164834


----------------------------------------------

Without the padding:
             precision    recall  f1-score   support

        b-r     0.8301    0.7149    0.7682      1305
        e-r     0.9645    0.5191    0.6749      1310
        i-r     0.9633    0.9881    0.9755     27834
          o     0.4150    0.4801    0.4452       427

avg / total     0.9501    0.9497    0.9467     30876




Confusion matrix, without normalization
[[    37      0    111      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    30      3    817      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    16      0     87      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   902      2   4026     18      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    110      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1      7      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    129      5      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2     56      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     28      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0     12      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      0      0      0      0      0      0      0      0
       0      0 133958      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     2      3    109      6      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [    10      7    521    214      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1    172    962      4      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1     12    630      3      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      1   1590      1      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      2    346     23      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     1      0   1442      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0      3      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     5      1    148      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    153      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [   118      5  15405     32      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      2    222      0      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0      0    275      2      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]
 [     0    492   1361    183      0      0      0      0      0      0
       0      0      0      0      0      0      0      0      0      0
       0      0      0      0      0      0      0]]
Normalized confusion matrix
[[  2.50000000e-01   0.00000000e+00   7.50000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.51699883e-02   3.51699883e-03   9.57796014e-01   3.51699883e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.55339806e-01   0.00000000e+00   8.44660194e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [             nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan              nan
               nan              nan              nan]
 [  1.82295877e-01   4.04203719e-04   8.13662086e-01   3.63783347e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.25000000e-01   8.75000000e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.62686567e-01   3.73134328e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   3.44827586e-02   9.65517241e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.66666667e-02   2.50000000e-02   9.08333333e-01   5.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.32978723e-02   9.30851064e-03   6.92819149e-01   2.84574468e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.77963126e-04   1.51009658e-01   8.44600527e-01   3.51185250e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  1.54798762e-03   1.85758514e-02   9.75232198e-01   4.64396285e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   6.28140704e-04   9.98743719e-01   6.28140704e-04
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  2.68817204e-03   5.37634409e-03   9.30107527e-01   6.18279570e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  6.93000693e-04   0.00000000e+00   9.99306999e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  3.24675325e-02   6.49350649e-03   9.61038961e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.58354756e-03   3.21336761e-04   9.90038560e-01   2.05655527e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   8.92857143e-03   9.91071429e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   9.92779783e-01   7.22021661e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.41650295e-01   6.68467583e-01   8.98821218e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   269      0     39     40      0      0      0      0      0      0
       0]
 [    46      0     59      0      0      0      0      0      0      0
       0]
 [   618      0    122    112      0      0      0      0      0      0
       0]
 [     0    206    847      8      0      0      0      0      0      0
       0]
 [     0      7    290      3      0      0      0      0      0      0
       0]
 [     0    467   1234     16      0      0      0      0      0      0
       0]
 [    54      4   9875     48      0      0      0      0      0      0
       0]
 [     7      6   1706      9      0      0      0      0      0      0
       0]
 [   123     12  14169     53      0      0      0      0      0      0
       0]
 [     0      0      0      0      0      0      0      0      0 133958
       0]
 [     7      3    212    205      0      0      0      0      0      0
       0]]
Normalized confusion matrix
[[  7.72988506e-01   0.00000000e+00   1.12068966e-01   1.14942529e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.38095238e-01   0.00000000e+00   5.61904762e-01   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  7.25352113e-01   0.00000000e+00   1.43192488e-01   1.31455399e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   1.94156456e-01   7.98303487e-01   7.54005655e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.33333333e-02   9.66666667e-01   1.00000000e-02
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   2.71986022e-01   7.18695399e-01   9.31857892e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  5.41027953e-03   4.00761447e-04   9.89379822e-01   4.80913736e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  4.05092593e-03   3.47222222e-03   9.87268519e-01   5.20833333e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  8.56724943e-03   8.35829212e-04   9.86905342e-01   3.69157902e-03
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   1.00000000e+00   0.00000000e+00]
 [  1.63934426e-02   7.02576112e-03   4.96487119e-01   4.80093677e-01
    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
    0.00000000e+00   0.00000000e+00   0.00000000e+00]]
Confusion matrix, without normalization
[[   933      0    220      0    152]
 [     0    680    617      0     13]
 [   184     22  27504      0    124]
 [     0      0      0 133958      0]
 [     7      3    212      0    205]]
Normalized confusion matrix
[[  7.14942529e-01   0.00000000e+00   1.68582375e-01   0.00000000e+00
    1.16475096e-01]
 [  0.00000000e+00   5.19083969e-01   4.70992366e-01   0.00000000e+00
    9.92366412e-03]
 [  6.61062010e-03   7.90400230e-04   9.88143997e-01   0.00000000e+00
    4.45498311e-03]
 [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00
    0.00000000e+00]
 [  1.63934426e-02   7.02576112e-03   4.96487119e-01   0.00000000e+00
    4.80093677e-01]]
